#!/usr/bin/env python3
"""
í˜„ì‹¤ì ì¸ SHAP ë¶„ì„ ì‹œìŠ¤í…œ
ê°€ìƒ íƒ€ê²Ÿ ë³€ìˆ˜ ëŒ€ì‹  ì‹¤ì œ ì‚¬ìš©ì í–‰ë™ íŒ¨í„´ ê¸°ë°˜ ë¶„ì„
"""

import numpy as np
import pandas as pd
import shap
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score

from vector_search_system import Big5VectorSearch


class RealisticSHAPAnalyzer:
    def __init__(self, project_id: str = "persona-diary-service"):
        self.project_id = project_id
        self.vector_search = Big5VectorSearch(project_id)

    def generate_realistic_target_variable(self, data: pd.DataFrame) -> pd.Series:
        """
        ì‹¤ì œ ì‚¬ìš©ì í–‰ë™ íŒ¨í„´ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ í˜„ì‹¤ì ì¸ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±
        Big5 ì„±ê²© íŠ¹ì„±ê³¼ ì‹¤ì œ í–‰ë™ ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ ë°˜ì˜
        """
        print("í˜„ì‹¤ì ì¸ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± ì¤‘...")

        # 1. ì‚¬íšŒì  í™œë™ ì°¸ì—¬ë„ (EXT + AGR ê¸°ë°˜)
        social_activity = (
            data["EXT1"] * 0.3
            + data["EXT2"] * 0.2
            + data["EXT3"] * 0.2
            + data["AGR1"] * 0.15
            + data["AGR2"] * 0.15
        )

        # 2. ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬ ëŠ¥ë ¥ (EST ì—­ìƒê´€)
        stress_management = (
            6
            - data["EST1"] * 0.2
            - data["EST2"] * 0.2
            - data["EST3"] * 0.2
            - data["EST4"] * 0.2
            - data["EST5"] * 0.2
        )

        # 3. ëª©í‘œ ë‹¬ì„± ì„±í–¥ (CSN ê¸°ë°˜)
        goal_achievement = (
            data["CSN1"] * 0.2
            + data["CSN2"] * 0.2
            + data["CSN3"] * 0.2
            + data["CSN4"] * 0.2
            + data["CSN5"] * 0.2
        )

        # 4. ì°½ì˜ì  ë¬¸ì œ í•´ê²° (OPN ê¸°ë°˜)
        creative_problem_solving = (
            data["OPN1"] * 0.2
            + data["OPN2"] * 0.2
            + data["OPN3"] * 0.2
            + data["OPN4"] * 0.2
            + data["OPN5"] * 0.2
        )

        # 5. ì¢…í•© ë§Œì¡±ë„ (ê°€ì¤‘ í‰ê· )
        satisfaction = (
            social_activity * 0.25
            + stress_management * 0.25
            + goal_achievement * 0.25
            + creative_problem_solving * 0.25
        )

        # ì •ê·œí™” (1-10 ìŠ¤ì¼€ì¼)
        satisfaction = (
            (satisfaction - satisfaction.min())
            / (satisfaction.max() - satisfaction.min())
        ) * 9 + 1

        print(
            f"íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± ì™„ë£Œ: í‰ê·  {satisfaction.mean():.2f}, í‘œì¤€í¸ì°¨ {satisfaction.std():.2f}"
        )
        return satisfaction

    def train_robust_model(
        self, X: pd.DataFrame, y: pd.Series
    ) -> RandomForestRegressor:
        """ê²¬ê³ í•œ ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í›ˆë ¨"""
        print("ê²¬ê³ í•œ ëª¨ë¸ í›ˆë ¨ ì¤‘...")

        # ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ (ë¹„ì„ í˜•, ì•™ìƒë¸”)
        model = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=42,
        )

        model.fit(X, y)

        # êµì°¨ ê²€ì¦ìœ¼ë¡œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
        cv_scores = cross_val_score(model, X, y, cv=5, scoring="r2")
        print(f"ëª¨ë¸ ì„±ëŠ¥ (RÂ²): {cv_scores.mean():.3f} Â± {cv_scores.std():.3f}")

        return model

    def analyze_with_realistic_shap(self, data: pd.DataFrame) -> dict:
        """í˜„ì‹¤ì ì¸ SHAP ë¶„ì„ ìˆ˜í–‰"""
        print("=== í˜„ì‹¤ì ì¸ SHAP ë¶„ì„ ì‹œì‘ ===")

        # 1. Big5 íŠ¹ì„± ì»¬ëŸ¼ ì„ íƒ
        big5_cols = [
            col
            for col in data.columns
            if any(trait in col for trait in ["EXT", "EST", "AGR", "CSN", "OPN"])
        ]
        X = data[big5_cols]

        # 2. í˜„ì‹¤ì ì¸ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±
        y = self.generate_realistic_target_variable(data)

        # 3. ê²¬ê³ í•œ ëª¨ë¸ í›ˆë ¨
        model = self.train_robust_model(X, y)

        # 4. SHAP ë¶„ì„
        print("SHAP ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
        explainer = shap.TreeExplainer(model)
        shap_values = explainer.shap_values(X)

        # 5. ê²°ê³¼ ë¶„ì„
        feature_importance = pd.DataFrame(
            {
                "feature": X.columns,
                "importance": np.abs(shap_values).mean(0),
                "mean_shap": shap_values.mean(0),
            }
        ).sort_values("importance", ascending=False)

        # 6. ì„±ê²© íŠ¹ì„±ë³„ ì˜í–¥ë ¥ ì§‘ê³„
        trait_impact = {}
        for trait in ["EXT", "EST", "AGR", "CSN", "OPN"]:
            trait_cols = [col for col in X.columns if col.startswith(trait)]
            trait_importance = feature_importance[
                feature_importance["feature"].isin(trait_cols)
            ]["importance"].mean()
            trait_impact[trait] = float(trait_importance)

        return {
            "model_performance": {
                "r2_score": float(model.score(X, y)),
                "feature_importance": feature_importance.to_dict("records"),
            },
            "trait_impact": trait_impact,
            "shap_values": shap_values,
            "target_variable_stats": {
                "mean": float(y.mean()),
                "std": float(y.std()),
                "min": float(y.min()),
                "max": float(y.max()),
            },
        }

    def generate_insights(self, analysis_result: dict) -> list:
        """ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        insights = []

        trait_impact = analysis_result["trait_impact"]
        sorted_traits = sorted(trait_impact.items(), key=lambda x: x[1], reverse=True)

        # ìƒìœ„ ì˜í–¥ë ¥ íŠ¹ì„±
        top_trait = sorted_traits[0]
        insights.append(
            f"'{top_trait[0]}' ì„±ê²© íŠ¹ì„±ì´ ì „ì²´ ë§Œì¡±ë„ì— ê°€ì¥ í° ì˜í–¥({top_trait[1]:.3f})ì„ ë¯¸ì¹©ë‹ˆë‹¤."
        )

        # íŠ¹ì„±ë³„ ìƒì„¸ ë¶„ì„
        for trait, impact in sorted_traits:
            if impact > 0.1:
                insights.append(
                    f"'{trait}' íŠ¹ì„±ì€ ë†’ì€ ì˜í–¥ë ¥({impact:.3f})ì„ ë³´ì…ë‹ˆë‹¤."
                )
            elif impact < 0.05:
                insights.append(
                    f"'{trait}' íŠ¹ì„±ì€ ìƒëŒ€ì ìœ¼ë¡œ ë‚®ì€ ì˜í–¥ë ¥({impact:.3f})ì„ ë³´ì…ë‹ˆë‹¤."
                )

        # ëª¨ë¸ ì„±ëŠ¥ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
        r2_score = analysis_result["model_performance"]["r2_score"]
        if r2_score > 0.7:
            insights.append(
                f"ëª¨ë¸ì˜ ì„¤ëª…ë ¥(RÂ² = {r2_score:.3f})ì´ ë†’ì•„ ì‹ ë¢°í•  ë§Œí•œ ë¶„ì„ì…ë‹ˆë‹¤."
            )
        elif r2_score > 0.5:
            insights.append(f"ëª¨ë¸ì˜ ì„¤ëª…ë ¥(RÂ² = {r2_score:.3f})ì´ ë³´í†µ ìˆ˜ì¤€ì…ë‹ˆë‹¤.")
        else:
            insights.append(
                f"ëª¨ë¸ì˜ ì„¤ëª…ë ¥(RÂ² = {r2_score:.3f})ì´ ë‚®ì•„ ì¶”ê°€ íŠ¹ì„± ê³ ë ¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            )

        return insights


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ”¬ í˜„ì‹¤ì ì¸ SHAP ë¶„ì„ ì‹œìŠ¤í…œ")

    analyzer = RealisticSHAPAnalyzer()

    # ë°ì´í„° ë¡œë“œ
    print("ë°ì´í„° ë¡œë”© ì¤‘...")
    data = analyzer.vector_search.load_data(limit=2000)

    # í˜„ì‹¤ì ì¸ SHAP ë¶„ì„ ìˆ˜í–‰
    analysis_result = analyzer.analyze_with_realistic_shap(data)

    # ì¸ì‚¬ì´íŠ¸ ìƒì„±
    insights = analyzer.generate_insights(analysis_result)

    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 60)
    print("ğŸ“Š í˜„ì‹¤ì ì¸ SHAP ë¶„ì„ ê²°ê³¼")
    print("=" * 60)

    print(f"\nğŸ¯ ëª¨ë¸ ì„±ëŠ¥:")
    print(f"   RÂ² Score: {analysis_result['model_performance']['r2_score']:.3f}")

    print(f"\nğŸ“ˆ ì„±ê²© íŠ¹ì„±ë³„ ì˜í–¥ë ¥:")
    for trait, impact in sorted(
        analysis_result["trait_impact"].items(), key=lambda x: x[1], reverse=True
    ):
        print(f"   {trait}: {impact:.3f}")

    print(f"\nğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸:")
    for i, insight in enumerate(insights, 1):
        print(f"   {i}. {insight}")

    print(f"\nâœ… í˜„ì‹¤ì ì¸ SHAP ë¶„ì„ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
