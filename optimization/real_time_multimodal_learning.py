#!/usr/bin/env python3
"""
ì‹¤ì‹œê°„ ë©€í‹°ëª¨ë‹¬ í•™ìŠµ ì‹œìŠ¤í…œ
- ì˜¨ë¼ì¸ í•™ìŠµ ë° ì ì‘
- ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- ë™ì  ëª¨ë¸ ì—…ë°ì´íŠ¸
"""

import json
import os
import queue
import threading
import time
import warnings
from collections import deque
from typing import Any, Dict, List, Optional, Tuple

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.preprocessing import StandardScaler
from tqdm import tqdm

warnings.filterwarnings("ignore", category=UserWarning)


class OnlineMultimodalLearner:
    """ê³ ê¸‰ ì˜¨ë¼ì¸ ë©€í‹°ëª¨ë‹¬ í•™ìŠµ ì‹œìŠ¤í…œ - ì‹¤ì‹œê°„ ì ì‘ ë° ìµœì í™”"""

    def __init__(
        self,
        big5_dim=25,
        cmi_dim=10,
        rppg_dim=15,
        voice_dim=20,
        learning_rate=0.001,
        buffer_size=1000,
        update_frequency=10,
        use_adaptive_lr=True,
        use_uncertainty_estimation=True,
        use_concept_drift_detection=True,
    ):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.learning_rate = learning_rate
        self.buffer_size = buffer_size
        self.update_frequency = update_frequency
        self.use_adaptive_lr = use_adaptive_lr
        self.use_uncertainty_estimation = use_uncertainty_estimation
        self.use_concept_drift_detection = use_concept_drift_detection

        # ì ì‘í˜• í•™ìŠµë¥  ê´€ë¦¬
        self.adaptive_lr_scheduler = None
        self.lr_decay_factor = 0.95
        self.lr_patience = 5

        # ë¶ˆí™•ì‹¤ì„± ì¶”ì •
        self.uncertainty_threshold = 0.1
        self.uncertainty_history = deque(maxlen=100)

        # ì»¨ì…‰ ë“œë¦¬í”„íŠ¸ íƒì§€
        self.drift_detector = None
        self.drift_threshold = 0.05
        self.drift_history = deque(maxlen=200)

        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.performance_history = deque(maxlen=1000)
        self.alert_threshold = 0.1

        # ë°ì´í„° ë²„í¼
        self.data_buffer = deque(maxlen=buffer_size)
        self.target_buffer = deque(maxlen=buffer_size)

        # ëª¨ë¸ ì´ˆê¸°í™”
        self.model = self._create_model(big5_dim, cmi_dim, rppg_dim, voice_dim)
        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)
        self.criterion = nn.MSELoss()

        # ìŠ¤ì¼€ì¼ëŸ¬
        self.scalers = {
            "big5": StandardScaler(),
            "cmi": StandardScaler(),
            "rppg": StandardScaler(),
            "voice": StandardScaler(),
            "target": StandardScaler(),
        }

        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.performance_history = []
        self.update_count = 0
        self.is_training = False

        # ìŠ¤ë ˆë“œ ì•ˆì „ì„ ìœ„í•œ ë½
        self.lock = threading.Lock()

        print(f"ğŸ”§ ì‹¤ì‹œê°„ í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        print(f"   ë””ë°”ì´ìŠ¤: {self.device}")
        print(f"   ë²„í¼ í¬ê¸°: {buffer_size}")
        print(f"   ì—…ë°ì´íŠ¸ ì£¼ê¸°: {update_frequency}")

    def _create_model(self, big5_dim, cmi_dim, rppg_dim, voice_dim):
        """ê²½ëŸ‰í™”ëœ ëª¨ë¸ ìƒì„±"""

        class LightweightMultimodalNet(nn.Module):
            def __init__(self):
                super().__init__()

                # ê° ëª¨ë‹¬ë¦¬í‹°ë³„ ì¸ì½”ë” (ê²½ëŸ‰í™”)
                self.big5_encoder = nn.Linear(big5_dim, 64)
                self.cmi_encoder = nn.Linear(cmi_dim, 32)
                self.rppg_encoder = nn.Linear(rppg_dim, 32)
                self.voice_encoder = nn.Linear(voice_dim, 32)

                # ìœµí•© ë ˆì´ì–´
                fusion_dim = 64 + 32 + 32 + 32
                self.fusion = nn.Sequential(
                    nn.Linear(fusion_dim, 128),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(128, 64),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(64, 1),
                )

                # ëª¨ë‹¬ë¦¬í‹° ê°€ì¤‘ì¹˜
                self.modality_weights = nn.Parameter(torch.ones(4))

            def forward(self, big5, cmi, rppg, voice):
                # ê° ëª¨ë‹¬ë¦¬í‹° ì¸ì½”ë”©
                big5_encoded = torch.relu(self.big5_encoder(big5))
                cmi_encoded = torch.relu(self.cmi_encoder(cmi))
                rppg_encoded = torch.relu(self.rppg_encoder(rppg))
                voice_encoded = torch.relu(self.voice_encoder(voice))

                # ìœµí•©
                fused = torch.cat(
                    [big5_encoded, cmi_encoded, rppg_encoded, voice_encoded], dim=1
                )
                output = self.fusion(fused)

                # ê°€ì¤‘ì¹˜ ê³„ì‚°
                weights = torch.softmax(self.modality_weights, dim=0)

                return output, weights

        return LightweightMultimodalNet().to(self.device)

    def add_data_point(self, big5_data, cmi_data, rppg_data, voice_data, target):
        """ìƒˆë¡œìš´ ë°ì´í„° í¬ì¸íŠ¸ ì¶”ê°€"""
        with self.lock:
            # ë°ì´í„° ì •ê·œí™”
            big5_scaled = (
                self.scalers["big5"]
                .partial_fit(big5_data.reshape(1, -1))
                .transform(big5_data.reshape(1, -1))
            )
            cmi_scaled = (
                self.scalers["cmi"]
                .partial_fit(cmi_data.reshape(1, -1))
                .transform(cmi_data.reshape(1, -1))
            )
            rppg_scaled = (
                self.scalers["rppg"]
                .partial_fit(rppg_data.reshape(1, -1))
                .transform(rppg_data.reshape(1, -1))
            )
            voice_scaled = (
                self.scalers["voice"]
                .partial_fit(voice_data.reshape(1, -1))
                .transform(voice_data.reshape(1, -1))
            )
            target_scaled = (
                self.scalers["target"]
                .partial_fit(np.array([[target]]))
                .transform(np.array([[target]]))[0, 0]
            )

            # ë²„í¼ì— ì¶”ê°€
            self.data_buffer.append(
                {
                    "big5": big5_scaled[0],
                    "cmi": cmi_scaled[0],
                    "rppg": rppg_scaled[0],
                    "voice": voice_scaled[0],
                }
            )
            self.target_buffer.append(target_scaled)

            # ì—…ë°ì´íŠ¸ ì£¼ê¸° í™•ì¸
            if len(self.data_buffer) >= self.update_frequency:
                self._update_model()

    def _update_model(self):
        """ê³ ê¸‰ ëª¨ë¸ ì—…ë°ì´íŠ¸ - ì ì‘í˜• í•™ìŠµ ë° ë“œë¦¬í”„íŠ¸ íƒì§€"""
        if len(self.data_buffer) < self.update_frequency:
            return

        self.is_training = True

        # ìµœê·¼ ë°ì´í„°ë¡œ ë°°ì¹˜ ìƒì„±
        recent_data = list(self.data_buffer)[-self.update_frequency :]
        recent_targets = list(self.target_buffer)[-self.update_frequency :]

        # í…ì„œë¡œ ë³€í™˜
        big5_batch = torch.FloatTensor([d["big5"] for d in recent_data]).to(self.device)
        cmi_batch = torch.FloatTensor([d["cmi"] for d in recent_data]).to(self.device)
        rppg_batch = torch.FloatTensor([d["rppg"] for d in recent_data]).to(self.device)
        voice_batch = torch.FloatTensor([d["voice"] for d in recent_data]).to(
            self.device
        )
        targets_batch = torch.FloatTensor(recent_targets).to(self.device)

        # ì»¨ì…‰ ë“œë¦¬í”„íŠ¸ íƒì§€
        if self.use_concept_drift_detection:
            drift_detected = self._detect_concept_drift(big5_batch, targets_batch)
            if drift_detected:
                self._handle_concept_drift()

        # ë¶ˆí™•ì‹¤ì„± ì¶”ì •
        uncertainty = 0.0
        if self.use_uncertainty_estimation:
            uncertainty = self._estimate_uncertainty(
                big5_batch, cmi_batch, rppg_batch, voice_batch
            )
            self.uncertainty_history.append(uncertainty)

            # ë¶ˆí™•ì‹¤ì„±ì´ ë†’ìœ¼ë©´ í•™ìŠµë¥  ì¡°ì •
            if uncertainty > self.uncertainty_threshold:
                self.learning_rate *= 1.1  # í•™ìŠµë¥  ì¦ê°€
            else:
                self.learning_rate *= 0.99  # í•™ìŠµë¥  ê°ì†Œ

        # ì ì‘í˜• í•™ìŠµë¥  ì ìš©
        if self.use_adaptive_lr:
            self._update_adaptive_learning_rate()

        # í›ˆë ¨
        self.model.train()
        self.optimizer.zero_grad()

        outputs, weights = self.model(big5_batch, cmi_batch, rppg_batch, voice_batch)
        loss = self.criterion(outputs.squeeze(), targets_batch)

        # ì •ê·œí™” ì†ì‹¤ ì¶”ê°€
        l2_reg = 0.001 * sum(p.pow(2.0).sum() for p in self.model.parameters())
        total_loss = loss + l2_reg

        total_loss.backward()

        # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)

        self.optimizer.step()

        # ì„±ëŠ¥ ê¸°ë¡ ë° ëª¨ë‹ˆí„°ë§
        with torch.no_grad():
            predictions = outputs.squeeze().cpu().numpy()
            targets_np = targets_batch.cpu().numpy()

            mse = mean_squared_error(targets_np, predictions)
            mae = mean_absolute_error(targets_np, predictions)

            self.performance_history.append(
                {
                    "update_count": self.update_count,
                    "mse": mse,
                    "mae": mae,
                    "loss": loss.item(),
                    "modality_weights": weights.cpu().numpy().tolist(),
                    "uncertainty": uncertainty,
                    "learning_rate": self.learning_rate,
                }
            )

            # ì„±ëŠ¥ ì•Œë¦¼ ì²´í¬
            self._check_performance_alerts(mae)

        self.update_count += 1
        self.is_training = False

    def _detect_concept_drift(self, big5_batch, targets_batch):
        """ì»¨ì…‰ ë“œë¦¬í”„íŠ¸ íƒì§€"""
        if len(self.drift_history) < 50:
            self.drift_history.append(
                (big5_batch.cpu().numpy(), targets_batch.cpu().numpy())
            )
            return False

        # ìµœê·¼ ë°ì´í„°ì™€ ì´ì „ ë°ì´í„° ë¹„êµ
        recent_data = np.array([x[0] for x in list(self.drift_history)[-10:]])
        older_data = np.array([x[0] for x in list(self.drift_history)[-50:-10]])

        # ë¶„í¬ ë³€í™” ì¸¡ì • (ê°„ë‹¨í•œ í†µê³„ì  í…ŒìŠ¤íŠ¸)
        recent_mean = np.mean(recent_data, axis=0)
        older_mean = np.mean(older_data, axis=0)

        drift_score = np.linalg.norm(recent_mean - older_mean)

        # ìƒˆë¡œìš´ ë°ì´í„° ì¶”ê°€
        self.drift_history.append(
            (big5_batch.cpu().numpy(), targets_batch.cpu().numpy())
        )

        return drift_score > self.drift_threshold

    def _handle_concept_drift(self):
        """ì»¨ì…‰ ë“œë¦¬í”„íŠ¸ ì²˜ë¦¬"""
        print("ğŸ”„ ì»¨ì…‰ ë“œë¦¬í”„íŠ¸ íƒì§€ë¨ - ëª¨ë¸ ì¬ì´ˆê¸°í™”")

        # í•™ìŠµë¥  ì¦ê°€
        self.learning_rate *= 1.5

        # ëª¨ë¸ ê°€ì¤‘ì¹˜ ì¬ì´ˆê¸°í™” (ë¶€ë¶„ì )
        for layer in self.model.children():
            if hasattr(layer, "reset_parameters"):
                layer.reset_parameters()

    def _estimate_uncertainty(self, big5_batch, cmi_batch, rppg_batch, voice_batch):
        """ë¶ˆí™•ì‹¤ì„± ì¶”ì • (Monte Carlo Dropout)"""
        self.model.train()  # Dropout í™œì„±í™”

        predictions = []
        for _ in range(10):  # 10ë²ˆ ìƒ˜í”Œë§
            with torch.no_grad():
                pred, _ = self.model(big5_batch, cmi_batch, rppg_batch, voice_batch)
                predictions.append(pred.cpu().numpy())

        predictions = np.array(predictions)
        uncertainty = np.std(predictions, axis=0).mean()

        return uncertainty

    def _update_adaptive_learning_rate(self):
        """ì ì‘í˜• í•™ìŠµë¥  ì—…ë°ì´íŠ¸"""
        if len(self.performance_history) < self.lr_patience:
            return

        recent_performance = [
            p["mae"] for p in list(self.performance_history)[-self.lr_patience :]
        ]
        older_performance = [
            p["mae"]
            for p in list(self.performance_history)[
                -self.lr_patience * 2 : -self.lr_patience
            ]
        ]

        if len(older_performance) > 0:
            recent_avg = np.mean(recent_performance)
            older_avg = np.mean(older_performance)

            # ì„±ëŠ¥ì´ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ í•™ìŠµë¥  ê°ì†Œ
            if recent_avg >= older_avg:
                self.learning_rate *= self.lr_decay_factor
                self.learning_rate = max(self.learning_rate, 1e-6)  # ìµœì†Œê°’ ë³´ì¥

    def _check_performance_alerts(self, current_mae):
        """ì„±ëŠ¥ ì•Œë¦¼ ì²´í¬"""
        if len(self.performance_history) < 10:
            return

        recent_mae = [p["mae"] for p in list(self.performance_history)[-10:]]
        overall_mae = [p["mae"] for p in list(self.performance_history)]

        recent_avg = np.mean(recent_mae)
        overall_avg = np.mean(overall_mae)

        # ì„±ëŠ¥ì´ í¬ê²Œ ì €í•˜ëœ ê²½ìš°
        if recent_avg > overall_avg * (1 + self.alert_threshold):
            print(f"âš ï¸ ì„±ëŠ¥ ì €í•˜ ê°ì§€: {recent_avg:.4f} > {overall_avg:.4f}")

            # ìë™ ë³µêµ¬ ì‹œë„
            self._attempt_recovery()

    def _attempt_recovery(self):
        """ì„±ëŠ¥ ë³µêµ¬ ì‹œë„"""
        print("ğŸ”§ ì„±ëŠ¥ ë³µêµ¬ ì‹œë„ ì¤‘...")

        # í•™ìŠµë¥  ì¡°ì •
        self.learning_rate *= 0.5

        # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¶€ë¶„ ì¬ì´ˆê¸°í™”
        for name, param in self.model.named_parameters():
            if "weight" in name and param.requires_grad:
                # ê°€ì¤‘ì¹˜ì— ì‘ì€ ë…¸ì´ì¦ˆ ì¶”ê°€
                noise = torch.randn_like(param) * 0.01
                param.data += noise

        print(
            f"ğŸ”„ ëª¨ë¸ ì—…ë°ì´íŠ¸ #{self.update_count}: Loss={loss.item():.4f}, MSE={mse:.4f}"
        )

    def predict(self, big5_data, cmi_data, rppg_data, voice_data):
        """ì˜ˆì¸¡ ìˆ˜í–‰"""
        with self.lock:
            self.model.eval()

            with torch.no_grad():
                # ë°ì´í„° ì •ê·œí™”
                big5_scaled = self.scalers["big5"].transform(big5_data.reshape(1, -1))
                cmi_scaled = self.scalers["cmi"].transform(cmi_data.reshape(1, -1))
                rppg_scaled = self.scalers["rppg"].transform(rppg_data.reshape(1, -1))
                voice_scaled = self.scalers["voice"].transform(
                    voice_data.reshape(1, -1)
                )

                # í…ì„œë¡œ ë³€í™˜
                big5_tensor = torch.FloatTensor(big5_scaled).to(self.device)
                cmi_tensor = torch.FloatTensor(cmi_scaled).to(self.device)
                rppg_tensor = torch.FloatTensor(rppg_scaled).to(self.device)
                voice_tensor = torch.FloatTensor(voice_scaled).to(self.device)

                # ì˜ˆì¸¡
                output, weights = self.model(
                    big5_tensor, cmi_tensor, rppg_tensor, voice_tensor
                )
                prediction = output.cpu().numpy()[0, 0]

                # ì—­ì •ê·œí™”
                prediction_original = self.scalers["target"].inverse_transform(
                    [[prediction]]
                )[0, 0]

                return prediction_original, weights.cpu().numpy()

    def get_performance_metrics(self):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°˜í™˜"""
        if not self.performance_history:
            return None

        recent_performance = self.performance_history[-10:]  # ìµœê·¼ 10íšŒ

        return {
            "avg_mse": np.mean([p["mse"] for p in recent_performance]),
            "avg_mae": np.mean([p["mae"] for p in recent_performance]),
            "avg_loss": np.mean([p["loss"] for p in recent_performance]),
            "total_updates": self.update_count,
            "buffer_size": len(self.data_buffer),
            "is_training": self.is_training,
        }

    def save_model(self, filepath: str):
        """ëª¨ë¸ ì €ì¥"""
        torch.save(
            {
                "model_state_dict": self.model.state_dict(),
                "optimizer_state_dict": self.optimizer.state_dict(),
                "scalers": self.scalers,
                "performance_history": self.performance_history,
                "update_count": self.update_count,
            },
            filepath,
        )
        print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥: {filepath}")

    def load_model(self, filepath: str):
        """ëª¨ë¸ ë¡œë“œ"""
        checkpoint = torch.load(filepath, map_location=self.device)
        self.model.load_state_dict(checkpoint["model_state_dict"])
        self.optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
        self.scalers = checkpoint["scalers"]
        self.performance_history = checkpoint["performance_history"]
        self.update_count = checkpoint["update_count"]
        print(f"ğŸ“‚ ëª¨ë¸ ë¡œë“œ: {filepath}")


class RealTimeMultimodalSystem:
    """ì‹¤ì‹œê°„ ë©€í‹°ëª¨ë‹¬ ì‹œìŠ¤í…œ"""

    def __init__(self, project_id: str = "persona-diary-service"):
        self.project_id = project_id
        self.learner = OnlineMultimodalLearner()
        self.data_queue = queue.Queue()
        self.running = False
        self.worker_thread = None

        print("ğŸš€ ì‹¤ì‹œê°„ ë©€í‹°ëª¨ë‹¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”")

    def start_learning_loop(self):
        """í•™ìŠµ ë£¨í”„ ì‹œì‘"""
        self.running = True
        self.worker_thread = threading.Thread(target=self._learning_worker)
        self.worker_thread.start()
        print("ğŸ”„ ì‹¤ì‹œê°„ í•™ìŠµ ë£¨í”„ ì‹œì‘")

    def stop_learning_loop(self):
        """í•™ìŠµ ë£¨í”„ ì¤‘ì§€"""
        self.running = False
        if self.worker_thread:
            self.worker_thread.join()
        print("â¹ï¸ ì‹¤ì‹œê°„ í•™ìŠµ ë£¨í”„ ì¤‘ì§€")

    def _learning_worker(self):
        """í•™ìŠµ ì›Œì»¤ ìŠ¤ë ˆë“œ"""
        while self.running:
            try:
                # íì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (íƒ€ì„ì•„ì›ƒ 1ì´ˆ)
                data = self.data_queue.get(timeout=1.0)

                # ë°ì´í„° ì²˜ë¦¬
                big5_data = data["big5"]
                cmi_data = data["cmi"]
                rppg_data = data["rppg"]
                voice_data = data["voice"]
                target = data["target"]

                # í•™ìŠµì— ì¶”ê°€
                self.learner.add_data_point(
                    big5_data, cmi_data, rppg_data, voice_data, target
                )

            except queue.Empty:
                continue
            except Exception as e:
                print(f"âŒ í•™ìŠµ ì›Œì»¤ ì˜¤ë¥˜: {e}")

    def add_training_data(self, big5_data, cmi_data, rppg_data, voice_data, target):
        """í›ˆë ¨ ë°ì´í„° ì¶”ê°€"""
        self.data_queue.put(
            {
                "big5": big5_data,
                "cmi": cmi_data,
                "rppg": rppg_data,
                "voice": voice_data,
                "target": target,
            }
        )

    def predict(self, big5_data, cmi_data, rppg_data, voice_data):
        """ì‹¤ì‹œê°„ ì˜ˆì¸¡"""
        return self.learner.predict(big5_data, cmi_data, rppg_data, voice_data)

    def get_system_status(self):
        """ì‹œìŠ¤í…œ ìƒíƒœ ë°˜í™˜"""
        metrics = self.learner.get_performance_metrics()
        return {
            "is_running": self.running,
            "queue_size": self.data_queue.qsize(),
            "performance": metrics,
            "learner_status": {
                "buffer_size": len(self.learner.data_buffer),
                "update_count": self.learner.update_count,
                "is_training": self.learner.is_training,
            },
        }

    def create_performance_dashboard(self, save_path: str = "realtime_performance.png"):
        """ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ ìƒì„±"""
        if not self.learner.performance_history:
            print("âŒ ì„±ëŠ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        history_df = pd.DataFrame(self.learner.performance_history)

        plt.figure(figsize=(15, 10))

        # MSE ì¶”ì´
        plt.subplot(2, 3, 1)
        plt.plot(history_df["update_count"], history_df["mse"])
        plt.title("MSE Over Time")
        plt.xlabel("Update Count")
        plt.ylabel("MSE")
        plt.grid(True)

        # MAE ì¶”ì´
        plt.subplot(2, 3, 2)
        plt.plot(history_df["update_count"], history_df["mae"])
        plt.title("MAE Over Time")
        plt.xlabel("Update Count")
        plt.ylabel("MAE")
        plt.grid(True)

        # Loss ì¶”ì´
        plt.subplot(2, 3, 3)
        plt.plot(history_df["update_count"], history_df["loss"])
        plt.title("Loss Over Time")
        plt.xlabel("Update Count")
        plt.ylabel("Loss")
        plt.grid(True)

        # ëª¨ë‹¬ë¦¬í‹° ê°€ì¤‘ì¹˜ ì¶”ì´
        plt.subplot(2, 3, 4)
        weights_df = pd.DataFrame(
            history_df["modality_weights"].tolist(),
            columns=["Big5", "CMI", "RPPG", "Voice"],
        )
        for col in weights_df.columns:
            plt.plot(history_df["update_count"], weights_df[col], label=col)
        plt.title("Modality Weights Over Time")
        plt.xlabel("Update Count")
        plt.ylabel("Weight")
        plt.legend()
        plt.grid(True)

        # ìµœê·¼ ì„±ëŠ¥ íˆíŠ¸ë§µ
        plt.subplot(2, 3, 5)
        recent_data = history_df.tail(20)
        performance_matrix = recent_data[["mse", "mae", "loss"]].values
        sns.heatmap(
            performance_matrix.T,
            xticklabels=recent_data["update_count"],
            yticklabels=["MSE", "MAE", "Loss"],
            cmap="YlOrRd",
            annot=True,
            fmt=".4f",
        )
        plt.title("Recent Performance Heatmap")

        # ì„±ëŠ¥ ë¶„í¬
        plt.subplot(2, 3, 6)
        plt.hist(history_df["mse"], bins=20, alpha=0.7, label="MSE")
        plt.hist(history_df["mae"], bins=20, alpha=0.7, label="MAE")
        plt.title("Performance Distribution")
        plt.xlabel("Value")
        plt.ylabel("Frequency")
        plt.legend()
        plt.grid(True)

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches="tight")
        plt.close()

        print(f"ğŸ“Š ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ ì €ì¥: {save_path}")


def simulate_real_time_learning():
    """ì‹¤ì‹œê°„ í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜"""
    print("ğŸ® ì‹¤ì‹œê°„ í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘")
    print("=" * 60)

    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    system = RealTimeMultimodalSystem()
    system.start_learning_loop()

    # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±
    np.random.seed(42)
    n_samples = 1000

    print(f"ğŸ“Š {n_samples}ê°œ ìƒ˜í”Œë¡œ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘...")

    for i in tqdm(range(n_samples)):
        # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±
        big5_data = np.random.normal(3.5, 1.0, 25)
        cmi_data = np.random.normal(50, 15, 10)
        rppg_data = np.random.normal(70, 10, 15)
        voice_data = np.random.normal(200, 50, 20)

        # íƒ€ê²Ÿ ìƒì„± (ë³µí•© ì ìˆ˜)
        target = (
            big5_data[:5].mean() * 0.3  # EXT
            + big5_data[20:25].mean() * 0.25  # OPN
            + (5 - big5_data[5:10].mean()) * 0.2  # EST (ì—­)
            + big5_data[10:15].mean() * 0.15  # AGR
            + big5_data[15:20].mean() * 0.1  # CSN
            + cmi_data.mean() / 100 * 0.1
            + rppg_data.mean() / 100 * 0.05
            + voice_data.mean() / 300 * 0.05
        )

        # ë°ì´í„° ì¶”ê°€
        system.add_training_data(big5_data, cmi_data, rppg_data, voice_data, target)

        # ì£¼ê¸°ì ìœ¼ë¡œ ìƒíƒœ ì¶œë ¥
        if (i + 1) % 100 == 0:
            status = system.get_system_status()
            print(f"\nğŸ“ˆ ì§„í–‰ ìƒí™© ({i+1}/{n_samples}):")
            print(f"   í í¬ê¸°: {status['queue_size']}")
            print(f"   ë²„í¼ í¬ê¸°: {status['learner_status']['buffer_size']}")
            print(f"   ì—…ë°ì´íŠ¸ íšŸìˆ˜: {status['learner_status']['update_count']}")
            if status["performance"]:
                print(f"   í‰ê·  MSE: {status['performance']['avg_mse']:.4f}")
                print(f"   í‰ê·  MAE: {status['performance']['avg_mae']:.4f}")

    # ìµœì¢… ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ ìƒì„±
    system.create_performance_dashboard()

    # ì‹œìŠ¤í…œ ì¤‘ì§€
    system.stop_learning_loop()

    # ìµœì¢… ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
    print("\nğŸ”® ìµœì¢… ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸:")
    test_big5 = np.random.normal(3.5, 1.0, 25)
    test_cmi = np.random.normal(50, 15, 10)
    test_rppg = np.random.normal(70, 10, 15)
    test_voice = np.random.normal(200, 50, 20)

    prediction, weights = system.predict(test_big5, test_cmi, test_rppg, test_voice)
    print(f"   ì˜ˆì¸¡ê°’: {prediction:.4f}")
    print(f"   ëª¨ë‹¬ë¦¬í‹° ê°€ì¤‘ì¹˜: {weights}")

    print("\nğŸ‰ ì‹¤ì‹œê°„ í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ!")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ§  ì‹¤ì‹œê°„ ë©€í‹°ëª¨ë‹¬ í•™ìŠµ ì‹œìŠ¤í…œ")
    print("=" * 60)

    # ì‹¤ì‹œê°„ í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
    simulate_real_time_learning()


if __name__ == "__main__":
    main()
