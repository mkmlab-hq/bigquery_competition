import json
import os
import warnings
from typing import Dict, List, Optional, Tuple

import numpy as np
import optuna
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim

# from optuna.integration import PyTorchLightningPruningCallback  # ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset

warnings.filterwarnings("ignore")


class TransferLearningMultimodalDataset(Dataset):
    """ì „ì´ í•™ìŠµìš© ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹"""

    def __init__(
        self,
        big5_data,
        cmi_data,
        rppg_data,
        voice_data,
        targets,
        augment=False,
        mixup_alpha=0.2,
        cutmix_alpha=1.0,
        noise_std=0.1,
    ):
        self.big5_data = big5_data
        self.cmi_data = cmi_data
        self.rppg_data = rppg_data
        self.voice_data = voice_data
        self.targets = targets
        self.augment = augment
        self.mixup_alpha = mixup_alpha
        self.cutmix_alpha = cutmix_alpha
        self.noise_std = noise_std
        self.training = False

    def __len__(self):
        return len(self.targets)

    def __getitem__(self, idx):
        big5 = torch.FloatTensor(self.big5_data[idx])
        cmi = torch.FloatTensor(self.cmi_data[idx])
        rppg = torch.FloatTensor(self.rppg_data[idx])
        voice = torch.FloatTensor(self.voice_data[idx])
        target = torch.FloatTensor([self.targets[idx]])

        # ë°ì´í„° ì¦ê°• ì ìš©
        if self.augment and self.training:
            big5, cmi, rppg, voice, target = self._apply_augmentation(
                big5, cmi, rppg, voice, target
            )

        return {
            "big5": big5,
            "cmi": cmi,
            "rppg": rppg,
            "voice": voice,
            "target": target,
        }

    def _apply_augmentation(self, big5, cmi, rppg, voice, target):
        """ê³ ê¸‰ ë°ì´í„° ì¦ê°• ì ìš©"""

        # 1. ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì¶”ê°€
        if np.random.random() < 0.3:
            noise_std = self.noise_std * np.random.uniform(0.5, 1.5)
            big5 += torch.randn_like(big5) * noise_std
            cmi += torch.randn_like(cmi) * noise_std
            rppg += torch.randn_like(rppg) * noise_std
            voice += torch.randn_like(voice) * noise_std

        # 2. Mixup ì ìš©
        if np.random.random() < 0.2:
            big5, cmi, rppg, voice, target = self._apply_mixup(
                big5, cmi, rppg, voice, target
            )

        # 3. CutMix ì ìš©
        if np.random.random() < 0.2:
            big5, cmi, rppg, voice, target = self._apply_cutmix(
                big5, cmi, rppg, voice, target
            )

        return big5, cmi, rppg, voice, target

    def _apply_mixup(self, big5, cmi, rppg, voice, target):
        """Mixup ë°ì´í„° ì¦ê°•"""
        alpha = self.mixup_alpha
        lam = np.random.beta(alpha, alpha)

        # ëœë¤ ìƒ˜í”Œ ì„ íƒ
        idx = np.random.randint(0, len(self.targets))
        big5_mix = torch.FloatTensor(self.big5_data[idx])
        cmi_mix = torch.FloatTensor(self.cmi_data[idx])
        rppg_mix = torch.FloatTensor(self.rppg_data[idx])
        voice_mix = torch.FloatTensor(self.voice_data[idx])
        target_mix = torch.FloatTensor([self.targets[idx]])

        # Mixup ì ìš©
        big5 = lam * big5 + (1 - lam) * big5_mix
        cmi = lam * cmi + (1 - lam) * cmi_mix
        rppg = lam * rppg + (1 - lam) * rppg_mix
        voice = lam * voice + (1 - lam) * voice_mix
        target = lam * target + (1 - lam) * target_mix

        return big5, cmi, rppg, voice, target

    def _apply_cutmix(self, big5, cmi, rppg, voice, target):
        """CutMix ë°ì´í„° ì¦ê°•"""
        alpha = self.cutmix_alpha
        lam = np.random.beta(alpha, alpha)

        # ëœë¤ ìƒ˜í”Œ ì„ íƒ
        idx = np.random.randint(0, len(self.targets))
        big5_mix = torch.FloatTensor(self.big5_data[idx])
        cmi_mix = torch.FloatTensor(self.cmi_data[idx])
        rppg_mix = torch.FloatTensor(self.rppg_data[idx])
        voice_mix = torch.FloatTensor(self.voice_data[idx])
        target_mix = torch.FloatTensor([self.targets[idx]])

        # CutMix ì ìš© (íŠ¹ì§• ì°¨ì›ì—ì„œ)
        cut_len = int(lam * len(big5))
        cut_start = np.random.randint(0, len(big5) - cut_len + 1)

        big5[cut_start : cut_start + cut_len] = big5_mix[
            cut_start : cut_start + cut_len
        ]
        cmi[cut_start : cut_start + cut_len] = cmi_mix[cut_start : cut_start + cut_len]
        rppg[cut_start : cut_start + cut_len] = rppg_mix[
            cut_start : cut_start + cut_len
        ]
        voice[cut_start : cut_start + cut_len] = voice_mix[
            cut_start : cut_start + cut_len
        ]

        # íƒ€ê²Ÿì€ ê°€ì¤‘ í‰ê· 
        target = lam * target + (1 - lam) * target_mix

        return big5, cmi, rppg, voice, target


class TransferLearningMultimodalNet(nn.Module):
    """ì „ì´ í•™ìŠµìš© ë©€í‹°ëª¨ë‹¬ ë„¤íŠ¸ì›Œí¬"""

    def __init__(
        self,
        big5_dim=5,
        cmi_dim=20,
        rppg_dim=10,
        voice_dim=20,
        hidden_dim=128,
        dropout_rate=0.3,
        use_pretrained=True,
    ):
        super(TransferLearningMultimodalNet, self).__init__()

        self.hidden_dim = hidden_dim
        self.use_pretrained = use_pretrained

        # ëª¨ë‹¬ë¦¬í‹°ë³„ ì¸ì½”ë” (ì‚¬ì „í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ í™œìš©)
        self.big5_encoder = nn.Sequential(
            nn.Linear(big5_dim, hidden_dim // 2),
            nn.BatchNorm1d(hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(hidden_dim // 2, hidden_dim // 2),
            nn.BatchNorm1d(hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
        )

        self.cmi_encoder = nn.Sequential(
            nn.Linear(cmi_dim, hidden_dim // 2),
            nn.BatchNorm1d(hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(hidden_dim // 2, hidden_dim // 2),
            nn.BatchNorm1d(hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
        )

        self.rppg_encoder = nn.Sequential(
            nn.Linear(rppg_dim, hidden_dim // 2),
            nn.BatchNorm1d(hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(hidden_dim // 2, hidden_dim // 2),
            nn.BatchNorm1d(hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
        )

        self.voice_encoder = nn.Sequential(
            nn.Linear(voice_dim, hidden_dim // 2),
            nn.BatchNorm1d(hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(hidden_dim // 2, hidden_dim // 2),
            nn.BatchNorm1d(hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
        )

        # í¬ë¡œìŠ¤ ëª¨ë‹¬ ì–´í…ì…˜ (ê°„ë‹¨í•œ ë²„ì „)
        self.attention_weights = nn.Sequential(
            nn.Linear(hidden_dim // 2, hidden_dim // 4),
            nn.ReLU(),
            nn.Linear(hidden_dim // 4, 1),
            nn.Softmax(dim=1),
        )

        # ìœµí•© ë ˆì´ì–´
        fusion_input_dim = 4 * (hidden_dim // 2) + (
            hidden_dim // 2
        )  # 4ê°œ ëª¨ë‹¬ë¦¬í‹° + ì–´í…ì…˜
        self.fusion_layer = nn.Sequential(
            nn.Linear(fusion_input_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.BatchNorm1d(hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
        )

        # ì¶œë ¥ ë ˆì´ì–´
        self.output_layer = nn.Sequential(
            nn.Linear(hidden_dim // 2, 1), nn.Sigmoid()  # 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
        )

        # ì‚¬ì „í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ (ê°€ëŠ¥í•œ ê²½ìš°)
        if use_pretrained:
            self._load_pretrained_weights()

    def _load_pretrained_weights(self):
        """ì‚¬ì „í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ"""
        try:
            # ê¸°ì¡´ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹œë„
            pretrained_path = "ultimate_smart_model.pth"
            if os.path.exists(pretrained_path):
                checkpoint = torch.load(pretrained_path, map_location="cpu")
                if "model_state_dict" in checkpoint:
                    state_dict = checkpoint["model_state_dict"]
                    # í˜¸í™˜ë˜ëŠ” ê°€ì¤‘ì¹˜ë§Œ ë¡œë“œ
                    self._load_compatible_weights(state_dict)
                    print("âœ… ì‚¬ì „í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ")
                else:
                    print(
                        "âš ï¸ ì‚¬ì „í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëœë¤ ì´ˆê¸°í™”ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
                    )
            else:
                print(
                    "âš ï¸ ì‚¬ì „í›ˆë ¨ëœ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëœë¤ ì´ˆê¸°í™”ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
                )
        except Exception as e:
            print(f"âš ï¸ ì‚¬ì „í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨: {str(e)}. ëœë¤ ì´ˆê¸°í™”ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

    def _load_compatible_weights(self, state_dict):
        """í˜¸í™˜ë˜ëŠ” ê°€ì¤‘ì¹˜ë§Œ ë¡œë“œ"""
        model_dict = self.state_dict()
        compatible_dict = {}

        for k, v in state_dict.items():
            if k in model_dict and v.shape == model_dict[k].shape:
                compatible_dict[k] = v

        model_dict.update(compatible_dict)
        self.load_state_dict(model_dict)
        print(f"âœ… {len(compatible_dict)}ê°œ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ")

    def forward(self, big5, cmi, rppg, voice):
        # ëª¨ë‹¬ë¦¬í‹°ë³„ ì¸ì½”ë”©
        big5_encoded = self.big5_encoder(big5)
        cmi_encoded = self.cmi_encoder(cmi)
        rppg_encoded = self.rppg_encoder(rppg)
        voice_encoded = self.voice_encoder(voice)

        # ê°„ë‹¨í•œ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜
        # ëª¨ë“  ëª¨ë‹¬ë¦¬í‹°ë¥¼ ìŠ¤íƒ
        modalities = torch.stack(
            [big5_encoded, cmi_encoded, rppg_encoded, voice_encoded], dim=1
        )
        # ì–´í…ì…˜ ê°€ì¤‘ì¹˜ ê³„ì‚°
        attention_weights = self.attention_weights(modalities)  # [batch_size, 4, 1]
        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì–´í…ì…˜ ì ìš©
        attended_features = torch.sum(
            modalities * attention_weights, dim=1
        )  # [batch_size, hidden_dim//2]

        # ìœµí•©
        fused_features = torch.cat(
            [big5_encoded, cmi_encoded, rppg_encoded, voice_encoded, attended_features],
            dim=1,
        )

        # ìµœì¢… ì˜ˆì¸¡
        fused = self.fusion_layer(fused_features)
        output = self.output_layer(fused)

        return output


class TransferLearningTrainer:
    """ì „ì´ í•™ìŠµ íŠ¸ë ˆì´ë„ˆ"""

    def __init__(self, model, device="cpu"):
        self.model = model
        self.device = device
        self.model.to(device)

    def train_epoch(self, dataloader, optimizer, criterion, scheduler=None):
        """í•œ ì—í¬í¬ í›ˆë ¨"""
        self.model.train()
        total_loss = 0
        num_batches = 0

        for batch in dataloader:
            optimizer.zero_grad()

            # ë°ì´í„°ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            big5 = batch["big5"].to(self.device)
            cmi = batch["cmi"].to(self.device)
            rppg = batch["rppg"].to(self.device)
            voice = batch["voice"].to(self.device)
            targets = batch["target"].to(self.device)

            # ì˜ˆì¸¡
            predictions = self.model(big5, cmi, rppg, voice)

            # ì†ì‹¤ ê³„ì‚°
            loss = criterion(predictions, targets)

            # ì—­ì „íŒŒ
            loss.backward()

            # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)

            optimizer.step()

            total_loss += loss.item()
            num_batches += 1

        if scheduler:
            scheduler.step()

        return total_loss / num_batches

    def evaluate(self, dataloader, criterion):
        """ëª¨ë¸ í‰ê°€"""
        self.model.eval()
        total_loss = 0
        all_predictions = []
        all_targets = []

        with torch.no_grad():
            for batch in dataloader:
                big5 = batch["big5"].to(self.device)
                cmi = batch["cmi"].to(self.device)
                rppg = batch["rppg"].to(self.device)
                voice = batch["voice"].to(self.device)
                targets = batch["target"].to(self.device)

                predictions = self.model(big5, cmi, rppg, voice)
                loss = criterion(predictions, targets)

                total_loss += loss.item()
                all_predictions.extend(predictions.cpu().numpy().flatten())
                all_targets.extend(targets.cpu().numpy().flatten())

        # ë©”íŠ¸ë¦­ ê³„ì‚°
        r2 = r2_score(all_targets, all_predictions)
        rmse = np.sqrt(mean_squared_error(all_targets, all_predictions))
        mae = mean_absolute_error(all_targets, all_predictions)

        return {
            "loss": total_loss / len(dataloader),
            "r2": r2,
            "rmse": rmse,
            "mae": mae,
            "predictions": all_predictions,
            "targets": all_targets,
        }

    def train(
        self,
        train_loader,
        val_loader,
        epochs=50,
        lr=0.001,
        weight_decay=1e-4,
        patience=10,
    ):
        """ì „ì²´ í›ˆë ¨ ê³¼ì •"""

        # ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬
        optimizer = optim.AdamW(
            self.model.parameters(), lr=lr, weight_decay=weight_decay
        )

        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
            optimizer, T_0=10, T_mult=2, eta_min=1e-6
        )

        criterion = nn.MSELoss()

        # ì¡°ê¸° ì¢…ë£Œ
        best_val_r2 = -float("inf")
        patience_counter = 0
        best_model_state = None

        print(f"ğŸš€ ì „ì´ í•™ìŠµ ì‹œì‘ (ì—í¬í¬: {epochs}, í•™ìŠµë¥ : {lr})")

        for epoch in range(epochs):
            # í›ˆë ¨
            train_loss = self.train_epoch(train_loader, optimizer, criterion, scheduler)

            # ê²€ì¦
            val_metrics = self.evaluate(val_loader, criterion)

            print(f"Epoch {epoch+1}/{epochs}:")
            print(f"  Train Loss: {train_loss:.4f}")
            print(f"  Val RÂ²: {val_metrics['r2']:.4f}")
            print(f"  Val RMSE: {val_metrics['rmse']:.4f}")
            print(f"  Val MAE: {val_metrics['mae']:.4f}")

            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
            if val_metrics["r2"] > best_val_r2:
                best_val_r2 = val_metrics["r2"]
                patience_counter = 0
                best_model_state = self.model.state_dict().copy()
                print(f"  âœ… ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! RÂ²: {best_val_r2:.4f}")
            else:
                patience_counter += 1
                print(f"  â³ ì¡°ê¸° ì¢…ë£Œ ì¹´ìš´í„°: {patience_counter}/{patience}")

            # ì¡°ê¸° ì¢…ë£Œ
            if patience_counter >= patience:
                print(f"ğŸ›‘ ì¡°ê¸° ì¢…ë£Œ! {patience}ë²ˆ ì—°ì† ê°œì„  ì—†ìŒ")
                break

        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë³µì›
        if best_model_state:
            self.model.load_state_dict(best_model_state)
            print(f"âœ… ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë³µì› ì™„ë£Œ (RÂ²: {best_val_r2:.4f})")

        return best_val_r2


def objective(trial, train_loader, val_loader, device):
    """Optuna ìµœì í™” ëª©ì  í•¨ìˆ˜"""

    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì œì•ˆ
    hidden_dim = trial.suggest_categorical("hidden_dim", [64, 128, 256])
    dropout_rate = trial.suggest_float("dropout_rate", 0.1, 0.5)
    lr = trial.suggest_float("lr", 1e-4, 1e-2, log=True)
    weight_decay = trial.suggest_float("weight_decay", 1e-5, 1e-3, log=True)

    # ëª¨ë¸ ìƒì„±
    model = TransferLearningMultimodalNet(
        hidden_dim=hidden_dim, dropout_rate=dropout_rate
    )

    # íŠ¸ë ˆì´ë„ˆ ìƒì„±
    trainer = TransferLearningTrainer(model, device)

    # í›ˆë ¨
    best_r2 = trainer.train(
        train_loader,
        val_loader,
        epochs=30,  # ë¹ ë¥¸ íŠœë‹ì„ ìœ„í•´ ì—í¬í¬ ìˆ˜ ê°ì†Œ
        lr=lr,
        weight_decay=weight_decay,
        patience=5,
    )

    return best_r2


def run_transfer_learning_experiment():
    """ì „ì´ í•™ìŠµ ì‹¤í—˜ ì‹¤í–‰"""

    print("ğŸ¯ ì „ì´ í•™ìŠµ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ ì‹¤í—˜ ì‹œì‘!")

    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")

    # ë°ì´í„° ìƒì„± (ì‹¤ì œ BigQuery ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜)
    print("ğŸ“Š ë°ì´í„° ìƒì„± ì¤‘...")

    # í•©ì„± ë°ì´í„° ìƒì„± (ì‚¬ì „í›ˆë ¨ìš©)
    n_samples = 10000
    big5_data = np.random.randn(n_samples, 5)
    cmi_data = np.random.randn(n_samples, 20)
    rppg_data = np.random.randn(n_samples, 10)
    voice_data = np.random.randn(n_samples, 20)

    # íƒ€ê²Ÿ ìƒì„± (ë” í˜„ì‹¤ì ì¸ ê´€ê³„)
    targets = (
        0.3 * big5_data[:, 0]  # Openness
        + 0.2 * big5_data[:, 1]  # Conscientiousness
        + 0.1 * big5_data[:, 2]  # Extraversion
        + 0.2 * big5_data[:, 3]  # Agreeableness
        + 0.1 * big5_data[:, 4]  # Neuroticism
        + 0.1 * np.mean(cmi_data, axis=1)
        + 0.05 * np.mean(rppg_data, axis=1)
        + 0.05 * np.mean(voice_data, axis=1)
        + np.random.normal(0, 0.1, n_samples)  # ë…¸ì´ì¦ˆ
    )

    # íƒ€ê²Ÿ ì •ê·œí™” (0-1 ë²”ìœ„)
    targets = (targets - targets.min()) / (targets.max() - targets.min())

    # ë°ì´í„° ë¶„í• 
    # ë¨¼ì € ì¸ë±ìŠ¤ë¡œ ë¶„í• 
    train_idx, test_idx = train_test_split(
        range(len(targets)), test_size=0.2, random_state=42
    )
    train_idx, val_idx = train_test_split(train_idx, test_size=0.2, random_state=42)

    # ë°ì´í„° ë¶„í• 
    X_train = {
        "big5": big5_data[train_idx],
        "cmi": cmi_data[train_idx],
        "rppg": rppg_data[train_idx],
        "voice": voice_data[train_idx],
    }
    X_val = {
        "big5": big5_data[val_idx],
        "cmi": cmi_data[val_idx],
        "rppg": rppg_data[val_idx],
        "voice": voice_data[val_idx],
    }
    X_test = {
        "big5": big5_data[test_idx],
        "cmi": cmi_data[test_idx],
        "rppg": rppg_data[test_idx],
        "voice": voice_data[test_idx],
    }

    y_train = targets[train_idx]
    y_val = targets[val_idx]
    y_test = targets[test_idx]

    print(f"í›ˆë ¨ ë°ì´í„°: {len(y_train)}ê°œ")
    print(f"ê²€ì¦ ë°ì´í„°: {len(y_val)}ê°œ")
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(y_test)}ê°œ")

    # ë°ì´í„° ì •ê·œí™”
    scalers = {}
    for modality in ["big5", "cmi", "rppg", "voice"]:
        scaler = StandardScaler()
        X_train[modality] = scaler.fit_transform(X_train[modality])
        X_val[modality] = scaler.transform(X_val[modality])
        X_test[modality] = scaler.transform(X_test[modality])
        scalers[modality] = scaler

    # ë°ì´í„°ì…‹ ìƒì„±
    train_dataset = TransferLearningMultimodalDataset(
        X_train["big5"],
        X_train["cmi"],
        X_train["rppg"],
        X_train["voice"],
        y_train,
        augment=True,
    )
    val_dataset = TransferLearningMultimodalDataset(
        X_val["big5"], X_val["cmi"], X_val["rppg"], X_val["voice"], y_val, augment=False
    )
    test_dataset = TransferLearningMultimodalDataset(
        X_test["big5"],
        X_test["cmi"],
        X_test["rppg"],
        X_test["voice"],
        y_test,
        augment=False,
    )

    # ë°ì´í„°ë¡œë” ìƒì„±
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

    # Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
    print("ğŸ” í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘...")

    study = optuna.create_study(direction="maximize")
    study.optimize(
        lambda trial: objective(trial, train_loader, val_loader, device),
        n_trials=20,  # ë¹ ë¥¸ íŠœë‹ì„ ìœ„í•´ ì‹œë„ íšŸìˆ˜ ê°ì†Œ
        show_progress_bar=True,
    )

    print(f"âœ… ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°: {study.best_params}")
    print(f"âœ… ìµœê³  RÂ²: {study.best_value:.4f}")

    # ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ìµœì¢… ëª¨ë¸ í›ˆë ¨
    print("ğŸ¯ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ìµœì¢… ëª¨ë¸ í›ˆë ¨...")

    best_model = TransferLearningMultimodalNet(
        hidden_dim=study.best_params["hidden_dim"],
        dropout_rate=study.best_params["dropout_rate"],
    )

    best_trainer = TransferLearningTrainer(best_model, device)
    final_r2 = best_trainer.train(
        train_loader,
        val_loader,
        epochs=50,
        lr=study.best_params["lr"],
        weight_decay=study.best_params["weight_decay"],
        patience=10,
    )

    # í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ í‰ê°€
    print("ğŸ§ª í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ í‰ê°€...")
    test_metrics = best_trainer.evaluate(test_loader, nn.MSELoss())

    print("\nğŸ“Š ìµœì¢… ê²°ê³¼:")
    print(f"  ê²€ì¦ RÂ²: {final_r2:.4f}")
    print(f"  í…ŒìŠ¤íŠ¸ RÂ²: {test_metrics['r2']:.4f}")
    print(f"  í…ŒìŠ¤íŠ¸ RMSE: {test_metrics['rmse']:.4f}")
    print(f"  í…ŒìŠ¤íŠ¸ MAE: {test_metrics['mae']:.4f}")

    # ê²°ê³¼ ì €ì¥
    results = {
        "best_params": study.best_params,
        "best_val_r2": study.best_value,
        "final_val_r2": final_r2,
        "test_r2": test_metrics["r2"],
        "test_rmse": test_metrics["rmse"],
        "test_mae": test_metrics["mae"],
        "model_architecture": {
            "hidden_dim": study.best_params["hidden_dim"],
            "dropout_rate": study.best_params["dropout_rate"],
        },
    }

    with open("transfer_learning_results.json", "w") as f:
        json.dump(results, f, indent=2)

    # ëª¨ë¸ ì €ì¥
    torch.save(
        {
            "model_state_dict": best_model.state_dict(),
            "best_params": study.best_params,
            "test_metrics": test_metrics,
        },
        "transfer_learning_model.pth",
    )

    print("âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ!")
    print("ğŸ“ transfer_learning_results.json")
    print("ğŸ“ transfer_learning_model.pth")

    return results


if __name__ == "__main__":
    results = run_transfer_learning_experiment()
