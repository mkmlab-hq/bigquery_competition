#!/usr/bin/env python3
"""
ì•™ìƒë¸” ìµœì í™” ì‹œìŠ¤í…œ - RÂ² 0.70+ ë„ì „
- í˜„ì¬ ëª¨ë¸ ê¸°ë°˜ ì•™ìƒë¸” êµ¬í˜„
- ë‹¤ì–‘í•œ ì•Œê³ ë¦¬ì¦˜ ì¡°í•©
- ì„±ëŠ¥ í–¥ìƒ ëª©í‘œ: RÂ² 0.70+
"""

import json
import os
import warnings
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from lightgbm import LGBMRegressor
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
from sklearn.linear_model import ElasticNet, Ridge
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import RobustScaler
from sklearn.svm import SVR
from xgboost import XGBRegressor

warnings.filterwarnings("ignore", category=UserWarning)


class EnsembleOptimizer:
    """ì•™ìƒë¸” ìµœì í™” ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.ensemble_weights = None
        self.best_ensemble = None

    def create_diverse_models(self):
        """ë‹¤ì–‘í•œ ëª¨ë¸ ìƒì„±"""
        print("ğŸ”„ ë‹¤ì–‘í•œ ëª¨ë¸ ìƒì„± ì¤‘...")

        self.models = {
            # íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ë“¤
            "random_forest": RandomForestRegressor(
                n_estimators=200,
                max_depth=15,
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=42,
            ),
            "gradient_boosting": GradientBoostingRegressor(
                n_estimators=200,
                learning_rate=0.1,
                max_depth=8,
                min_samples_split=5,
                random_state=42,
            ),
            "xgboost": XGBRegressor(
                n_estimators=200,
                learning_rate=0.1,
                max_depth=8,
                subsample=0.8,
                colsample_bytree=0.8,
                random_state=42,
            ),
            "lightgbm": LGBMRegressor(
                n_estimators=200,
                learning_rate=0.1,
                max_depth=8,
                subsample=0.8,
                colsample_bytree=0.8,
                random_state=42,
                verbose=-1,
            ),
            # ì„ í˜• ëª¨ë¸ë“¤
            "ridge": Ridge(alpha=1.0),
            "elastic_net": ElasticNet(alpha=0.1, l1_ratio=0.5),
            # ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹ 
            "svr": SVR(kernel="rbf", C=1.0, gamma="scale"),
        }

        print(f"âœ… {len(self.models)}ê°œ ëª¨ë¸ ìƒì„± ì™„ë£Œ")

    def prepare_ensemble_data(
        self, multimodal_data: Dict, targets: np.ndarray
    ) -> Tuple[np.ndarray, np.ndarray]:
        """ì•™ìƒë¸”ìš© ë°ì´í„° ì¤€ë¹„"""
        print("ğŸ”„ ì•™ìƒë¸” ë°ì´í„° ì¤€ë¹„ ì¤‘...")

        # ëª¨ë“  ëª¨ë‹¬ë¦¬í‹°ë¥¼ í•˜ë‚˜ì˜ í–‰ë ¬ë¡œ ê²°í•©
        X = np.concatenate(
            [
                multimodal_data["big5"],
                multimodal_data["cmi"],
                multimodal_data["rppg"],
                multimodal_data["voice"],
            ],
            axis=1,
        )

        # RobustScalerë¡œ ì •ê·œí™”
        scaler = RobustScaler()
        X_scaled = scaler.fit_transform(X)
        self.scalers["ensemble"] = scaler

        print(f"âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {X_scaled.shape}")
        return X_scaled, targets

    def train_individual_models(self, X: np.ndarray, y: np.ndarray) -> Dict:
        """ê°œë³„ ëª¨ë¸ í›ˆë ¨"""
        print("ğŸš€ ê°œë³„ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")

        model_scores = {}

        for name, model in self.models.items():
            print(f"   í›ˆë ¨ ì¤‘: {name}")

            try:
                # ëª¨ë¸ í›ˆë ¨
                model.fit(X, y)

                # êµì°¨ ê²€ì¦ ì ìˆ˜
                cv_scores = cross_val_score(model, X, y, cv=5, scoring="r2")
                avg_score = cv_scores.mean()
                std_score = cv_scores.std()

                model_scores[name] = {
                    "cv_mean": avg_score,
                    "cv_std": std_score,
                    "model": model,
                }

                print(f"     RÂ²: {avg_score:.4f} (Â±{std_score:.4f})")

            except Exception as e:
                print(f"     âŒ í›ˆë ¨ ì‹¤íŒ¨: {str(e)}")
                model_scores[name] = None

        # ì„±ëŠ¥ ìˆœìœ¼ë¡œ ì •ë ¬
        valid_models = {k: v for k, v in model_scores.items() if v is not None}
        sorted_models = sorted(
            valid_models.items(), key=lambda x: x[1]["cv_mean"], reverse=True
        )

        print(f"âœ… {len(valid_models)}ê°œ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
        print("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ìˆœìœ„:")
        for i, (name, scores) in enumerate(sorted_models[:5], 1):
            print(f"   {i}. {name}: RÂ² = {scores['cv_mean']:.4f}")

        return model_scores

    def optimize_ensemble_weights(
        self, X: np.ndarray, y: np.ndarray, model_scores: Dict
    ) -> np.ndarray:
        """ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ìµœì í™”"""
        print("ğŸ”„ ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ìµœì í™” ì¤‘...")

        # ìœ íš¨í•œ ëª¨ë¸ë“¤ë§Œ ì„ íƒ
        valid_models = {k: v for k, v in model_scores.items() if v is not None}

        if len(valid_models) < 2:
            print("âŒ ì•™ìƒë¸”ì„ ìœ„í•œ ì¶©ë¶„í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None

        # ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ ìƒì„±
        predictions = {}
        for name, scores in valid_models.items():
            model = scores["model"]
            pred = model.predict(X)
            predictions[name] = pred

        # ê°€ì¤‘ì¹˜ ìµœì í™” (ê°„ë‹¨í•œ ë°©ë²•: ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ì¹˜)
        weights = []
        for name in valid_models.keys():
            score = valid_models[name]["cv_mean"]
            weights.append(score)

        # ì •ê·œí™”
        weights = np.array(weights)
        weights = weights / weights.sum()

        self.ensemble_weights = dict(zip(valid_models.keys(), weights))

        print("âœ… ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ìµœì í™” ì™„ë£Œ:")
        for name, weight in self.ensemble_weights.items():
            print(f"   {name}: {weight:.4f}")

        return weights

    def create_ensemble_predictions(
        self, X: np.ndarray, model_scores: Dict
    ) -> np.ndarray:
        """ì•™ìƒë¸” ì˜ˆì¸¡ ìƒì„±"""
        if self.ensemble_weights is None:
            print("âŒ ì•™ìƒë¸” ê°€ì¤‘ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        # ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ ìƒì„±
        predictions = []
        weights = []

        for name, weight in self.ensemble_weights.items():
            if name in model_scores and model_scores[name] is not None:
                model = model_scores[name]["model"]
                pred = model.predict(X)
                predictions.append(pred)
                weights.append(weight)

        if not predictions:
            print("âŒ ìœ íš¨í•œ ì˜ˆì¸¡ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None

        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì•™ìƒë¸” ì˜ˆì¸¡
        predictions = np.array(predictions)
        weights = np.array(weights)

        ensemble_pred = np.average(predictions, axis=0, weights=weights)

        return ensemble_pred

    def evaluate_ensemble(
        self, X: np.ndarray, y: np.ndarray, model_scores: Dict
    ) -> Dict:
        """ì•™ìƒë¸” ì„±ëŠ¥ í‰ê°€"""
        print("ğŸ“Š ì•™ìƒë¸” ì„±ëŠ¥ í‰ê°€ ì¤‘...")

        # ì•™ìƒë¸” ì˜ˆì¸¡
        ensemble_pred = self.create_ensemble_predictions(X, model_scores)

        if ensemble_pred is None:
            return None

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°
        r2 = r2_score(y, ensemble_pred)
        mse = mean_squared_error(y, ensemble_pred)
        rmse = np.sqrt(mse)
        mae = np.mean(np.abs(ensemble_pred - y))
        correlation = np.corrcoef(ensemble_pred, y)[0, 1]

        results = {
            "r2": r2,
            "mse": mse,
            "rmse": rmse,
            "mae": mae,
            "correlation": correlation,
            "predictions": ensemble_pred,
            "targets": y,
            "ensemble_weights": self.ensemble_weights,
        }

        print(f"âœ… ì•™ìƒë¸” í‰ê°€ ì™„ë£Œ:")
        print(f"   RÂ²: {r2:.4f}")
        print(f"   RMSE: {rmse:.4f}")
        print(f"   MAE: {mae:.4f}")
        print(f"   ìƒê´€ê³„ìˆ˜: {correlation:.4f}")

        return results

    def run_ensemble_optimization(
        self, multimodal_data: Dict, targets: np.ndarray
    ) -> Dict:
        """ì•™ìƒë¸” ìµœì í™” ì‹¤í–‰"""
        print("ğŸš€ ì•™ìƒë¸” ìµœì í™” ì‹œìŠ¤í…œ ì‹œì‘")
        print("=" * 60)

        # 1. ë‹¤ì–‘í•œ ëª¨ë¸ ìƒì„±
        self.create_diverse_models()

        # 2. ë°ì´í„° ì¤€ë¹„
        X, y = self.prepare_ensemble_data(multimodal_data, targets)

        # 3. ê°œë³„ ëª¨ë¸ í›ˆë ¨
        model_scores = self.train_individual_models(X, y)

        # 4. ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ìµœì í™”
        weights = self.optimize_ensemble_weights(X, y, model_scores)

        # 5. ì•™ìƒë¸” ì„±ëŠ¥ í‰ê°€
        ensemble_results = self.evaluate_ensemble(X, y, model_scores)

        # 6. ê²°ê³¼ ì €ì¥
        results = {
            "individual_models": {
                name: {
                    "cv_mean": scores["cv_mean"] if scores else None,
                    "cv_std": scores["cv_std"] if scores else None,
                }
                for name, scores in model_scores.items()
            },
            "ensemble_results": ensemble_results,
            "ensemble_weights": self.ensemble_weights,
            "data_info": {
                "n_samples": len(y),
                "n_features": X.shape[1],
                "n_models": len([m for m in model_scores.values() if m is not None]),
            },
        }

        # JSONìœ¼ë¡œ ì €ì¥
        with open("ensemble_optimization_results.json", "w") as f:

            def convert_to_json_serializable(obj):
                if isinstance(obj, np.ndarray):
                    return obj.tolist()
                elif isinstance(obj, np.float32):
                    return float(obj)
                elif isinstance(obj, np.float64):
                    return float(obj)
                elif isinstance(obj, np.int32):
                    return int(obj)
                elif isinstance(obj, np.int64):
                    return int(obj)
                elif isinstance(obj, dict):
                    return {k: convert_to_json_serializable(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [convert_to_json_serializable(item) for item in obj]
                else:
                    return obj

            json_results = convert_to_json_serializable(results)
            json.dump(json_results, f, indent=2)

        print(f"âœ… ì•™ìƒë¸” ìµœì í™” ì™„ë£Œ!")
        if ensemble_results:
            print(f"   ìµœì¢… RÂ²: {ensemble_results['r2']:.4f}")
            print(f"   ìµœì¢… RMSE: {ensemble_results['rmse']:.4f}")

        return results


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ì•™ìƒë¸” ìµœì í™” ì‹œìŠ¤í…œ - RÂ² 0.70+ ë„ì „")
    print("=" * 60)

    # ê¸°ì¡´ ë°ì´í„° ë¡œë” ì‚¬ìš©
    from advanced_multimodal_training import BigQueryDataLoader

    # ë°ì´í„° ë¡œë”©
    data_loader = BigQueryDataLoader()
    multimodal_data, targets = data_loader.load_competition_data(10000)

    # ì•™ìƒë¸” ìµœì í™” ì‹¤í–‰
    optimizer = EnsembleOptimizer()
    results = optimizer.run_ensemble_optimization(multimodal_data, targets)

    print("\nğŸ“Š ì•™ìƒë¸” ìµœì í™” ê²°ê³¼:")
    if results["ensemble_results"]:
        print(f"   ì•™ìƒë¸” RÂ²: {results['ensemble_results']['r2']:.4f}")
        print(f"   ì•™ìƒë¸” RMSE: {results['ensemble_results']['rmse']:.4f}")
        print(f"   ìƒê´€ê³„ìˆ˜: {results['ensemble_results']['correlation']:.4f}")


if __name__ == "__main__":
    main()
