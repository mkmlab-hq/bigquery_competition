import json
import os
import warnings
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
from sklearn.linear_model import Lasso, Ridge
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

warnings.filterwarnings("ignore")


class EnsembleMultimodalModel:
    """ì•™ìƒë¸” ë©€í‹°ëª¨ë‹¬ ëª¨ë¸"""

    def __init__(self, device="cpu"):
        self.device = device
        self.models = {}
        self.scalers = {}
        self.weights = {}

    def add_neural_network_model(
        self, name: str, model: nn.Module, weight: float = 1.0
    ):
        """ì‹ ê²½ë§ ëª¨ë¸ ì¶”ê°€"""
        self.models[name] = {"type": "neural_network", "model": model, "weight": weight}

    def add_sklearn_model(self, name: str, model, weight: float = 1.0):
        """Scikit-learn ëª¨ë¸ ì¶”ê°€"""
        self.models[name] = {"type": "sklearn", "model": model, "weight": weight}

    def train_models(
        self, X_train: Dict, y_train: np.ndarray, X_val: Dict, y_val: np.ndarray
    ):
        """ëª¨ë“  ëª¨ë¸ í›ˆë ¨"""

        print("ğŸš€ ì•™ìƒë¸” ëª¨ë¸ í›ˆë ¨ ì‹œì‘!")

        # ë°ì´í„° ì •ê·œí™”
        for modality in ["big5", "cmi", "rppg", "voice"]:
            scaler = StandardScaler()
            X_train[modality] = scaler.fit_transform(X_train[modality])
            X_val[modality] = scaler.transform(X_val[modality])
            self.scalers[modality] = scaler

        # ëª¨ë“  ëª¨ë‹¬ë¦¬í‹° ê²°í•©
        X_train_combined = np.concatenate(
            [X_train["big5"], X_train["cmi"], X_train["rppg"], X_train["voice"]], axis=1
        )
        X_val_combined = np.concatenate(
            [X_val["big5"], X_val["cmi"], X_val["rppg"], X_val["voice"]], axis=1
        )

        # ê° ëª¨ë¸ í›ˆë ¨
        for name, model_info in self.models.items():
            print(f"ğŸ“š {name} ëª¨ë¸ í›ˆë ¨ ì¤‘...")

            if model_info["type"] == "neural_network":
                # ì‹ ê²½ë§ ëª¨ë¸ í›ˆë ¨
                self._train_neural_network(
                    name, model_info, X_train, y_train, X_val, y_val
                )
            else:
                # Scikit-learn ëª¨ë¸ í›ˆë ¨
                self._train_sklearn_model(
                    name, model_info, X_train_combined, y_train, X_val_combined, y_val
                )

        # ê°€ì¤‘ì¹˜ ìµœì í™”
        self._optimize_weights(X_val, y_val)

        print("âœ… ì•™ìƒë¸” ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")

    def _train_neural_network(
        self,
        name: str,
        model_info: Dict,
        X_train: Dict,
        y_train: np.ndarray,
        X_val: Dict,
        y_val: np.ndarray,
    ):
        """ì‹ ê²½ë§ ëª¨ë¸ í›ˆë ¨"""
        model = model_info["model"]
        model.to(self.device)

        # ì˜µí‹°ë§ˆì´ì € ë° ì†ì‹¤ í•¨ìˆ˜
        optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)
        criterion = nn.MSELoss()

        # ë°ì´í„°ì…‹ ìƒì„±
        from torch.utils.data import DataLoader

        from transfer_learning_multimodal import TransferLearningMultimodalDataset

        train_dataset = TransferLearningMultimodalDataset(
            X_train["big5"],
            X_train["cmi"],
            X_train["rppg"],
            X_train["voice"],
            y_train,
            augment=False,
        )
        val_dataset = TransferLearningMultimodalDataset(
            X_val["big5"],
            X_val["cmi"],
            X_val["rppg"],
            X_val["voice"],
            y_val,
            augment=False,
        )

        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)

        # í›ˆë ¨
        best_val_r2 = -float("inf")
        patience = 5
        patience_counter = 0

        for epoch in range(20):
            # í›ˆë ¨
            model.train()
            train_loss = 0
            for batch in train_loader:
                optimizer.zero_grad()

                big5 = batch["big5"].to(self.device)
                cmi = batch["cmi"].to(self.device)
                rppg = batch["rppg"].to(self.device)
                voice = batch["voice"].to(self.device)
                targets = batch["target"].to(self.device)

                predictions = model(big5, cmi, rppg, voice)
                loss = criterion(predictions, targets)

                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                optimizer.step()

                train_loss += loss.item()

            # ê²€ì¦
            model.eval()
            val_predictions = []
            val_targets = []

            with torch.no_grad():
                for batch in val_loader:
                    big5 = batch["big5"].to(self.device)
                    cmi = batch["cmi"].to(self.device)
                    rppg = batch["rppg"].to(self.device)
                    voice = batch["voice"].to(self.device)
                    targets = batch["target"].to(self.device)

                    predictions = model(big5, cmi, rppg, voice)
                    val_predictions.extend(predictions.cpu().numpy().flatten())
                    val_targets.extend(targets.cpu().numpy().flatten())

            val_r2 = r2_score(val_targets, val_predictions)

            if val_r2 > best_val_r2:
                best_val_r2 = val_r2
                patience_counter = 0
                # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
                model_info["best_state"] = model.state_dict().copy()
            else:
                patience_counter += 1

            if patience_counter >= patience:
                break

        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë³µì›
        if "best_state" in model_info:
            model.load_state_dict(model_info["best_state"])

        print(f"  {name} ìµœê³  RÂ²: {best_val_r2:.4f}")

    def _train_sklearn_model(
        self,
        name: str,
        model_info: Dict,
        X_train: np.ndarray,
        y_train: np.ndarray,
        X_val: np.ndarray,
        y_val: np.ndarray,
    ):
        """Scikit-learn ëª¨ë¸ í›ˆë ¨"""
        model = model_info["model"]

        # í›ˆë ¨
        model.fit(X_train, y_train)

        # ê²€ì¦
        val_predictions = model.predict(X_val)
        val_r2 = r2_score(y_val, val_predictions)

        print(f"  {name} RÂ²: {val_r2:.4f}")

    def _optimize_weights(self, X_val: Dict, y_val: np.ndarray):
        """ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ìµœì í™”"""
        print("âš–ï¸ ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ìµœì í™” ì¤‘...")

        # ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ ìˆ˜ì§‘
        predictions = {}

        for name, model_info in self.models.items():
            if model_info["type"] == "neural_network":
                # ì‹ ê²½ë§ ëª¨ë¸ ì˜ˆì¸¡
                model = model_info["model"]
                model.eval()

                from torch.utils.data import DataLoader

                from transfer_learning_multimodal import (
                    TransferLearningMultimodalDataset,
                )

                val_dataset = TransferLearningMultimodalDataset(
                    X_val["big5"],
                    X_val["cmi"],
                    X_val["rppg"],
                    X_val["voice"],
                    y_val,
                    augment=False,
                )
                val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)

                val_predictions = []
                with torch.no_grad():
                    for batch in val_loader:
                        big5 = batch["big5"].to(self.device)
                        cmi = batch["cmi"].to(self.device)
                        rppg = batch["rppg"].to(self.device)
                        voice = batch["voice"].to(self.device)

                        pred = model(big5, cmi, rppg, voice)
                        val_predictions.extend(pred.cpu().numpy().flatten())

                predictions[name] = np.array(val_predictions)
            else:
                # Scikit-learn ëª¨ë¸ ì˜ˆì¸¡
                X_val_combined = np.concatenate(
                    [X_val["big5"], X_val["cmi"], X_val["rppg"], X_val["voice"]], axis=1
                )

                predictions[name] = model_info["model"].predict(X_val_combined)

        # ê°€ì¤‘ì¹˜ ìµœì í™” (ê°„ë‹¨í•œ ë°©ë²•: ê° ëª¨ë¸ì˜ RÂ² ì ìˆ˜ ê¸°ë°˜)
        weights = {}
        for name, pred in predictions.items():
            r2 = r2_score(y_val, pred)
            weights[name] = max(0, r2)  # ìŒìˆ˜ RÂ²ëŠ” 0ìœ¼ë¡œ ì„¤ì •

        # ì •ê·œí™”
        total_weight = sum(weights.values())
        if total_weight > 0:
            for name in weights:
                weights[name] /= total_weight
        else:
            # ëª¨ë“  ê°€ì¤‘ì¹˜ê°€ 0ì´ë©´ ê· ë“± ë¶„ë°°
            for name in weights:
                weights[name] = 1.0 / len(weights)

        self.weights = weights
        print(f"âœ… ìµœì  ê°€ì¤‘ì¹˜: {weights}")

    def predict(self, X: Dict) -> np.ndarray:
        """ì•™ìƒë¸” ì˜ˆì¸¡"""
        predictions = {}

        for name, model_info in self.models.items():
            if model_info["type"] == "neural_network":
                # ì‹ ê²½ë§ ëª¨ë¸ ì˜ˆì¸¡
                model = model_info["model"]
                model.eval()

                from torch.utils.data import DataLoader

                from transfer_learning_multimodal import (
                    TransferLearningMultimodalDataset,
                )

                dataset = TransferLearningMultimodalDataset(
                    X["big5"],
                    X["cmi"],
                    X["rppg"],
                    X["voice"],
                    np.zeros(len(X["big5"])),
                    augment=False,
                )
                dataloader = DataLoader(dataset, batch_size=64, shuffle=False)

                pred = []
                with torch.no_grad():
                    for batch in dataloader:
                        big5 = batch["big5"].to(self.device)
                        cmi = batch["cmi"].to(self.device)
                        rppg = batch["rppg"].to(self.device)
                        voice = batch["voice"].to(self.device)

                        p = model(big5, cmi, rppg, voice)
                        pred.extend(p.cpu().numpy().flatten())

                predictions[name] = np.array(pred)
            else:
                # Scikit-learn ëª¨ë¸ ì˜ˆì¸¡
                X_combined = np.concatenate(
                    [X["big5"], X["cmi"], X["rppg"], X["voice"]], axis=1
                )

                predictions[name] = model_info["model"].predict(X_combined)

        # ê°€ì¤‘ í‰ê· 
        ensemble_pred = np.zeros(len(predictions[list(predictions.keys())[0]]))
        for name, pred in predictions.items():
            ensemble_pred += self.weights[name] * pred

        return ensemble_pred


def create_ensemble_models():
    """ì•™ìƒë¸” ëª¨ë¸ ìƒì„±"""

    print("ğŸ¯ ì•™ìƒë¸” ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ ìƒì„±!")

    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")

    # ì•™ìƒë¸” ëª¨ë¸ ìƒì„±
    ensemble = EnsembleMultimodalModel(device)

    # 1. ì‹ ê²½ë§ ëª¨ë¸ë“¤ ì¶”ê°€
    from transfer_learning_multimodal import TransferLearningMultimodalNet

    # ëª¨ë¸ 1: ê¸°ë³¸ ì „ì´ í•™ìŠµ ëª¨ë¸
    model1 = TransferLearningMultimodalNet(
        hidden_dim=256, dropout_rate=0.3, use_pretrained=False
    )
    ensemble.add_neural_network_model("neural_net_1", model1, weight=1.0)

    # ëª¨ë¸ 2: ë‹¤ë¥¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°
    model2 = TransferLearningMultimodalNet(
        hidden_dim=128, dropout_rate=0.4, use_pretrained=False
    )
    ensemble.add_neural_network_model("neural_net_2", model2, weight=1.0)

    # 2. Scikit-learn ëª¨ë¸ë“¤ ì¶”ê°€
    ensemble.add_sklearn_model(
        "random_forest",
        RandomForestRegressor(n_estimators=100, random_state=42),
        weight=1.0,
    )
    ensemble.add_sklearn_model(
        "gradient_boosting",
        GradientBoostingRegressor(n_estimators=100, random_state=42),
        weight=1.0,
    )
    ensemble.add_sklearn_model("ridge", Ridge(alpha=1.0), weight=1.0)
    ensemble.add_sklearn_model("lasso", Lasso(alpha=0.1), weight=1.0)

    return ensemble


def test_ensemble_model():
    """ì•™ìƒë¸” ëª¨ë¸ í…ŒìŠ¤íŠ¸"""

    print("ğŸ§ª ì•™ìƒë¸” ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘!")

    # ë°ì´í„° ìƒì„± (ì‹¤ì œ ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜)
    np.random.seed(42)
    n_samples = 5000

    big5_data = np.random.beta(2, 2, (n_samples, 5))
    cmi_data = np.random.beta(1.5, 1.5, (n_samples, 20))
    rppg_data = np.random.normal(0, 1, (n_samples, 10))
    voice_data = np.random.normal(0, 1, (n_samples, 20))

    # íƒ€ê²Ÿ ìƒì„±
    targets = (
        0.25 * big5_data[:, 0]
        + 0.20 * big5_data[:, 1]
        + 0.15 * big5_data[:, 2]
        + 0.20 * big5_data[:, 3]
        + 0.10 * big5_data[:, 4]
        + 0.05 * np.mean(cmi_data, axis=1)
        + 0.03 * np.mean(rppg_data, axis=1)
        + 0.02 * np.mean(voice_data, axis=1)
        + np.random.normal(0, 0.15, n_samples)
    )

    targets = (targets - targets.min()) / (targets.max() - targets.min())

    # ë°ì´í„° ë¶„í• 
    train_idx, test_idx = train_test_split(
        range(len(targets)), test_size=0.3, random_state=42
    )
    train_idx, val_idx = train_test_split(train_idx, test_size=0.2, random_state=42)

    X_train = {
        "big5": big5_data[train_idx],
        "cmi": cmi_data[train_idx],
        "rppg": rppg_data[train_idx],
        "voice": voice_data[train_idx],
    }
    X_val = {
        "big5": big5_data[val_idx],
        "cmi": cmi_data[val_idx],
        "rppg": rppg_data[val_idx],
        "voice": voice_data[val_idx],
    }
    X_test = {
        "big5": big5_data[test_idx],
        "cmi": cmi_data[test_idx],
        "rppg": rppg_data[test_idx],
        "voice": voice_data[test_idx],
    }

    y_train = targets[train_idx]
    y_val = targets[val_idx]
    y_test = targets[test_idx]

    print(f"í›ˆë ¨ ë°ì´í„°: {len(y_train)}ê°œ")
    print(f"ê²€ì¦ ë°ì´í„°: {len(y_val)}ê°œ")
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(y_test)}ê°œ")

    # ì•™ìƒë¸” ëª¨ë¸ ìƒì„± ë° í›ˆë ¨
    ensemble = create_ensemble_models()
    ensemble.train_models(X_train, y_train, X_val, y_val)

    # í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡
    test_predictions = ensemble.predict(X_test)

    # ì„±ëŠ¥ í‰ê°€
    test_r2 = r2_score(y_test, test_predictions)
    test_rmse = np.sqrt(mean_squared_error(y_test, test_predictions))
    test_mae = mean_absolute_error(y_test, test_predictions)

    print("\nğŸ“Š ì•™ìƒë¸” ëª¨ë¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    print(f"  í…ŒìŠ¤íŠ¸ RÂ²: {test_r2:.4f}")
    print(f"  í…ŒìŠ¤íŠ¸ RMSE: {test_rmse:.4f}")
    print(f"  í…ŒìŠ¤íŠ¸ MAE: {test_mae:.4f}")

    # ê²°ê³¼ ì €ì¥
    results = {
        "ensemble_test": {
            "test_r2": test_r2,
            "test_rmse": test_rmse,
            "test_mae": test_mae,
            "model_count": len(ensemble.models),
            "weights": ensemble.weights,
        }
    }

    with open("ensemble_test_results.json", "w") as f:
        json.dump(results, f, indent=2)

    print("âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ!")
    print("ğŸ“ ensemble_test_results.json")

    return results


if __name__ == "__main__":
    results = test_ensemble_model()


