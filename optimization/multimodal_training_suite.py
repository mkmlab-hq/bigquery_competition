#!/usr/bin/env python3
"""
ë©€í‹°ëª¨ë‹¬ í›ˆë ¨ í†µí•© ìŠ¤ìœ„íŠ¸
- ëª¨ë“  ë©€í‹°ëª¨ë‹¬ í›ˆë ¨ ì‹œìŠ¤í…œ í†µí•©
- ìë™í™”ëœ í›ˆë ¨ íŒŒì´í”„ë¼ì¸
- ì„±ëŠ¥ ë¹„êµ ë° ë²¤ì¹˜ë§ˆí‚¹
"""

import json
import os
import subprocess
import sys
import time
import warnings
from typing import Any, Dict, List, Optional, Tuple

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from tqdm import tqdm

warnings.filterwarnings("ignore", category=UserWarning)


class MultimodalTrainingSuite:
    """ë©€í‹°ëª¨ë‹¬ í›ˆë ¨ í†µí•© ìŠ¤ìœ„íŠ¸"""

    def __init__(self, project_id: str = "persona-diary-service"):
        self.project_id = project_id
        self.training_results = {}
        self.performance_comparison = {}

        print("ğŸš€ ë©€í‹°ëª¨ë‹¬ í›ˆë ¨ í†µí•© ìŠ¤ìœ„íŠ¸ ì´ˆê¸°í™”")
        print("=" * 60)

    def check_dependencies(self) -> Dict[str, bool]:
        """ì˜ì¡´ì„± í™•ì¸"""
        print("ğŸ” ì˜ì¡´ì„± í™•ì¸ ì¤‘...")

        dependencies = {
            "torch": False,
            "sklearn": False,
            "pandas": False,
            "numpy": False,
            "matplotlib": False,
            "seaborn": False,
            "tqdm": False,
        }

        for dep in dependencies.keys():
            try:
                __import__(dep)
                dependencies[dep] = True
                print(f"   âœ… {dep}")
            except ImportError:
                print(f"   âŒ {dep}")

        return dependencies

    def run_advanced_training(self, n_samples: int = 10000, epochs: int = 100) -> Dict:
        """ê³ ê¸‰ ë©€í‹°ëª¨ë‹¬ í›ˆë ¨ ì‹¤í–‰"""
        print("\nğŸ§  ê³ ê¸‰ ë©€í‹°ëª¨ë‹¬ í›ˆë ¨ ì‹¤í–‰")
        print("-" * 40)

        try:
            # advanced_multimodal_training.py ì‹¤í–‰
            result = subprocess.run(
                [sys.executable, "f:\\workspace\\bigquery_competition\\optimization\\advanced_multimodal_training.py"],
                capture_output=True,
                text=True,
                timeout=1800,
                encoding="utf-8",  # Explicitly set encoding to UTF-8
                errors="replace"  # Replace invalid characters
            )  # 30ë¶„ íƒ€ì„ì•„ì›ƒ

            if result.returncode == 0:
                print("âœ… ê³ ê¸‰ í›ˆë ¨ ì™„ë£Œ")

                # ê²°ê³¼ íŒŒì¼ í™•ì¸
                if os.path.exists("multimodal_training_results.json"):
                    with open("multimodal_training_results.json", "r") as f:
                        training_data = json.load(f)

                    self.training_results["advanced_training"] = {
                        "status": "success",
                        "r2_score": training_data["evaluation_results"]["r2"],
                        "rmse": training_data["evaluation_results"]["rmse"],
                        "mae": training_data["evaluation_results"]["mae"],
                        "modality_weights": training_data["evaluation_results"][
                            "modality_weights"
                        ],
                        "epochs_trained": training_data["training_results"][
                            "total_epochs"
                        ],
                    }
                else:
                    self.training_results["advanced_training"] = {
                        "status": "completed_but_no_results_file"
                    }
            else:
                print(f"âŒ ê³ ê¸‰ í›ˆë ¨ ì‹¤íŒ¨: {result.stderr}")
                self.training_results["advanced_training"] = {
                    "status": "failed",
                    "error": result.stderr,
                }

        except subprocess.TimeoutExpired:
            print("â° ê³ ê¸‰ í›ˆë ¨ íƒ€ì„ì•„ì›ƒ (30ë¶„)")
            self.training_results["advanced_training"] = {"status": "timeout"}
        except Exception as e:
            print(f"âŒ ê³ ê¸‰ í›ˆë ¨ ì˜¤ë¥˜: {e}")
            self.training_results["advanced_training"] = {
                "status": "error",
                "error": str(e),
            }

    def run_realtime_learning(self, n_samples: int = 1000) -> Dict:
        """ì‹¤ì‹œê°„ í•™ìŠµ ì‹¤í–‰"""
        print("\nâš¡ ì‹¤ì‹œê°„ í•™ìŠµ ì‹¤í–‰")
        print("-" * 40)

        try:
            # real_time_multimodal_learning.py ì‹¤í–‰
            result = subprocess.run(
                [sys.executable, "f:\\workspace\\bigquery_competition\\optimization\\real_time_multimodal_learning.py"],
                capture_output=True,
                text=True,
                timeout=600,
                encoding="utf-8",
                errors="replace"
            )  # 10ë¶„ íƒ€ì„ì•„ì›ƒ

            if result.returncode == 0:
                print("âœ… ì‹¤ì‹œê°„ í•™ìŠµ ì™„ë£Œ")
                self.training_results["realtime_learning"] = {
                    "status": "success",
                    "output": result.stdout,
                }
            else:
                print(f"âŒ ì‹¤ì‹œê°„ í•™ìŠµ ì‹¤íŒ¨: {result.stderr}")
                self.training_results["realtime_learning"] = {
                    "status": "failed",
                    "error": result.stderr,
                }

        except subprocess.TimeoutExpired:
            print("â° ì‹¤ì‹œê°„ í•™ìŠµ íƒ€ì„ì•„ì›ƒ (10ë¶„)")
            self.training_results["realtime_learning"] = {"status": "timeout"}
        except Exception as e:
            print(f"âŒ ì‹¤ì‹œê°„ í•™ìŠµ ì˜¤ë¥˜: {e}")
            self.training_results["realtime_learning"] = {
                "status": "error",
                "error": str(e),
            }

    def run_performance_optimization(
        self, n_samples: int = 50000, epochs: int = 50
    ) -> Dict:
        """ì„±ëŠ¥ ìµœì í™” ì‹¤í–‰"""
        print("\nâš¡ ì„±ëŠ¥ ìµœì í™” ì‹¤í–‰")
        print("-" * 40)

        try:
            # multimodal_performance_optimizer.py ì‹¤í–‰
            result = subprocess.run(
                [sys.executable, "f:\\workspace\\bigquery_competition\\optimization\\multimodal_performance_optimizer.py"],
                capture_output=True,
                text=True,
                timeout=1800,
                encoding="utf-8",
                errors="replace"
            )  # 30ë¶„ íƒ€ì„ì•„ì›ƒ

            if result.returncode == 0:
                print("âœ… ì„±ëŠ¥ ìµœì í™” ì™„ë£Œ")

                # ê²°ê³¼ íŒŒì¼ í™•ì¸
                if os.path.exists("multimodal_optimization_results.json"):
                    with open("multimodal_optimization_results.json", "r") as f:
                        optimization_data = json.load(f)

                    self.training_results["performance_optimization"] = {
                        "status": "success",
                        "torchscript_throughput": optimization_data[
                            "optimization_results"
                        ]["torchscript_inference"]["throughput"],
                        "speedup": optimization_data["optimization_results"][
                            "torchscript_inference"
                        ]["speedup"],
                        "optimal_batch_size": optimization_data["optimization_results"][
                            "batch_optimization"
                        ]["optimal_batch_size"],
                        "memory_usage_mb": optimization_data["optimization_results"][
                            "memory_usage_mb"
                        ],
                    }
                else:
                    self.training_results["performance_optimization"] = {
                        "status": "completed_but_no_results_file"
                    }
            else:
                print(f"âŒ ì„±ëŠ¥ ìµœì í™” ì‹¤íŒ¨: {result.stderr}")
                self.training_results["performance_optimization"] = {
                    "status": "failed",
                    "error": result.stderr,
                }

        except subprocess.TimeoutExpired:
            print("â° ì„±ëŠ¥ ìµœì í™” íƒ€ì„ì•„ì›ƒ (30ë¶„)")
            self.training_results["performance_optimization"] = {"status": "timeout"}
        except Exception as e:
            print(f"âŒ ì„±ëŠ¥ ìµœì í™” ì˜¤ë¥˜: {e}")
            self.training_results["performance_optimization"] = {
                "status": "error",
                "error": str(e),
            }

    def create_comprehensive_comparison(
        self, save_path: str = "multimodal_training_comparison.png"
    ):
        """ì¢…í•© ë¹„êµ ë¶„ì„ ìƒì„±"""
        print("\nğŸ“Š ì¢…í•© ë¹„êµ ë¶„ì„ ìƒì„± ì¤‘...")

        # ì„±ê³µí•œ í›ˆë ¨ ê²°ê³¼ë§Œ í•„í„°ë§
        successful_results = {
            k: v
            for k, v in self.training_results.items()
            if v.get("status") == "success"
        }

        if not successful_results:
            print("âŒ ì„±ê³µí•œ í›ˆë ¨ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        fig, axes = plt.subplots(2, 3, figsize=(18, 12))

        # 1. í›ˆë ¨ ìƒíƒœ ìš”ì•½
        axes[0, 0].axis("off")
        status_summary = []
        for method, result in self.training_results.items():
            status = result.get("status", "unknown")
            status_summary.append(f"{method.replace('_', ' ').title()}: {status}")

        axes[0, 0].text(
            0.1,
            0.9,
            "\n".join(status_summary),
            transform=axes[0, 0].transAxes,
            fontsize=12,
            verticalalignment="top",
            fontfamily="monospace",
        )
        axes[0, 0].set_title("Training Status Summary")

        # 2. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¹„êµ (ê³ ê¸‰ í›ˆë ¨ì´ ìˆëŠ” ê²½ìš°)
        if "advanced_training" in successful_results:
            metrics = ["r2_score", "rmse", "mae"]
            values = [
                successful_results["advanced_training"].get(metric, 0)
                for metric in metrics
            ]

            axes[0, 1].bar(metrics, values)
            axes[0, 1].set_title("Advanced Training Performance")
            axes[0, 1].set_ylabel("Value")
            axes[0, 1].tick_params(axis="x", rotation=45)

            # ê°’ í‘œì‹œ
            for i, v in enumerate(values):
                axes[0, 1].text(
                    i, v + max(values) * 0.01, f"{v:.3f}", ha="center", va="bottom"
                )

        # 3. ëª¨ë‹¬ë¦¬í‹° ê°€ì¤‘ì¹˜ (ê³ ê¸‰ í›ˆë ¨ì´ ìˆëŠ” ê²½ìš°)
        if "advanced_training" in successful_results:
            modality_weights = successful_results["advanced_training"].get(
                "modality_weights", {}
            )
            if modality_weights:
                modalities = list(modality_weights.keys())
                weights = list(modality_weights.values())

                axes[0, 2].bar(modalities, weights)
                axes[0, 2].set_title("Modality Weights")
                axes[0, 2].set_ylabel("Weight")
                axes[0, 2].tick_params(axis="x", rotation=45)

        # 4. ì„±ëŠ¥ ìµœì í™” ê²°ê³¼ (ì„±ëŠ¥ ìµœì í™”ê°€ ìˆëŠ” ê²½ìš°)
        if "performance_optimization" in successful_results:
            opt_results = successful_results["performance_optimization"]

            # ì¶”ë¡  ì†ë„ ë¹„êµ
            methods = ["Basic", "TorchScript"]
            throughputs = [
                opt_results.get("torchscript_throughput", 0)
                / opt_results.get("speedup", 1),
                opt_results.get("torchscript_throughput", 0),
            ]

            axes[1, 0].bar(methods, throughputs)
            axes[1, 0].set_title("Inference Speed Comparison")
            axes[1, 0].set_ylabel("Samples/Second")

            # ì†ë„ í–¥ìƒ í‘œì‹œ
            speedup = opt_results.get("speedup", 1)
            axes[1, 0].text(
                0.5,
                max(throughputs) * 0.8,
                f"Speedup: {speedup:.2f}x",
                ha="center",
                va="center",
                fontsize=12,
                bbox=dict(boxstyle="round,pad=0.3", facecolor="yellow", alpha=0.7),
            )

        # 5. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (ì„±ëŠ¥ ìµœì í™”ê°€ ìˆëŠ” ê²½ìš°)
        if "performance_optimization" in successful_results:
            memory_usage = successful_results["performance_optimization"].get(
                "memory_usage_mb", 0
            )

            axes[1, 1].bar(["Memory Usage"], [memory_usage])
            axes[1, 1].set_title("Memory Usage")
            axes[1, 1].set_ylabel("MB")
            axes[1, 1].text(
                0,
                memory_usage + memory_usage * 0.01,
                f"{memory_usage:.1f} MB",
                ha="center",
                va="bottom",
            )

        # 6. ìµœì  ë°°ì¹˜ í¬ê¸° (ì„±ëŠ¥ ìµœì í™”ê°€ ìˆëŠ” ê²½ìš°)
        if "performance_optimization" in successful_results:
            optimal_batch_size = successful_results["performance_optimization"].get(
                "optimal_batch_size", 0
            )

            axes[1, 2].bar(["Optimal Batch Size"], [optimal_batch_size])
            axes[1, 2].set_title("Optimal Batch Size")
            axes[1, 2].set_ylabel("Batch Size")
            axes[1, 2].text(
                0,
                optimal_batch_size + optimal_batch_size * 0.01,
                f"{optimal_batch_size}",
                ha="center",
                va="bottom",
            )

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches="tight")
        plt.close()

        print(f"âœ… ì¢…í•© ë¹„êµ ë¶„ì„ ì €ì¥: {save_path}")

    def generate_training_report(
        self, save_path: str = "multimodal_training_report.md"
    ):
        """í›ˆë ¨ ë³´ê³ ì„œ ìƒì„±"""
        print(f"\nğŸ“ í›ˆë ¨ ë³´ê³ ì„œ ìƒì„± ì¤‘...")

        report_content = f"""# ë©€í‹°ëª¨ë‹¬ í›ˆë ¨ í†µí•© ë³´ê³ ì„œ

## ğŸ“Š í›ˆë ¨ ê°œìš”
- **í”„ë¡œì íŠ¸ ID**: {self.project_id}
- **ìƒì„± ì‹œê°„**: {time.strftime('%Y-%m-%d %H:%M:%S')}
- **ì´ í›ˆë ¨ ë°©ë²•**: {len(self.training_results)}ê°œ

## ğŸ§  í›ˆë ¨ ê²°ê³¼ ìƒì„¸

"""

        for method, result in self.training_results.items():
            method_name = method.replace("_", " ").title()
            status = result.get("status", "unknown")

            report_content += f"### {method_name}\n"
            report_content += f"- **ìƒíƒœ**: {status}\n"

            if status == "success":
                if "r2_score" in result:
                    report_content += f"- **RÂ² Score**: {result['r2_score']:.4f}\n"
                if "rmse" in result:
                    report_content += f"- **RMSE**: {result['rmse']:.4f}\n"
                if "mae" in result:
                    report_content += f"- **MAE**: {result['mae']:.4f}\n"
                if "torchscript_throughput" in result:
                    report_content += f"- **TorchScript Throughput**: {result['torchscript_throughput']:.1f} samples/sec\n"
                if "speedup" in result:
                    report_content += f"- **Speedup**: {result['speedup']:.2f}x\n"
                if "optimal_batch_size" in result:
                    report_content += (
                        f"- **Optimal Batch Size**: {result['optimal_batch_size']}\n"
                    )
                if "memory_usage_mb" in result:
                    report_content += (
                        f"- **Memory Usage**: {result['memory_usage_mb']:.1f} MB\n"
                    )
            elif status == "failed":
                report_content += (
                    f"- **ì˜¤ë¥˜**: {result.get('error', 'Unknown error')}\n"
                )
            elif status == "timeout":
                report_content += f"- **ìƒíƒœ**: íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ì¸í•œ ì¤‘ë‹¨\n"

            report_content += "\n"

        # ì„±ê³µí•œ í›ˆë ¨ ìš”ì•½
        successful_count = sum(
            1
            for result in self.training_results.values()
            if result.get("status") == "success"
        )

        report_content += f"""## ğŸ“ˆ í›ˆë ¨ ìš”ì•½
- **ì„±ê³µí•œ í›ˆë ¨**: {successful_count}/{len(self.training_results)}ê°œ
- **ì„±ê³µë¥ **: {successful_count/len(self.training_results)*100:.1f}%

## ğŸ¯ ê¶Œì¥ì‚¬í•­

"""

        if "advanced_training" in self.training_results:
            if self.training_results["advanced_training"].get("status") == "success":
                r2_score = self.training_results["advanced_training"].get("r2_score", 0)
                if r2_score > 0.8:
                    report_content += (
                        "- âœ… ê³ ê¸‰ í›ˆë ¨ì´ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤ (RÂ² > 0.8)\n"
                    )
                elif r2_score > 0.6:
                    report_content += "- âš ï¸ ê³ ê¸‰ í›ˆë ¨ ì„±ëŠ¥ì´ ë³´í†µì…ë‹ˆë‹¤ (RÂ² > 0.6)\n"
                else:
                    report_content += (
                        "- âŒ ê³ ê¸‰ í›ˆë ¨ ì„±ëŠ¥ì´ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤ (RÂ² < 0.6)\n"
                    )

        if "performance_optimization" in self.training_results:
            if (
                self.training_results["performance_optimization"].get("status")
                == "success"
            ):
                speedup = self.training_results["performance_optimization"].get(
                    "speedup", 1
                )
                if speedup > 2.0:
                    report_content += (
                        "- âœ… ì„±ëŠ¥ ìµœì í™”ê°€ íš¨ê³¼ì ì…ë‹ˆë‹¤ (ì†ë„ í–¥ìƒ > 2x)\n"
                    )
                else:
                    report_content += "- âš ï¸ ì„±ëŠ¥ ìµœì í™” íš¨ê³¼ê°€ ì œí•œì ì…ë‹ˆë‹¤\n"

        report_content += f"""
## ğŸ“ ìƒì„±ëœ íŒŒì¼
- `multimodal_training_comparison.png`: ì¢…í•© ë¹„êµ ë¶„ì„ ì°¨íŠ¸
- `multimodal_training_results.json`: ê³ ê¸‰ í›ˆë ¨ ê²°ê³¼ (ìˆëŠ” ê²½ìš°)
- `multimodal_optimization_results.json`: ì„±ëŠ¥ ìµœì í™” ê²°ê³¼ (ìˆëŠ” ê²½ìš°)
- `realtime_performance.png`: ì‹¤ì‹œê°„ í•™ìŠµ ì„±ëŠ¥ ì°¨íŠ¸ (ìˆëŠ” ê²½ìš°)

---
*ì´ ë³´ê³ ì„œëŠ” ë©€í‹°ëª¨ë‹¬ í›ˆë ¨ í†µí•© ìŠ¤ìœ„íŠ¸ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*
"""

        with open(save_path, "w", encoding="utf-8") as f:
            f.write(report_content)

        print(f"âœ… í›ˆë ¨ ë³´ê³ ì„œ ì €ì¥: {save_path}")

    def run_comprehensive_training_suite(
        self,
        advanced_samples: int = 10000,
        realtime_samples: int = 1000,
        optimization_samples: int = 50000,
    ) -> Dict:
        """ì¢…í•© í›ˆë ¨ ìŠ¤ìœ„íŠ¸ ì‹¤í–‰"""
        print("ğŸš€ ë©€í‹°ëª¨ë‹¬ ì¢…í•© í›ˆë ¨ ìŠ¤ìœ„íŠ¸ ì‹œì‘")
        print("=" * 60)

        start_time = time.time()

        # 1. ì˜ì¡´ì„± í™•ì¸
        dependencies = self.check_dependencies()
        missing_deps = [dep for dep, status in dependencies.items() if not status]
        if missing_deps:
            print(f"âš ï¸ ëˆ„ë½ëœ ì˜ì¡´ì„±: {missing_deps}")
            print("   ì¼ë¶€ í›ˆë ¨ì´ ì‹¤íŒ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        # 2. ê³ ê¸‰ ë©€í‹°ëª¨ë‹¬ í›ˆë ¨
        self.run_advanced_training(advanced_samples)

        # 3. ì‹¤ì‹œê°„ í•™ìŠµ
        self.run_realtime_learning(realtime_samples)

        # 4. ì„±ëŠ¥ ìµœì í™”
        self.run_performance_optimization(optimization_samples)

        # 5. ì¢…í•© ë¹„êµ ë¶„ì„
        self.create_comprehensive_comparison()

        # 6. í›ˆë ¨ ë³´ê³ ì„œ ìƒì„±
        self.generate_training_report()

        total_time = time.time() - start_time

        # ìµœì¢… ê²°ê³¼
        final_results = {
            "training_results": self.training_results,
            "dependencies": dependencies,
            "total_time_minutes": total_time / 60,
            "successful_trainings": sum(
                1
                for result in self.training_results.values()
                if result.get("status") == "success"
            ),
            "total_trainings": len(self.training_results),
        }

        # JSONìœ¼ë¡œ ì €ì¥
        with open("multimodal_training_suite_results.json", "w") as f:
            json.dump(final_results, f, indent=2, default=str)

        print(f"\nğŸ‰ ì¢…í•© í›ˆë ¨ ìŠ¤ìœ„íŠ¸ ì™„ë£Œ!")
        print(f"   ì´ ì†Œìš” ì‹œê°„: {total_time/60:.1f}ë¶„")
        print(
            f"   ì„±ê³µí•œ í›ˆë ¨: {final_results['successful_trainings']}/{final_results['total_trainings']}ê°œ"
        )
        print(
            f"   ì„±ê³µë¥ : {final_results['successful_trainings']/final_results['total_trainings']*100:.1f}%"
        )

        return final_results


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ§  ë©€í‹°ëª¨ë‹¬ í›ˆë ¨ í†µí•© ìŠ¤ìœ„íŠ¸")
    print("=" * 60)

    # í›ˆë ¨ ìŠ¤ìœ„íŠ¸ ì´ˆê¸°í™”
    suite = MultimodalTrainingSuite()

    # ì¢…í•© í›ˆë ¨ ì‹¤í–‰
    results = suite.run_comprehensive_training_suite(
        advanced_samples=10000, realtime_samples=1000, optimization_samples=50000
    )

    print("\nğŸ¯ ìµœì¢… ê²°ê³¼:")
    for method, result in results["training_results"].items():
        status = result.get("status", "unknown")
        print(f"   {method.replace('_', ' ').title()}: {status}")


if __name__ == "__main__":
    main()



