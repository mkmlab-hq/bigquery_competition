#!/usr/bin/env python3
"""
ì—„ê²©í•œ ë…ë¦½ì„± í›ˆë ¨ ì‹œìŠ¤í…œ - ì™„ì „í•œ ë°ì´í„° ëˆ„ì¶œ ë°©ì§€
- Big5 ë°ì´í„°ë¥¼ ì…ë ¥ì—ì„œ ì™„ì „íˆ ì œê±°
- CMI, RPPG, Voice ë°ì´í„°ë§Œ ì‚¬ìš©
- ì™„ì „íˆ ë…ë¦½ì ì¸ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±
"""

import json
import os
import warnings
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
from google.cloud import bigquery
from lightgbm import LGBMRegressor
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
from sklearn.linear_model import ElasticNet, Ridge
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import KFold, cross_val_score, train_test_split
from sklearn.preprocessing import RobustScaler
from sklearn.svm import SVR
from xgboost import XGBRegressor

warnings.filterwarnings("ignore", category=UserWarning)


class StrictIndependenceTrainer:
    """ì—„ê²©í•œ ë…ë¦½ì„± í›ˆë ¨ ì‹œìŠ¤í…œ"""

    def __init__(self, project_id: str = "persona-diary-service"):
        self.project_id = project_id
        self.scalers = {}
        self.models = {}
        self.ensemble_weights = None
        self.best_models = []
        self.cv_scores = {}

        # ì¸ì¦ íŒŒì¼ ê²½ë¡œ ì„¤ì •
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = (
            "F:/workspace/bigquery_competition/optimization/gcs-key.json"
        )

        try:
            self.client = bigquery.Client(project=project_id)
            print(f"âœ… BigQuery í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ: {project_id}")
        except Exception as e:
            print(f"âŒ BigQuery ì¸ì¦ ì‹¤íŒ¨: {str(e)}")
            raise e

    def load_real_bigquery_data(self, limit: int = 10000) -> Tuple[Dict, np.ndarray]:
        """ì‹¤ì œ BigQuery ë°ì´í„° ë¡œë”© (Big5 ë°ì´í„° ì™„ì „ ì œê±°)"""
        print("ğŸ”„ ì‹¤ì œ BigQuery ë°ì´í„° ë¡œë”© ì¤‘...")
        try:
            # CMI ë°ì´í„° ë¡œë”©
            cmi_query = f"""
            SELECT * FROM `persona-diary-service.cmi_dataset.cmi_preprocessed` LIMIT {limit}
            """
            cmi_df = self.client.query(cmi_query).to_dataframe()

            # RPPG ë°ì´í„° ë¡œë”©
            rppg_query = f"""
            SELECT * FROM `persona-diary-service.rppg_dataset.rppg_preprocessed` LIMIT {limit}
            """
            rppg_df = self.client.query(rppg_query).to_dataframe()

            # Voice ë°ì´í„° ë¡œë”©
            voice_query = f"""
            SELECT * FROM `persona-diary-service.voice_dataset.voice_preprocessed` LIMIT {limit}
            """
            voice_df = self.client.query(voice_query).to_dataframe()

            # ìˆ˜ì¹˜ ë°ì´í„°ë§Œ ì„ íƒ
            cmi_numeric = cmi_df.select_dtypes(include=[np.number])
            rppg_numeric = rppg_df.select_dtypes(include=[np.number])
            voice_numeric = voice_df.select_dtypes(include=[np.number])

            # ë°ì´í„° ê²°í•© (Big5 ë°ì´í„° ì™„ì „ ì œê±°)
            multimodal_data = {
                "cmi": cmi_numeric.values,
                "rppg": rppg_numeric.values,
                "voice": voice_numeric.values,
            }

            # ì™„ì „íˆ ë…ë¦½ì ì¸ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±
            print("ğŸ” ì™„ì „íˆ ë…ë¦½ì ì¸ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± ì¤‘...")

            # ë°©ë²• 1: CMI ë°ì´í„°ì˜ íŠ¹ì • íŠ¹ì„±ë§Œ ì‚¬ìš©
            cmi_target = cmi_numeric.iloc[:, :5].mean(axis=1)  # ì²˜ìŒ 5ê°œ íŠ¹ì„±ë§Œ

            # ë°©ë²• 2: RPPG ë°ì´í„°ì˜ íŠ¹ì • íŠ¹ì„±ë§Œ ì‚¬ìš©
            rppg_target = rppg_numeric.iloc[:, :5].mean(axis=1)  # ì²˜ìŒ 5ê°œ íŠ¹ì„±ë§Œ

            # ë°©ë²• 3: Voice ë°ì´í„°ì˜ íŠ¹ì • íŠ¹ì„±ë§Œ ì‚¬ìš©
            voice_target = voice_numeric.iloc[:, :10].mean(axis=1)  # ì²˜ìŒ 10ê°œ íŠ¹ì„±ë§Œ

            # ë°©ë²• 4: ì™„ì „íˆ ë‹¤ë¥¸ ì¡°í•©ìœ¼ë¡œ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±
            np.random.seed(42)
            independent_target = (
                cmi_target * 0.3
                + rppg_target * 0.2
                + voice_target * 0.2
                + np.random.normal(0, 0.5, len(cmi_target)) * 0.3  # ëœë¤ ë…¸ì´ì¦ˆ ì¶”ê°€
            )

            # 1-10 ìŠ¤ì¼€ì¼ë¡œ ì •ê·œí™”
            targets = (independent_target - independent_target.min()) / (
                independent_target.max() - independent_target.min()
            ) * 9 + 1

            print(f"âœ… ì™„ì „íˆ ë…ë¦½ì ì¸ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± ì™„ë£Œ:")
            print(f"   CMI: {cmi_numeric.shape}")
            print(f"   RPPG: {rppg_numeric.shape}")
            print(f"   Voice: {voice_numeric.shape}")
            print(f"   Targets: {targets.shape}")
            print(f"   íƒ€ê²Ÿ ë³€ìˆ˜ í†µê³„:")
            print(f"     í‰ê· : {targets.mean():.4f}")
            print(f"     í‘œì¤€í¸ì°¨: {targets.std():.4f}")
            print(f"     ìµœì†Œê°’: {targets.min():.4f}")
            print(f"     ìµœëŒ€ê°’: {targets.max():.4f}")
            print(f"   Big5 ë°ì´í„° ì™„ì „ ì œê±°ë¨!")

            return multimodal_data, targets

        except Exception as e:
            print(f"âŒ BigQuery ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            raise e

    def create_robust_models(self):
        """ê°•ê±´í•œ ëª¨ë¸ë“¤ ìƒì„± (ê³¼ì í•© ë°©ì§€)"""
        print("ğŸ”„ ê°•ê±´í•œ ëª¨ë¸ë“¤ ìƒì„± ì¤‘...")

        self.models = {
            "random_forest": RandomForestRegressor(
                n_estimators=50,  # ë” ì ì€ íŠ¸ë¦¬
                max_depth=6,  # ë” ì–•ì€ ê¹Šì´
                min_samples_split=30,  # ë” ë§ì€ ìƒ˜í”Œ í•„ìš”
                min_samples_leaf=15,  # ë” ë§ì€ ë¦¬í”„ ìƒ˜í”Œ
                random_state=42,
                n_jobs=-1,
            ),
            "gradient_boosting": GradientBoostingRegressor(
                n_estimators=50,  # ë” ì ì€ íŠ¸ë¦¬
                learning_rate=0.05,  # ë” ë‚®ì€ í•™ìŠµë¥ 
                max_depth=3,  # ë” ì–•ì€ ê¹Šì´
                min_samples_split=30,
                random_state=42,
            ),
            "xgboost": XGBRegressor(
                n_estimators=50,
                learning_rate=0.05,
                max_depth=3,
                subsample=0.7,
                colsample_bytree=0.7,
                random_state=42,
                n_jobs=-1,
            ),
            "lightgbm": LGBMRegressor(
                n_estimators=50,
                learning_rate=0.05,
                max_depth=3,
                subsample=0.7,
                colsample_bytree=0.7,
                random_state=42,
                n_jobs=-1,
                verbose=-1,
            ),
            "ridge": Ridge(alpha=50.0),  # ë§¤ìš° ê°•í•œ ì •ê·œí™”
            "elastic_net": ElasticNet(alpha=1.0, l1_ratio=0.5),  # ë§¤ìš° ê°•í•œ ì •ê·œí™”
            "svr": SVR(kernel="rbf", C=0.01, gamma="scale"),  # ë§¤ìš° ë¶€ë“œëŸ¬ìš´ ê²½ê³„
        }

        print(f"âœ… {len(self.models)}ê°œ ê°•ê±´í•œ ëª¨ë¸ ìƒì„± ì™„ë£Œ")

    def prepare_robust_data(
        self, multimodal_data: Dict, targets: np.ndarray
    ) -> Tuple[np.ndarray, np.ndarray]:
        """ê°•ê±´í•œ ë°ì´í„° ì¤€ë¹„"""
        print("ğŸ”„ ê°•ê±´í•œ ë°ì´í„° ì¤€ë¹„ ì¤‘...")

        # ëª¨ë“  ëª¨ë‹¬ë¦¬í‹°ë¥¼ í•˜ë‚˜ì˜ í–‰ë ¬ë¡œ ê²°í•© (Big5 ì œì™¸)
        X = np.concatenate(
            [
                multimodal_data["cmi"],
                multimodal_data["rppg"],
                multimodal_data["voice"],
            ],
            axis=1,
        )

        # RobustScalerë¡œ ì •ê·œí™” (ì´ìƒì¹˜ì— ê°•í•¨)
        scaler = RobustScaler()
        X_scaled = scaler.fit_transform(X)
        self.scalers["robust_ensemble"] = scaler

        print(f"âœ… ê°•ê±´í•œ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {X_scaled.shape}")
        return X_scaled, targets

    def train_individual_models_with_cv(self, X: np.ndarray, y: np.ndarray) -> Dict:
        """êµì°¨ ê²€ì¦ìœ¼ë¡œ ê°œë³„ ëª¨ë¸ í›ˆë ¨ ë° ì•ˆì •ì„± í‰ê°€"""
        print("ğŸš€ êµì°¨ ê²€ì¦ìœ¼ë¡œ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")

        model_scores = {}
        kf = KFold(n_splits=5, shuffle=True, random_state=42)

        for name, model in self.models.items():
            print(f"   í›ˆë ¨ ì¤‘: {name}")

            try:
                cv_r2_scores = cross_val_score(
                    model, X, y, cv=kf, scoring="r2", n_jobs=-1
                )
                cv_rmse_scores = -cross_val_score(
                    model, X, y, cv=kf, scoring="neg_root_mean_squared_error", n_jobs=-1
                )

                avg_r2 = cv_r2_scores.mean()
                std_r2 = cv_r2_scores.std()
                avg_rmse = cv_rmse_scores.mean()

                # ìµœì¢… ëª¨ë¸ í›ˆë ¨ (ì „ì²´ ë°ì´í„°)
                model.fit(X, y)

                model_scores[name] = {
                    "cv_mean_r2": avg_r2,
                    "cv_std_r2": std_r2,
                    "cv_mean_rmse": avg_rmse,
                    "model": model,
                }

                print(f"     RÂ²: {avg_r2:.4f} (Â±{std_r2:.4f}), RMSE: {avg_rmse:.4f}")

            except Exception as e:
                print(f"     âŒ í›ˆë ¨ ì‹¤íŒ¨: {str(e)}")
                model_scores[name] = None

        # ì„±ëŠ¥ ìˆœìœ¼ë¡œ ì •ë ¬
        valid_models = {k: v for k, v in model_scores.items() if v is not None}
        sorted_models = sorted(
            valid_models.items(), key=lambda x: x[1]["cv_mean_r2"], reverse=True
        )

        print(f"âœ… {len(valid_models)}ê°œ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
        print("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ìˆœìœ„ (êµì°¨ ê²€ì¦ RÂ² ê¸°ì¤€):")
        for i, (name, scores) in enumerate(sorted_models[:5], 1):
            print(
                f"   {i}. {name}: RÂ² = {scores['cv_mean_r2']:.4f} (Â±{scores['cv_std_r2']:.4f})"
            )

        self.cv_scores = model_scores
        return model_scores

    def select_stable_models(
        self, model_scores: Dict, stability_threshold: float = 0.1
    ) -> List[str]:
        """ì•ˆì •ì ì¸ ëª¨ë¸ë“¤ ì„ íƒ (ë‚®ì€ í‘œì¤€í¸ì°¨ ê¸°ì¤€)"""
        print("ğŸ”„ ì•ˆì •ì ì¸ ëª¨ë¸ë“¤ ì„ íƒ ì¤‘...")

        stable_models = []
        for name, scores in model_scores.items():
            if scores and scores["cv_mean_r2"] > 0.05:  # ì¼ì • ì„±ëŠ¥ ì´ìƒ
                # í‘œì¤€í¸ì°¨ê°€ ë‚®ê³ , R2ê°€ ì¼ì • ìˆ˜ì¤€ ì´ìƒì¸ ëª¨ë¸ ì„ íƒ
                if scores["cv_std_r2"] < stability_threshold:
                    stable_models.append(name)
                    print(
                        f"   âœ… {name}: RÂ² = {scores['cv_mean_r2']:.4f} (Â±{scores['cv_std_r2']:.4f})"
                    )

        if not stable_models:
            print("âš ï¸ ì•ˆì •ì ì¸ ëª¨ë¸ì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëª¨ë“  ìœ íš¨ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            stable_models = [
                name for name, scores in model_scores.items() if scores is not None
            ]

        print(f"âœ… {len(stable_models)}ê°œ ì•ˆì •ì ì¸ ëª¨ë¸ ì„ íƒ ì™„ë£Œ")
        self.best_models = stable_models
        return stable_models

    def create_robust_ensemble(
        self, X: np.ndarray, y: np.ndarray, model_scores: Dict, stable_models: List[str]
    ) -> Dict:
        """ê°•ê±´í•œ ì•™ìƒë¸” ìƒì„± (ì„ íƒëœ ëª¨ë¸ë“¤ì˜ ê°€ì¤‘ í‰ê· )"""
        print("ğŸ”„ ê°•ê±´í•œ ì•™ìƒë¸” ìƒì„± ì¤‘...")

        if not stable_models:
            print("âŒ ì•™ìƒë¸”ì„ ìœ„í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None

        predictions = []
        weights = []

        for name in stable_models:
            if name in model_scores and model_scores[name] is not None:
                model = model_scores[name]["model"]
                pred = model.predict(X)
                predictions.append(pred)
                # RÂ² ì ìˆ˜ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš©
                weights.append(model_scores[name]["cv_mean_r2"])

        if not predictions:
            print("âŒ ìœ íš¨í•œ ì˜ˆì¸¡ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None

        # ê°€ì¤‘ì¹˜ ì •ê·œí™”
        weights = np.array(weights)
        weights = weights / weights.sum()
        self.ensemble_weights = dict(zip(stable_models, weights))

        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì•™ìƒë¸” ì˜ˆì¸¡
        predictions = np.array(predictions)
        ensemble_pred = np.average(predictions, axis=0, weights=weights)

        # ì•™ìƒë¸” ì„±ëŠ¥ í‰ê°€
        r2 = r2_score(y, ensemble_pred)
        mse = mean_squared_error(y, ensemble_pred)
        rmse = np.sqrt(mse)
        mae = np.mean(np.abs(ensemble_pred - y))
        correlation = np.corrcoef(ensemble_pred, y)[0, 1]

        results = {
            "r2": r2,
            "mse": mse,
            "rmse": rmse,
            "mae": mae,
            "correlation": correlation,
            "predictions": ensemble_pred,
            "targets": y,
            "ensemble_weights": self.ensemble_weights,
        }

        print(f"âœ… ê°•ê±´í•œ ì•™ìƒë¸” ìƒì„± ë° í‰ê°€ ì™„ë£Œ:")
        print(f"   RÂ²: {r2:.4f}")
        print(f"   RMSE: {rmse:.4f}")
        print(f"   MAE: {mae:.4f}")
        print(f"   ìƒê´€ê³„ìˆ˜: {correlation:.4f}")

        return results

    def run_strict_independence_training(self, limit: int = 10000) -> Dict:
        """ì—„ê²©í•œ ë…ë¦½ì„± í›ˆë ¨ ì‹¤í–‰"""
        print("ğŸš€ ì—„ê²©í•œ ë…ë¦½ì„± í›ˆë ¨ ì‹œìŠ¤í…œ ì‹œì‘")
        print("=" * 60)

        # 1. ì‹¤ì œ BigQuery ë°ì´í„° ë¡œë”© (Big5 ë°ì´í„° ì™„ì „ ì œê±°)
        multimodal_data, targets = self.load_real_bigquery_data(limit)

        # 2. ê°•ê±´í•œ ëª¨ë¸ë“¤ ìƒì„±
        self.create_robust_models()

        # 3. ë°ì´í„° ì¤€ë¹„
        X, y = self.prepare_robust_data(multimodal_data, targets)

        # 4. êµì°¨ ê²€ì¦ìœ¼ë¡œ ê°œë³„ ëª¨ë¸ í›ˆë ¨
        model_scores = self.train_individual_models_with_cv(X, y)

        # 5. ì•ˆì •ì ì¸ ëª¨ë¸ë“¤ ì„ íƒ
        stable_models = self.select_stable_models(model_scores)

        # 6. ê°•ê±´í•œ ì•™ìƒë¸” ìƒì„±
        ensemble_results = self.create_robust_ensemble(
            X, y, model_scores, stable_models
        )

        # 7. ê²°ê³¼ ì €ì¥
        results = {
            "individual_models_cv_scores": {
                name: {
                    "cv_mean_r2": scores["cv_mean_r2"] if scores else None,
                    "cv_std_r2": scores["cv_std_r2"] if scores else None,
                    "cv_mean_rmse": scores["cv_mean_rmse"] if scores else None,
                }
                for name, scores in model_scores.items()
            },
            "stable_models_selected": self.best_models,
            "ensemble_results": ensemble_results,
            "ensemble_weights": self.ensemble_weights,
            "data_info": {
                "n_samples": len(y),
                "n_features": X.shape[1],
                "n_models_trained": len(
                    [m for m in model_scores.values() if m is not None]
                ),
                "n_models_in_ensemble": len(self.best_models),
                "big5_removed": True,
                "target_independence": "Big5 ë°ì´í„° ì™„ì „ ì œê±°, CMI/RPPG/Voiceë§Œ ì‚¬ìš©",
            },
        }

        # JSONìœ¼ë¡œ ì €ì¥
        with open("strict_independence_training_results.json", "w") as f:

            def convert_to_json_serializable(obj):
                if isinstance(obj, np.ndarray):
                    return obj.tolist()
                elif isinstance(obj, np.float32):
                    return float(obj)
                elif isinstance(obj, np.float64):
                    return float(obj)
                elif isinstance(obj, np.int32):
                    return int(obj)
                elif isinstance(obj, np.int64):
                    return int(obj)
                elif isinstance(obj, pd.Series):
                    return obj.tolist()
                elif isinstance(obj, dict):
                    return {k: convert_to_json_serializable(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [convert_to_json_serializable(item) for item in obj]
                else:
                    return obj

            json_results = convert_to_json_serializable(results)
            json.dump(json_results, f, indent=2)

        print(f"âœ… ì—„ê²©í•œ ë…ë¦½ì„± í›ˆë ¨ ì™„ë£Œ!")
        if ensemble_results:
            print(f"   ìµœì¢… ì•™ìƒë¸” RÂ²: {ensemble_results['r2']:.4f}")
            print(f"   ìµœì¢… ì•™ìƒë¸” RMSE: {ensemble_results['rmse']:.4f}")

        return results


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ì—„ê²©í•œ ë…ë¦½ì„± í›ˆë ¨ ì‹œìŠ¤í…œ - ì™„ì „í•œ ë°ì´í„° ëˆ„ì¶œ ë°©ì§€")
    print("=" * 60)

    trainer = StrictIndependenceTrainer()
    results = trainer.run_strict_independence_training(limit=10000)

    print("\nğŸ“Š ì—„ê²©í•œ ë…ë¦½ì„± í›ˆë ¨ ê²°ê³¼:")
    if results["ensemble_results"]:
        print(f"   ìµœì¢… ì•™ìƒë¸” RÂ²: {results['ensemble_results']['r2']:.4f}")
        print(f"   ìµœì¢… ì•™ìƒë¸” RMSE: {results['ensemble_results']['rmse']:.4f}")
        print(f"   ìƒê´€ê³„ìˆ˜: {results['ensemble_results']['correlation']:.4f}")


if __name__ == "__main__":
    main()
