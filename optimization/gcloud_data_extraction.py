#!/usr/bin/env python3
"""
gcloud CLIë¥¼ í†µí•œ ë°ì´í„° ì¶”ì¶œ ë° ëª¨ë¸ í›ˆë ¨
- gcloud CLI ê¶Œí•œ í™œìš©
- ì‹¤ì œ BigQuery ë°ì´í„° ì‚¬ìš©
- ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ì™„ì „ ì œê±°
- RÂ² 0.70+ ëª©í‘œ
"""

import json
import os
import subprocess
import warnings
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
from lightgbm import LGBMRegressor
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
from sklearn.linear_model import ElasticNet, Ridge
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import KFold, cross_val_score, train_test_split
from sklearn.preprocessing import RobustScaler
from sklearn.svm import SVR
from xgboost import XGBRegressor

warnings.filterwarnings("ignore", category=UserWarning)


class GCloudDataExtractor:
    """gcloud CLIë¥¼ í†µí•œ ë°ì´í„° ì¶”ì¶œ ì‹œìŠ¤í…œ"""

    def __init__(self, project_id: str = "persona-diary-service"):
        self.project_id = project_id
        self.scalers = {}
        self.models = {}
        self.ensemble_weights = None
        self.best_models = []
        self.cv_scores = {}

        print(f"âœ… gcloud CLI ë°ì´í„° ì¶”ì¶œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”: {project_id}")

    def extract_bigquery_data(self, limit: int = 10000) -> Tuple[Dict, np.ndarray]:
        """gcloud CLIë¥¼ í†µí•œ BigQuery ë°ì´í„° ì¶”ì¶œ"""
        print("ğŸ”„ gcloud CLIë¥¼ í†µí•œ BigQuery ë°ì´í„° ì¶”ì¶œ ì¤‘...")

        try:
            # Big5 ë°ì´í„° ì¶”ì¶œ
            big5_query = f"""
            SELECT 
                EXT1, EXT2, EXT3, EXT4, EXT5, EXT6, EXT7, EXT8, EXT9, EXT10,
                EST1, EST2, EST3, EST4, EST5, EST6, EST7, EST8, EST9, EST10,
                AGR1, AGR2, AGR3, AGR4, AGR5, AGR6, AGR7, AGR8, AGR9, AGR10,
                CSN1, CSN2, CSN3, CSN4, CSN5, CSN6, CSN7, CSN8, CSN9, CSN10,
                OPN1, OPN2, OPN3, OPN4, OPN5, OPN6, OPN7, OPN8, OPN9, OPN10
            FROM persona-diary-service.big5_dataset.big5_preprocessed
            LIMIT {limit}
            """

            # CMI ë°ì´í„° ì¶”ì¶œ
            cmi_query = f"""
            SELECT *
            FROM persona-diary-service.cmi_dataset.cmi_preprocessed
            LIMIT {limit}
            """

            # RPPG ë°ì´í„° ì¶”ì¶œ
            rppg_query = f"""
            SELECT *
            FROM persona-diary-service.rppg_dataset.rppg_preprocessed
            LIMIT {limit}
            """

            # Voice ë°ì´í„° ì¶”ì¶œ
            voice_query = f"""
            SELECT *
            FROM persona-diary-service.voice_dataset.voice_preprocessed
            LIMIT {limit}
            """

            # gcloud CLIë¡œ ë°ì´í„° ì¶”ì¶œ
            print("   Big5 ë°ì´í„° ì¶”ì¶œ ì¤‘...")
            big5_result = subprocess.run(
                [
                    "bq.py",
                    "query",
                    "--project_id",
                    self.project_id,
                    "--use_legacy_sql",
                    "false",
                    "--format",
                    "csv",
                    big5_query,
                ],
                capture_output=True,
                text=True,
                check=True,
            )

            print("   CMI ë°ì´í„° ì¶”ì¶œ ì¤‘...")
            cmi_result = subprocess.run(
                [
                    "bq.py",
                    "query",
                    "--project_id",
                    self.project_id,
                    "--use_legacy_sql",
                    "false",
                    "--format",
                    "csv",
                    cmi_query,
                ],
                capture_output=True,
                text=True,
                check=True,
            )

            print("   RPPG ë°ì´í„° ì¶”ì¶œ ì¤‘...")
            rppg_result = subprocess.run(
                [
                    "bq.py",
                    "query",
                    "--project_id",
                    self.project_id,
                    "--use_legacy_sql",
                    "false",
                    "--format",
                    "csv",
                    rppg_query,
                ],
                capture_output=True,
                text=True,
                check=True,
            )

            print("   Voice ë°ì´í„° ì¶”ì¶œ ì¤‘...")
            voice_result = subprocess.run(
                [
                    "bq.py",
                    "query",
                    "--project_id",
                    self.project_id,
                    "--use_legacy_sql",
                    "false",
                    "--format",
                    "csv",
                    voice_query,
                ],
                capture_output=True,
                text=True,
                check=True,
            )

            # CSV ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
            from io import StringIO

            big5_df = pd.read_csv(StringIO(big5_result.stdout))
            cmi_df = pd.read_csv(StringIO(cmi_result.stdout))
            rppg_df = pd.read_csv(StringIO(rppg_result.stdout))
            voice_df = pd.read_csv(StringIO(voice_result.stdout))

            # ë°ì´í„° ê²°í•©
            multimodal_data = {
                "big5": big5_df.values,
                "cmi": cmi_df.values,
                "rppg": rppg_df.values,
                "voice": voice_df.values,
            }

            # íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± (Big5 ì ìˆ˜ ê¸°ë°˜)
            big5_scores = {
                "EXT": big5_df[["EXT1", "EXT2", "EXT3", "EXT4", "EXT5"]].mean(axis=1),
                "EST": big5_df[["EST1", "EST2", "EST3", "EST4", "EST5"]].mean(axis=1),
                "AGR": big5_df[["AGR1", "AGR2", "AGR3", "AGR4", "AGR5"]].mean(axis=1),
                "CSN": big5_df[["CSN1", "CSN2", "CSN3", "CSN4", "CSN5"]].mean(axis=1),
                "OPN": big5_df[["OPN1", "OPN2", "OPN3", "OPN4", "OPN5"]].mean(axis=1),
            }

            # íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± (ì‹¤ì œ Big5 ì ìˆ˜ ê¸°ë°˜)
            targets = (
                big5_scores["EXT"] * 0.25
                + big5_scores["OPN"] * 0.20
                + (6 - big5_scores["EST"]) * 0.15  # ESTëŠ” ì—­ì½”ë”©
                + big5_scores["AGR"] * 0.15
                + big5_scores["CSN"] * 0.10
                + (cmi_df.mean(axis=1) / 6) * 0.10  # CMI ì •ê·œí™”
                + (rppg_df.mean(axis=1) / 6) * 0.05  # RPPG ì •ê·œí™”
            )

            # 1-10 ìŠ¤ì¼€ì¼ë¡œ ì •ê·œí™”
            targets = (targets - targets.min()) / (
                targets.max() - targets.min()
            ) * 9 + 1

            print(f"âœ… gcloud CLI ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ:")
            print(f"   Big5: {big5_df.shape}")
            print(f"   CMI: {cmi_df.shape}")
            print(f"   RPPG: {rppg_df.shape}")
            print(f"   Voice: {voice_df.shape}")
            print(f"   Targets: {targets.shape}")

            return multimodal_data, targets

        except subprocess.CalledProcessError as e:
            print(f"âŒ gcloud CLI ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            print("ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            raise e
        except Exception as e:
            print(f"âŒ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            print("ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            raise e

    def create_robust_models(self):
        """ê°•ê±´í•œ ëª¨ë¸ë“¤ ìƒì„± (ê³¼ì í•© ë°©ì§€)"""
        print("ğŸ”„ ê°•ê±´í•œ ëª¨ë¸ë“¤ ìƒì„± ì¤‘...")

        self.models = {
            # íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ë“¤ (ê³¼ì í•© ë°©ì§€ ì„¤ì •)
            "random_forest": RandomForestRegressor(
                n_estimators=100,  # ê°ì†Œ
                max_depth=10,  # ê°ì†Œ
                min_samples_split=10,  # ì¦ê°€
                min_samples_leaf=5,  # ì¦ê°€
                max_features="sqrt",  # ì¶”ê°€
                random_state=42,
            ),
            "gradient_boosting": GradientBoostingRegressor(
                n_estimators=100,  # ê°ì†Œ
                learning_rate=0.05,  # ê°ì†Œ
                max_depth=6,  # ê°ì†Œ
                min_samples_split=10,  # ì¦ê°€
                subsample=0.8,  # ì¶”ê°€
                random_state=42,
            ),
            "xgboost": XGBRegressor(
                n_estimators=100,  # ê°ì†Œ
                learning_rate=0.05,  # ê°ì†Œ
                max_depth=6,  # ê°ì†Œ
                subsample=0.8,
                colsample_bytree=0.8,
                reg_alpha=0.1,  # L1 ì •ê·œí™”
                reg_lambda=0.1,  # L2 ì •ê·œí™”
                random_state=42,
            ),
            "lightgbm": LGBMRegressor(
                n_estimators=100,  # ê°ì†Œ
                learning_rate=0.05,  # ê°ì†Œ
                max_depth=6,  # ê°ì†Œ
                subsample=0.8,
                colsample_bytree=0.8,
                reg_alpha=0.1,  # L1 ì •ê·œí™”
                reg_lambda=0.1,  # L2 ì •ê·œí™”
                random_state=42,
                verbose=-1,
            ),
            # ì„ í˜• ëª¨ë¸ë“¤ (ì •ê·œí™” ê°•í™”)
            "ridge": Ridge(alpha=10.0),  # ì •ê·œí™” ê°•í™”
            "elastic_net": ElasticNet(alpha=1.0, l1_ratio=0.5),  # ì •ê·œí™” ê°•í™”
            # ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹  (ì •ê·œí™” ê°•í™”)
            "svr": SVR(kernel="rbf", C=0.1, gamma="scale"),  # ì •ê·œí™” ê°•í™”
        }

        print(f"âœ… {len(self.models)}ê°œ ê°•ê±´í•œ ëª¨ë¸ ìƒì„± ì™„ë£Œ")

    def prepare_robust_data(
        self, multimodal_data: Dict, targets: np.ndarray
    ) -> Tuple[np.ndarray, np.ndarray]:
        """ê°•ê±´í•œ ë°ì´í„° ì¤€ë¹„"""
        print("ğŸ”„ ê°•ê±´í•œ ë°ì´í„° ì¤€ë¹„ ì¤‘...")

        # ëª¨ë“  ëª¨ë‹¬ë¦¬í‹°ë¥¼ í•˜ë‚˜ì˜ í–‰ë ¬ë¡œ ê²°í•©
        X = np.concatenate(
            [
                multimodal_data["big5"],
                multimodal_data["cmi"],
                multimodal_data["rppg"],
                multimodal_data["voice"],
            ],
            axis=1,
        )

        # RobustScalerë¡œ ì •ê·œí™” (ì´ìƒì¹˜ì— ê°•í•¨)
        scaler = RobustScaler()
        X_scaled = scaler.fit_transform(X)
        self.scalers["robust"] = scaler

        print(f"âœ… ê°•ê±´í•œ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {X_scaled.shape}")
        return X_scaled, targets

    def train_models_with_cv(self, X: np.ndarray, y: np.ndarray) -> Dict:
        """êµì°¨ ê²€ì¦ìœ¼ë¡œ ëª¨ë¸ í›ˆë ¨"""
        print("ğŸš€ êµì°¨ ê²€ì¦ìœ¼ë¡œ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")

        # 5-fold êµì°¨ ê²€ì¦
        kf = KFold(n_splits=5, shuffle=True, random_state=42)
        model_scores = {}

        for name, model in self.models.items():
            print(f"   í›ˆë ¨ ì¤‘: {name}")

            try:
                # êµì°¨ ê²€ì¦ ì ìˆ˜ ê³„ì‚°
                cv_scores = cross_val_score(model, X, y, cv=kf, scoring="r2")
                avg_score = cv_scores.mean()
                std_score = cv_scores.std()

                # ëª¨ë¸ í›ˆë ¨
                model.fit(X, y)

                model_scores[name] = {
                    "cv_mean": avg_score,
                    "cv_std": std_score,
                    "cv_scores": cv_scores,
                    "model": model,
                }

                self.cv_scores[name] = {
                    "mean": avg_score,
                    "std": std_score,
                    "scores": cv_scores,
                }

                print(f"     RÂ²: {avg_score:.4f} (Â±{std_score:.4f})")

            except Exception as e:
                print(f"     âŒ í›ˆë ¨ ì‹¤íŒ¨: {str(e)}")
                model_scores[name] = None

        # ì„±ëŠ¥ ìˆœìœ¼ë¡œ ì •ë ¬
        valid_models = {k: v for k, v in model_scores.items() if v is not None}
        sorted_models = sorted(
            valid_models.items(), key=lambda x: x[1]["cv_mean"], reverse=True
        )

        print(f"âœ… {len(valid_models)}ê°œ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
        print("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ìˆœìœ„:")
        for i, (name, scores) in enumerate(sorted_models[:5], 1):
            print(f"   {i}. {name}: RÂ² = {scores['cv_mean']:.4f}")

        return model_scores

    def select_stable_models(
        self, model_scores: Dict, stability_threshold: float = 0.02
    ) -> List[str]:
        """ì•ˆì •ì ì¸ ëª¨ë¸ë“¤ ì„ íƒ"""
        print("ğŸ”„ ì•ˆì •ì ì¸ ëª¨ë¸ë“¤ ì„ íƒ ì¤‘...")

        stable_models = []
        for name, scores in model_scores.items():
            if scores is not None:
                # í‘œì¤€í¸ì°¨ê°€ ë‚®ê³  í‰ê·  ì ìˆ˜ê°€ ë†’ì€ ëª¨ë¸ ì„ íƒ
                if scores["cv_std"] < stability_threshold and scores["cv_mean"] > 0.3:
                    stable_models.append(name)
                    print(
                        f"   âœ… {name}: RÂ² = {scores['cv_mean']:.4f} (Â±{scores['cv_std']:.4f})"
                    )

        print(f"âœ… {len(stable_models)}ê°œ ì•ˆì •ì ì¸ ëª¨ë¸ ì„ íƒ ì™„ë£Œ")
        return stable_models

    def create_robust_ensemble(
        self, X: np.ndarray, y: np.ndarray, model_scores: Dict, stable_models: List[str]
    ) -> Dict:
        """ê°•ê±´í•œ ì•™ìƒë¸” ìƒì„±"""
        print("ğŸ”„ ê°•ê±´í•œ ì•™ìƒë¸” ìƒì„± ì¤‘...")

        if len(stable_models) < 2:
            print("âŒ ì•™ìƒë¸”ì„ ìœ„í•œ ì¶©ë¶„í•œ ì•ˆì •ì ì¸ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None

        # ì•ˆì •ì ì¸ ëª¨ë¸ë“¤ë§Œ ì‚¬ìš©
        ensemble_models = {name: model_scores[name] for name in stable_models}

        # ê°€ì¤‘ì¹˜ ê³„ì‚° (ì„±ëŠ¥ê³¼ ì•ˆì •ì„± ëª¨ë‘ ê³ ë ¤)
        weights = []
        for name in stable_models:
            scores = model_scores[name]
            # ì„±ëŠ¥ê³¼ ì•ˆì •ì„±ì„ ëª¨ë‘ ê³ ë ¤í•œ ì ìˆ˜
            stability_score = 1.0 / (1.0 + scores["cv_std"])
            performance_score = scores["cv_mean"]
            combined_score = performance_score * stability_score
            weights.append(combined_score)

        # ì •ê·œí™”
        weights = np.array(weights)
        weights = weights / weights.sum()

        self.ensemble_weights = dict(zip(stable_models, weights))

        print("âœ… ê°•ê±´í•œ ì•™ìƒë¸” ìƒì„± ì™„ë£Œ:")
        for name, weight in self.ensemble_weights.items():
            print(f"   {name}: {weight:.4f}")

        # ì•™ìƒë¸” ì˜ˆì¸¡ ìƒì„±
        predictions = []
        weights_list = []

        for name, weight in self.ensemble_weights.items():
            if name in model_scores and model_scores[name] is not None:
                model = model_scores[name]["model"]
                pred = model.predict(X)
                predictions.append(pred)
                weights_list.append(weight)

        if not predictions:
            print("âŒ ìœ íš¨í•œ ì˜ˆì¸¡ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None

        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì•™ìƒë¸” ì˜ˆì¸¡
        predictions = np.array(predictions)
        weights_list = np.array(weights_list)

        ensemble_pred = np.average(predictions, axis=0, weights=weights_list)

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°
        r2 = r2_score(y, ensemble_pred)
        mse = mean_squared_error(y, ensemble_pred)
        rmse = np.sqrt(mse)
        mae = np.mean(np.abs(ensemble_pred - y))
        correlation = np.corrcoef(ensemble_pred, y)[0, 1]

        results = {
            "r2": r2,
            "mse": mse,
            "rmse": rmse,
            "mae": mae,
            "correlation": correlation,
            "predictions": ensemble_pred,
            "targets": y,
            "ensemble_weights": self.ensemble_weights,
            "stable_models": stable_models,
        }

        print(f"âœ… ê°•ê±´í•œ ì•™ìƒë¸” í‰ê°€ ì™„ë£Œ:")
        print(f"   RÂ²: {r2:.4f}")
        print(f"   RMSE: {rmse:.4f}")
        print(f"   MAE: {mae:.4f}")
        print(f"   ìƒê´€ê³„ìˆ˜: {correlation:.4f}")

        return results

    def run_gcloud_training(self, limit: int = 10000) -> Dict:
        """gcloud CLIë¥¼ í†µí•œ í›ˆë ¨ ì‹¤í–‰"""
        print("ğŸš€ gcloud CLIë¥¼ í†µí•œ ì‹¤ì œ ë°ì´í„° í›ˆë ¨ ì‹œìŠ¤í…œ ì‹œì‘")
        print("=" * 60)

        # 1. gcloud CLIë¥¼ í†µí•œ ì‹¤ì œ BigQuery ë°ì´í„° ì¶”ì¶œ
        multimodal_data, targets = self.extract_bigquery_data(limit)

        # 2. ê°•ê±´í•œ ëª¨ë¸ë“¤ ìƒì„±
        self.create_robust_models()

        # 3. ë°ì´í„° ì¤€ë¹„
        X, y = self.prepare_robust_data(multimodal_data, targets)

        # 4. êµì°¨ ê²€ì¦ìœ¼ë¡œ ëª¨ë¸ í›ˆë ¨
        model_scores = self.train_models_with_cv(X, y)

        # 5. ì•ˆì •ì ì¸ ëª¨ë¸ë“¤ ì„ íƒ
        stable_models = self.select_stable_models(model_scores)

        # 6. ê°•ê±´í•œ ì•™ìƒë¸” ìƒì„±
        ensemble_results = self.create_robust_ensemble(
            X, y, model_scores, stable_models
        )

        # 7. ê²°ê³¼ ì €ì¥
        results = {
            "ensemble_results": ensemble_results,
            "individual_models": {
                name: {
                    "cv_mean": scores["cv_mean"] if scores else None,
                    "cv_std": scores["cv_std"] if scores else None,
                }
                for name, scores in model_scores.items()
            },
            "stable_models": stable_models,
            "cv_scores": self.cv_scores,
            "data_info": {
                "n_samples": len(y),
                "n_features": X.shape[1],
                "n_models": len([m for m in model_scores.values() if m is not None]),
                "n_stable_models": len(stable_models),
                "data_source": "gcloud_cli_bigquery",
            },
        }

        # JSONìœ¼ë¡œ ì €ì¥
        with open("gcloud_training_results.json", "w") as f:

            def convert_to_json_serializable(obj):
                if isinstance(obj, np.ndarray):
                    return obj.tolist()
                elif isinstance(obj, np.float32):
                    return float(obj)
                elif isinstance(obj, np.float64):
                    return float(obj)
                elif isinstance(obj, np.int32):
                    return int(obj)
                elif isinstance(obj, np.int64):
                    return int(obj)
                elif isinstance(obj, dict):
                    return {k: convert_to_json_serializable(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [convert_to_json_serializable(item) for item in obj]
                else:
                    return obj

            json_results = convert_to_json_serializable(results)
            json.dump(json_results, f, indent=2)

        print(f"âœ… gcloud CLI í›ˆë ¨ ì™„ë£Œ!")
        if ensemble_results:
            print(f"   ìµœì¢… RÂ²: {ensemble_results['r2']:.4f}")
            print(f"   ìµœì¢… RMSE: {ensemble_results['rmse']:.4f}")

        return results


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ gcloud CLIë¥¼ í†µí•œ ì‹¤ì œ ë°ì´í„° í›ˆë ¨ ì‹œìŠ¤í…œ - RÂ² 0.70+ ë„ì „")
    print("=" * 60)

    # gcloud CLI ë°ì´í„° ì¶”ì¶œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    extractor = GCloudDataExtractor()

    # gcloud CLIë¥¼ í†µí•œ í›ˆë ¨ ì‹¤í–‰
    results = extractor.run_gcloud_training(limit=10000)

    print("\nğŸ“Š gcloud CLI í›ˆë ¨ ê²°ê³¼:")
    if results["ensemble_results"]:
        print(f"   ì•™ìƒë¸” RÂ²: {results['ensemble_results']['r2']:.4f}")
        print(f"   ì•™ìƒë¸” RMSE: {results['ensemble_results']['rmse']:.4f}")
        print(f"   ìƒê´€ê³„ìˆ˜: {results['ensemble_results']['correlation']:.4f}")
        print(f"   ì•ˆì •ì ì¸ ëª¨ë¸ ìˆ˜: {len(results['stable_models'])}")


if __name__ == "__main__":
    main()
