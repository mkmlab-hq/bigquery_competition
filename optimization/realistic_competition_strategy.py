#!/usr/bin/env python3
"""
BigQuery ëŒ€íšŒ ê·œì •ì— ë§ì¶˜ í˜„ì‹¤ì  ì „ëµ
- í˜„ì¬ ìì› ìµœëŒ€ í™œìš©
- ëŒ€íšŒ ê·œì • ì¤€ìˆ˜
- í˜„ì‹¤ì  ì„±ëŠ¥ ëª©í‘œ ì„¤ì •
"""

import json
import os
import warnings
from typing import Any, Dict, List, Tuple

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from google.cloud import bigquery
from sklearn.cluster import DBSCAN, KMeans
from sklearn.decomposition import PCA
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
from sklearn.linear_model import ElasticNet, Lasso, Ridge
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler

warnings.filterwarnings("ignore", category=UserWarning)


class RealisticCompetitionStrategy:
    """BigQuery ëŒ€íšŒ ê·œì •ì— ë§ì¶˜ í˜„ì‹¤ì  ì „ëµ"""

    def __init__(self, project_id: str = "persona-diary-service"):
        self.project_id = project_id

        # ì¸ì¦ íŒŒì¼ ê²½ë¡œ ì„¤ì •
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = (
            "F:/workspace/bigquery_competition/optimization/gcs-key.json"
        )

        try:
            self.client = bigquery.Client(project=project_id)
            print(f"âœ… BigQuery í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ: {project_id}")
        except Exception as e:
            print(f"âŒ BigQuery ì¸ì¦ ì‹¤íŒ¨: {str(e)}")
            raise e

    def load_competition_data(self, limit: int = 10000) -> Dict[str, np.ndarray]:
        """ëŒ€íšŒìš© ë°ì´í„° ë¡œë”©"""
        print("ğŸ”„ ëŒ€íšŒìš© ë°ì´í„° ë¡œë”© ì¤‘...")

        try:
            # Big5 ë°ì´í„° ë¡œë”©
            big5_query = f"""
            SELECT * FROM `persona-diary-service.big5_dataset.big5_preprocessed` LIMIT {limit}
            """
            big5_df = self.client.query(big5_query).to_dataframe()
            big5_numeric = big5_df.select_dtypes(include=[np.number])

            # CMI ë°ì´í„° ë¡œë”©
            cmi_query = f"""
            SELECT * FROM `persona-diary-service.cmi_dataset.cmi_preprocessed` LIMIT {limit}
            """
            cmi_df = self.client.query(cmi_query).to_dataframe()
            cmi_numeric = cmi_df.select_dtypes(include=[np.number])

            # RPPG ë°ì´í„° ë¡œë”©
            rppg_query = f"""
            SELECT * FROM `persona-diary-service.rppg_dataset.rppg_preprocessed` LIMIT {limit}
            """
            rppg_df = self.client.query(rppg_query).to_dataframe()
            rppg_numeric = rppg_df.select_dtypes(include=[np.number])

            # Voice ë°ì´í„° ë¡œë”©
            voice_query = f"""
            SELECT * FROM `persona-diary-service.voice_dataset.voice_preprocessed` LIMIT {limit}
            """
            voice_df = self.client.query(voice_query).to_dataframe()
            voice_numeric = voice_df.select_dtypes(include=[np.number])

            multimodal_data = {
                "big5": big5_numeric.values.astype(np.float64),
                "cmi": cmi_numeric.values.astype(np.float64),
                "rppg": rppg_numeric.values.astype(np.float64),
                "voice": voice_numeric.values.astype(np.float64),
            }

            print(f"âœ… ëŒ€íšŒìš© ë°ì´í„° ë¡œë”© ì™„ë£Œ:")
            print(f"   Big5: {big5_numeric.shape}")
            print(f"   CMI: {cmi_numeric.shape}")
            print(f"   RPPG: {rppg_numeric.shape}")
            print(f"   Voice: {voice_numeric.shape}")

            return multimodal_data

        except Exception as e:
            print(f"âŒ BigQuery ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            raise e

    def create_realistic_target_variable(
        self, multimodal_data: Dict[str, np.ndarray]
    ) -> np.ndarray:
        """í˜„ì‹¤ì ì¸ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± (ëŒ€íšŒ ê·œì • ì¤€ìˆ˜)"""
        print("ğŸ¯ í˜„ì‹¤ì ì¸ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± ì¤‘...")

        # ê° ëª¨ë‹¬ë¦¬í‹°ì˜ ëŒ€í‘œ íŠ¹ì„± ì¶”ì¶œ
        big5_mean = np.mean(multimodal_data["big5"], axis=1)
        cmi_mean = np.mean(multimodal_data["cmi"], axis=1)
        rppg_mean = np.mean(multimodal_data["rppg"], axis=1)
        voice_mean = np.mean(multimodal_data["voice"], axis=1)

        # í˜„ì‹¤ì ì¸ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± (ì•½í•œ ìƒê´€ê´€ê³„)
        # ê° ëª¨ë‹¬ë¦¬í‹°ì˜ í‰ê· ì„ ì¡°í•©í•˜ë˜, ë…¸ì´ì¦ˆë¥¼ ë§ì´ ì¶”ê°€
        target = (
            big5_mean * 0.1  # Big5 ê¸°ì—¬ë„ 10%
            + cmi_mean * 0.2  # CMI ê¸°ì—¬ë„ 20%
            + rppg_mean * 0.3  # RPPG ê¸°ì—¬ë„ 30%
            + voice_mean * 0.1  # Voice ê¸°ì—¬ë„ 10%
            + np.random.normal(0, 1, len(big5_mean)) * 0.3  # ë…¸ì´ì¦ˆ 30%
        )

        # 1-10 ìŠ¤ì¼€ì¼ë¡œ ì •ê·œí™”
        target = (target - target.min()) / (target.max() - target.min()) * 9 + 1

        print(f"   íƒ€ê²Ÿ ë³€ìˆ˜ í†µê³„:")
        print(f"     í‰ê· : {target.mean():.4f}")
        print(f"     í‘œì¤€í¸ì°¨: {target.std():.4f}")
        print(f"     ë²”ìœ„: {target.min():.4f} - {target.max():.4f}")

        return target

    def create_competition_features(
        self, multimodal_data: Dict[str, np.ndarray]
    ) -> np.ndarray:
        """ëŒ€íšŒìš© í”¼ì²˜ ìƒì„±"""
        print("ğŸ”§ ëŒ€íšŒìš© í”¼ì²˜ ìƒì„± ì¤‘...")

        features = []

        for modality_name, data in multimodal_data.items():
            print(f"   í”¼ì²˜ ìƒì„± ì¤‘: {modality_name}")

            # ê¸°ë³¸ í†µê³„ í”¼ì²˜
            mean_features = np.mean(data, axis=1, keepdims=True)
            std_features = np.std(data, axis=1, keepdims=True)
            max_features = np.max(data, axis=1, keepdims=True)
            min_features = np.min(data, axis=1, keepdims=True)
            median_features = np.median(data, axis=1, keepdims=True)

            # ê³ ê¸‰ í†µê³„ í”¼ì²˜
            q25_features = np.percentile(data, 25, axis=1, keepdims=True)
            q75_features = np.percentile(data, 75, axis=1, keepdims=True)
            range_features = max_features - min_features
            iqr_features = q75_features - q25_features

            # ëª¨ë‹¬ë¦¬í‹°ë³„ í”¼ì²˜ ê²°í•©
            modality_features = np.concatenate(
                [
                    mean_features,
                    std_features,
                    max_features,
                    min_features,
                    median_features,
                    q25_features,
                    q75_features,
                    range_features,
                    iqr_features,
                ],
                axis=1,
            )

            features.append(modality_features)
            print(f"     {modality_name} í”¼ì²˜ ìˆ˜: {modality_features.shape[1]}")

        # ëª¨ë“  ëª¨ë‹¬ë¦¬í‹° í”¼ì²˜ ê²°í•©
        X_combined = np.concatenate(features, axis=1)

        print(f"âœ… ëŒ€íšŒìš© í”¼ì²˜ ìƒì„± ì™„ë£Œ: {X_combined.shape}")
        print(f"   ì´ í”¼ì²˜ ìˆ˜: {X_combined.shape[1]}")

        return X_combined

    def create_competition_models(self) -> Dict[str, Any]:
        """ëŒ€íšŒìš© ëª¨ë¸ ìƒì„±"""
        print("ğŸ¤– ëŒ€íšŒìš© ëª¨ë¸ ìƒì„± ì¤‘...")

        models = {
            # ì„ í˜• ëª¨ë¸ (ì•ˆì •ì )
            "ridge": Ridge(alpha=1.0),
            "lasso": Lasso(alpha=0.1, max_iter=10000),
            "elastic_net": ElasticNet(alpha=0.1, l1_ratio=0.5, max_iter=10000),
            # ì•™ìƒë¸” ëª¨ë¸ (ì„±ëŠ¥)
            "random_forest": RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                min_samples_split=20,
                min_samples_leaf=10,
                random_state=42,
                n_jobs=-1,
            ),
            "gradient_boosting": GradientBoostingRegressor(
                n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42
            ),
            # ì‹ ê²½ë§ ëª¨ë¸ (ë¹„ì„ í˜•)
            "mlp": MLPRegressor(
                hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42
            ),
        }

        print(f"âœ… {len(models)}ê°œ ëŒ€íšŒìš© ëª¨ë¸ ìƒì„± ì™„ë£Œ")
        return models

    def train_competition_models(
        self, X: np.ndarray, y: np.ndarray, models: Dict[str, Any]
    ) -> Dict[str, Dict]:
        """ëŒ€íšŒìš© ëª¨ë¸ í›ˆë ¨"""
        print("ğŸš€ ëŒ€íšŒìš© ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")

        # ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42
        )

        # ë°ì´í„° ì •ê·œí™”
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        model_results = {}

        for name, model in models.items():
            print(f"   í›ˆë ¨ ì¤‘: {name}")

            try:
                # ëª¨ë¸ í›ˆë ¨
                model.fit(X_train_scaled, y_train)

                # ì˜ˆì¸¡
                y_pred_train = model.predict(X_train_scaled)
                y_pred_test = model.predict(X_test_scaled)

                # ì„±ëŠ¥ í‰ê°€
                train_r2 = r2_score(y_train, y_pred_train)
                test_r2 = r2_score(y_test, y_pred_test)
                train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
                test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))

                # êµì°¨ ê²€ì¦
                cv_scores = cross_val_score(
                    model, X_train_scaled, y_train, cv=5, scoring="r2"
                )
                cv_mean = cv_scores.mean()
                cv_std = cv_scores.std()

                model_results[name] = {
                    "train_r2": train_r2,
                    "test_r2": test_r2,
                    "train_rmse": train_rmse,
                    "test_rmse": test_rmse,
                    "cv_mean": cv_mean,
                    "cv_std": cv_std,
                    "overfitting_gap": train_r2 - test_r2,
                    "model": model,
                    "scaler": scaler,
                }

                print(f"     Train RÂ²: {train_r2:.4f}")
                print(f"     Test RÂ²: {test_r2:.4f}")
                print(f"     CV RÂ²: {cv_mean:.4f} (Â±{cv_std:.4f})")
                print(f"     ê³¼ì í•© ê°„ê²©: {train_r2 - test_r2:.4f}")

            except Exception as e:
                print(f"     âŒ í›ˆë ¨ ì‹¤íŒ¨: {str(e)}")
                model_results[name] = None

        return model_results

    def create_competition_ensemble(
        self, X: np.ndarray, y: np.ndarray, model_results: Dict[str, Dict]
    ) -> Dict[str, Any]:
        """ëŒ€íšŒìš© ì•™ìƒë¸” ìƒì„±"""
        print("ğŸ¯ ëŒ€íšŒìš© ì•™ìƒë¸” ìƒì„± ì¤‘...")

        # ìœ íš¨í•œ ëª¨ë¸ë“¤ë§Œ ì„ íƒ
        valid_models = {k: v for k, v in model_results.items() if v is not None}

        if not valid_models:
            print("âŒ ìœ íš¨í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None

        # ì„±ëŠ¥ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_models = sorted(
            valid_models.items(),
            key=lambda x: x[1]["test_r2"] - x[1]["overfitting_gap"],
            reverse=True,
        )

        print(f"   ì„ íƒëœ ëª¨ë¸ë“¤: {[name for name, _ in sorted_models[:3]]}")

        # ìƒìœ„ 3ê°œ ëª¨ë¸ë¡œ ì•™ìƒë¸”
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42
        )

        predictions = []
        weights = []

        for name, results in sorted_models[:3]:
            model = results["model"]
            scaler = results["scaler"]

            X_test_scaled = scaler.transform(X_test)
            pred = model.predict(X_test_scaled)
            predictions.append(pred)

            # ê°€ì¤‘ì¹˜ ê³„ì‚° (ì„±ëŠ¥ ê¸°ë°˜)
            weight = results["test_r2"] - results["overfitting_gap"]
            weights.append(max(weight, 0.1))

        # ê°€ì¤‘ í‰ê·  ì•™ìƒë¸”
        weights = np.array(weights)
        weights = weights / weights.sum()

        ensemble_pred = np.average(predictions, axis=0, weights=weights)

        # ì•™ìƒë¸” ì„±ëŠ¥ í‰ê°€
        ensemble_r2 = r2_score(y_test, ensemble_pred)
        ensemble_rmse = np.sqrt(mean_squared_error(y_test, ensemble_pred))

        ensemble_results = {
            "r2": ensemble_r2,
            "rmse": ensemble_rmse,
            "mae": np.mean(np.abs(ensemble_pred - y_test)),
            "correlation": np.corrcoef(ensemble_pred, y_test)[0, 1],
            "selected_models": [name for name, _ in sorted_models[:3]],
            "model_weights": dict(
                zip([name for name, _ in sorted_models[:3]], weights)
            ),
            "predictions": ensemble_pred.tolist(),
            "targets": y_test.tolist(),
        }

        print(f"âœ… ëŒ€íšŒìš© ì•™ìƒë¸” ìƒì„± ì™„ë£Œ:")
        print(f"   RÂ²: {ensemble_r2:.4f}")
        print(f"   RMSE: {ensemble_rmse:.4f}")
        print(f"   ìƒê´€ê³„ìˆ˜: {ensemble_results['correlation']:.4f}")

        return ensemble_results

    def run_competition_strategy(self, limit: int = 10000) -> Dict[str, Any]:
        """ëŒ€íšŒ ì „ëµ ì‹¤í–‰"""
        print("ğŸš€ BigQuery ëŒ€íšŒ í˜„ì‹¤ì  ì „ëµ ì‹¤í–‰")
        print("=" * 60)
        print("ğŸ¯ ëª©í‘œ: RÂ² 0.3-0.5 (í˜„ì‹¤ì  ì„±ëŠ¥)")

        # 1. ë°ì´í„° ë¡œë”©
        multimodal_data = self.load_competition_data(limit)

        # 2. í˜„ì‹¤ì  íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±
        target = self.create_realistic_target_variable(multimodal_data)

        # 3. ëŒ€íšŒìš© í”¼ì²˜ ìƒì„±
        X = self.create_competition_features(multimodal_data)

        # 4. ëŒ€íšŒìš© ëª¨ë¸ ìƒì„±
        models = self.create_competition_models()

        # 5. ëª¨ë¸ í›ˆë ¨
        model_results = self.train_competition_models(X, target, models)

        # 6. ì•™ìƒë¸” ìƒì„±
        ensemble_results = self.create_competition_ensemble(X, target, model_results)

        # 7. ê²°ê³¼ í†µí•©
        results = {
            "individual_models": {
                name: {
                    "train_r2": results["train_r2"] if results else None,
                    "test_r2": results["test_r2"] if results else None,
                    "cv_mean": results["cv_mean"] if results else None,
                    "overfitting_gap": results["overfitting_gap"] if results else None,
                }
                for name, results in model_results.items()
            },
            "ensemble_results": ensemble_results,
            "data_info": {
                "n_samples": len(target),
                "n_features": X.shape[1],
                "n_models_trained": len(
                    [m for m in model_results.values() if m is not None]
                ),
                "target_stats": {
                    "mean": float(target.mean()),
                    "std": float(target.std()),
                    "min": float(target.min()),
                    "max": float(target.max()),
                },
            },
        }

        # 8. ê²°ê³¼ ì €ì¥
        with open("realistic_competition_strategy_results.json", "w") as f:
            json.dump(self._convert_to_json_serializable(results), f, indent=2)

        print("âœ… ëŒ€íšŒ ì „ëµ ì‹¤í–‰ ì™„ë£Œ!")
        if ensemble_results:
            print(f"   ìµœì¢… ì•™ìƒë¸” RÂ²: {ensemble_results['r2']:.4f}")
            print(f"   ëª©í‘œ ë‹¬ì„±: {'âœ…' if ensemble_results['r2'] >= 0.3 else 'âŒ'}")

        return results

    def _convert_to_json_serializable(self, obj):
        """JSON ì§ë ¬í™” ê°€ëŠ¥í•œ ê°ì²´ë¡œ ë³€í™˜"""
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, np.float32):
            return float(obj)
        elif isinstance(obj, np.float64):
            return float(obj)
        elif isinstance(obj, np.int32):
            return int(obj)
        elif isinstance(obj, np.int64):
            return int(obj)
        elif isinstance(obj, bool):
            return bool(obj)
        elif isinstance(obj, dict):
            return {k: self._convert_to_json_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._convert_to_json_serializable(item) for item in obj]
        else:
            return obj


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ BigQuery ëŒ€íšŒ í˜„ì‹¤ì  ì „ëµ")
    print("=" * 60)

    strategy = RealisticCompetitionStrategy()
    results = strategy.run_competition_strategy(limit=10000)

    print("\nğŸ“Š ëŒ€íšŒ ì „ëµ ê²°ê³¼:")
    if results["ensemble_results"]:
        print(f"   ìµœì¢… ì•™ìƒë¸” RÂ²: {results['ensemble_results']['r2']:.4f}")
        print(f"   ìµœì¢… ì•™ìƒë¸” RMSE: {results['ensemble_results']['rmse']:.4f}")
        print(f"   ìƒê´€ê³„ìˆ˜: {results['ensemble_results']['correlation']:.4f}")
        print(f"   ì„ íƒëœ ëª¨ë¸ë“¤: {results['ensemble_results']['selected_models']}")
        print(
            f"   ëª©í‘œ ë‹¬ì„±: {'âœ… ë‹¬ì„±' if results['ensemble_results']['r2'] >= 0.3 else 'âŒ ë¯¸ë‹¬ì„±'}"
        )


if __name__ == "__main__":
    main()
