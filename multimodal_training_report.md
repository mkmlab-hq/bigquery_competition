# ë©€í‹°ëª¨ë‹¬ í›ˆë ¨ í†µí•© ë³´ê³ ì„œ

## ğŸ“Š í›ˆë ¨ ê°œìš”
- **í”„ë¡œì íŠ¸ ID**: persona-diary-service
- **ìƒì„± ì‹œê°„**: 2025-09-21 03:30:45
- **ì´ í›ˆë ¨ ë°©ë²•**: 3ê°œ

## ğŸ§  í›ˆë ¨ ê²°ê³¼ ìƒì„¸

### Advanced Training
- **ìƒíƒœ**: failed
- **ì˜¤ë¥˜**: 
Epoch 1/100:   0%|          | 0/110 [00:00<?, ?it/s]
Epoch 1/100:   0%|          | 0/110 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "f:\workspace\bigquery_competition\optimization\advanced_multimodal_training.py", line 832, in <module>
    main()
  File "f:\workspace\bigquery_competition\optimization\advanced_multimodal_training.py", line 822, in main
    results = trainer.run_comprehensive_training(n_samples=10000, epochs=100)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\workspace\bigquery_competition\optimization\advanced_multimodal_training.py", line 770, in run_comprehensive_training
    training_results = self.train_model(train_loader, val_loader, epochs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\workspace\bigquery_competition\optimization\advanced_multimodal_training.py", line 479, in train_model
    outputs, attention_info, dynamic_weights = self.model(
                                               ^^^^^^^^^^^
  File "F:\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\workspace\bigquery_competition\optimization\advanced_multimodal_training.py", line 198, in forward
    attended_features, cross_attention_weights = self.cross_attention(
                                                 ^^^^^^^^^^^^^^^^^^^^^
  File "F:\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Python\Python311\Lib\site-packages\torch\nn\modules\activation.py", line 1380, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Python\Python311\Lib\site-packages\torch\nn\functional.py", line 6304, in multi_head_attention_forward
    q, k, v = _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Python\Python311\Lib\site-packages\torch\nn\functional.py", line 5713, in _in_projection_packed
    kv_proj = linear(k, w_kv, b_kv)
              ^^^^^^^^^^^^^^^^^^^^^
RuntimeError: mat1 and mat2 shapes cannot be multiplied (192x128 and 64x128)


### Realtime Learning
- **ìƒíƒœ**: success

### Performance Optimization
- **ìƒíƒœ**: success
- **TorchScript Throughput**: 111710.6 samples/sec
- **Speedup**: 0.94x
- **Optimal Batch Size**: 512
- **Memory Usage**: 464.1 MB

## ğŸ“ˆ í›ˆë ¨ ìš”ì•½
- **ì„±ê³µí•œ í›ˆë ¨**: 2/3ê°œ
- **ì„±ê³µë¥ **: 66.7%

## ğŸ¯ ê¶Œì¥ì‚¬í•­

- âš ï¸ ì„±ëŠ¥ ìµœì í™” íš¨ê³¼ê°€ ì œí•œì ì…ë‹ˆë‹¤

## ğŸ“ ìƒì„±ëœ íŒŒì¼
- `multimodal_training_comparison.png`: ì¢…í•© ë¹„êµ ë¶„ì„ ì°¨íŠ¸
- `multimodal_training_results.json`: ê³ ê¸‰ í›ˆë ¨ ê²°ê³¼ (ìˆëŠ” ê²½ìš°)
- `multimodal_optimization_results.json`: ì„±ëŠ¥ ìµœì í™” ê²°ê³¼ (ìˆëŠ” ê²½ìš°)
- `realtime_performance.png`: ì‹¤ì‹œê°„ í•™ìŠµ ì„±ëŠ¥ ì°¨íŠ¸ (ìˆëŠ” ê²½ìš°)

---
*ì´ ë³´ê³ ì„œëŠ” ë©€í‹°ëª¨ë‹¬ í›ˆë ¨ í†µí•© ìŠ¤ìœ„íŠ¸ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*
