#!/usr/bin/env python3
"""
Multimodal Integrated System
4ê°œ ë°ì´í„°ì…‹(Big5, CMI, RPPG, Voice)ì„ í†µí•©í•œ ë©€í‹°ëª¨ë‹¬ AI ì‹œìŠ¤í…œ
"""

import json
import os
from typing import Any, Dict, List, Tuple

import google.cloud.bigquery as bigquery
import numpy as np
import pandas as pd
from google.cloud import aiplatform
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import StandardScaler

from ai_generate_system import AIGenerateSystem
from vector_search_system import Big5VectorSearch


class MultimodalIntegratedSystem:
    def __init__(self, project_id: str = "persona-diary-service"):
        """ë©€í‹°ëª¨ë‹¬ í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.project_id = project_id
        self.client = bigquery.Client(project=project_id)

        # ê° ëª¨ë‹¬ë¦¬í‹°ë³„ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.big5_system = Big5VectorSearch(project_id)
        self.ai_generate = AIGenerateSystem(project_id)

        # ë°ì´í„°ì…‹ ë§¤í•‘
        self.datasets = {
            "big5": "big5_dataset.big5_preprocessed",
            "cmi": "cmi_dataset.cmi_preprocessed",
            "rppg": "rppg_dataset.rppg_preprocessed",
            "voice": "voice_dataset.voice_preprocessed",
        }

    def load_multimodal_data(self, limit: int = 1000) -> Dict[str, pd.DataFrame]:
        """ëª¨ë“  ëª¨ë‹¬ë¦¬í‹° ë°ì´í„° ë¡œë“œ"""
        print("ğŸ”„ ë©€í‹°ëª¨ë‹¬ ë°ì´í„° ë¡œë”© ì¤‘...")

        multimodal_data = {}

        for modality, table_path in self.datasets.items():
            try:
                query = f"SELECT * FROM `{self.project_id}.{table_path}` LIMIT {limit}"
                print(f"   ğŸ“Š {modality.upper()} ë°ì´í„° ë¡œë”© ì¤‘...")

                df = self.client.query(query).to_dataframe()
                multimodal_data[modality] = df
                print(f"   âœ… {modality.upper()}: {len(df)}ê±´ ë¡œë“œ ì™„ë£Œ")

            except Exception as e:
                print(f"   âŒ {modality.upper()} ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                multimodal_data[modality] = pd.DataFrame()

        return multimodal_data

    def analyze_data_structure(self, data: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
        """ê° ëª¨ë‹¬ë¦¬í‹° ë°ì´í„° êµ¬ì¡° ë¶„ì„"""
        print("\nğŸ” ë°ì´í„° êµ¬ì¡° ë¶„ì„ ì¤‘...")

        structure_analysis = {}

        for modality, df in data.items():
            if df.empty:
                structure_analysis[modality] = {
                    "status": "empty",
                    "columns": [],
                    "shape": (0, 0),
                }
                continue

            structure_analysis[modality] = {
                "status": "loaded",
                "columns": list(df.columns),
                "shape": df.shape,
                "dtypes": df.dtypes.to_dict(),
                "sample_data": df.head(2).to_dict() if len(df) > 0 else {},
            }

        return structure_analysis

    def create_unified_user_profile(
        self,
        big5_scores: Dict[str, float],
        cmi_data: Dict[str, Any] = None,
        rppg_data: Dict[str, Any] = None,
        voice_data: Dict[str, Any] = None,
    ) -> Dict[str, Any]:
        """í†µí•© ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„±"""
        print("\nğŸ‘¤ í†µí•© ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„± ì¤‘...")

        unified_profile = {
            "personality": {
                "big5_scores": big5_scores,
                "personality_type": self.classify_personality_type(big5_scores),
            },
            "health_metrics": {
                "cmi_data": cmi_data or {},
                "rppg_data": rppg_data or {},
                "voice_data": voice_data or {},
            },
            "integrated_insights": [],
            "recommendations": [],
        }

        # í†µí•© ì¸ì‚¬ì´íŠ¸ ìƒì„±
        insights = self.generate_integrated_insights(
            big5_scores, cmi_data, rppg_data, voice_data
        )
        unified_profile["integrated_insights"] = insights

        # í†µí•© ì¶”ì²œ ìƒì„±
        recommendations = self.generate_integrated_recommendations(unified_profile)
        unified_profile["recommendations"] = recommendations

        return unified_profile

    def classify_personality_type(self, big5_scores: Dict[str, float]) -> str:
        """Big5 ì ìˆ˜ ê¸°ë°˜ ì„±ê²© ìœ í˜• ë¶„ë¥˜"""
        # ê°„ë‹¨í•œ ì„±ê²© ìœ í˜• ë¶„ë¥˜ ë¡œì§
        ext = big5_scores.get("EXT", 3.0)
        est = big5_scores.get("EST", 3.0)
        agr = big5_scores.get("AGR", 3.0)
        csn = big5_scores.get("CSN", 3.0)
        opn = big5_scores.get("OPN", 3.0)

        if ext > 4.0 and opn > 4.0:
            return "ì°½ì˜ì  ë¦¬ë”"
        elif ext > 4.0 and agr > 4.0:
            return "ì‚¬íšŒì  í˜‘ë ¥ì"
        elif csn > 4.0 and est < 3.0:
            return "ì•ˆì •ì  ì„±ì·¨ì"
        elif opn > 4.0 and est < 3.0:
            return "í˜ì‹ ì  íƒí—˜ê°€"
        else:
            return "ê· í˜•ì¡íŒ ì¼ë°˜ì¸"

    def generate_integrated_insights(
        self,
        big5_scores: Dict[str, float],
        cmi_data: Dict[str, Any],
        rppg_data: Dict[str, Any],
        voice_data: Dict[str, Any],
    ) -> List[str]:
        """í†µí•© ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        insights = []

        # Big5 ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
        if big5_scores.get("EXT", 3.0) > 4.0:
            insights.append("ì™¸í–¥ì ì¸ ì„±ê²©ìœ¼ë¡œ ì‚¬íšŒì  í™œë™ì—ì„œ ì—ë„ˆì§€ë¥¼ ì–»ìŠµë‹ˆë‹¤.")

        if big5_scores.get("OPN", 3.0) > 4.0:
            insights.append("ê°œë°©ì ì¸ ì„±ê²©ìœ¼ë¡œ ìƒˆë¡œìš´ ê²½í—˜ì„ ì ê·¹ì ìœ¼ë¡œ ì¶”êµ¬í•©ë‹ˆë‹¤.")

        # ê±´ê°• ì§€í‘œ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ (ì‹¤ì œ ë°ì´í„°ê°€ ìˆì„ ê²½ìš°)
        if cmi_data:
            insights.append("CMI ë°ì´í„°ë¥¼ í†µí•œ ê±´ê°• ìƒíƒœ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

        if rppg_data:
            insights.append(
                "RPPG ë°ì´í„°ë¥¼ í†µí•œ ì‹¬ë°•ìˆ˜ ê¸°ë°˜ ìŠ¤íŠ¸ë ˆìŠ¤ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
            )

        if voice_data:
            insights.append("ìŒì„± ë°ì´í„°ë¥¼ í†µí•œ ê°ì • ìƒíƒœ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

        return insights

    def generate_integrated_recommendations(
        self, profile: Dict[str, Any]
    ) -> List[Dict[str, str]]:
        """í†µí•© ì¶”ì²œ ìƒì„±"""
        recommendations = []

        personality_type = profile["personality"]["personality_type"]

        # ì„±ê²© ìœ í˜•ë³„ ì¶”ì²œ
        if personality_type == "ì°½ì˜ì  ë¦¬ë”":
            recommendations.append(
                {
                    "category": "í™œë™",
                    "recommendation": "ì°½ì˜ì  í”„ë¡œì íŠ¸ ë¦¬ë”ì‹­ ì—­í• ì„ ì¶”ì²œí•©ë‹ˆë‹¤.",
                    "priority": "high",
                }
            )
        elif personality_type == "ì‚¬íšŒì  í˜‘ë ¥ì":
            recommendations.append(
                {
                    "category": "í™œë™",
                    "recommendation": "íŒ€ì›Œí¬ ì¤‘ì‹¬ì˜ í˜‘ë ¥ í™œë™ì„ ì¶”ì²œí•©ë‹ˆë‹¤.",
                    "priority": "high",
                }
            )

        # ê±´ê°• ì§€í‘œ ê¸°ë°˜ ì¶”ì²œ
        if profile["health_metrics"]["cmi_data"]:
            recommendations.append(
                {
                    "category": "ê±´ê°•",
                    "recommendation": "ì •ê¸°ì ì¸ ê±´ê°• ì²´í¬ì—…ì„ ì¶”ì²œí•©ë‹ˆë‹¤.",
                    "priority": "medium",
                }
            )

        return recommendations

    def run_comprehensive_analysis(
        self, target_user: Dict[str, float], data_limit: int = 1000
    ) -> Dict[str, Any]:
        """ì¢…í•© ë¶„ì„ ì‹¤í–‰"""
        print("ğŸš€ ë©€í‹°ëª¨ë‹¬ í†µí•© ì‹œìŠ¤í…œ ì‹œì‘")
        print("=" * 60)

        # 1. ë©€í‹°ëª¨ë‹¬ ë°ì´í„° ë¡œë“œ
        multimodal_data = self.load_multimodal_data(limit=data_limit)

        # 2. ë°ì´í„° êµ¬ì¡° ë¶„ì„
        structure_analysis = self.analyze_data_structure(multimodal_data)

        # 3. Big5 ê¸°ë°˜ Vector Search
        print("\nğŸ” Vector Search ì‹¤í–‰ ì¤‘...")
        similar_users = self.big5_system.search_similar_users(
            target_user_data=target_user, all_data=multimodal_data["big5"], top_k=5
        )

        # 4. AI Generate ì‹¤í–‰
        print("\nğŸ¤– AI Generate ì‹¤í–‰ ì¤‘...")
        ai_report = self.ai_generate.generate_comprehensive_report(
            target_user, multimodal_data["big5"]
        )

        # 5. í†µí•© ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„±
        unified_profile = self.create_unified_user_profile(target_user)

        # 6. ì¢…í•© ê²°ê³¼ êµ¬ì„±
        comprehensive_result = {
            "system_info": {
                "project_id": self.project_id,
                "data_limit": data_limit,
                "analysis_timestamp": pd.Timestamp.now().isoformat(),
            },
            "data_status": structure_analysis,
            "vector_search_results": similar_users,
            "ai_generate_report": ai_report,
            "unified_profile": unified_profile,
            "multimodal_insights": {
                "total_modalities": len(
                    [m for m in multimodal_data.values() if not m.empty]
                ),
                "successful_analyses": len(
                    [m for m in multimodal_data.values() if not m.empty]
                ),
                "integration_status": "successful",
            },
        }

        return comprehensive_result


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸŒŸ ë©€í‹°ëª¨ë‹¬ í†µí•© AI ì‹œìŠ¤í…œ")
    print("=" * 60)

    # í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    integrated_system = MultimodalIntegratedSystem()

    # ìƒ˜í”Œ íƒ€ê²Ÿ ì‚¬ìš©ì (ì°½ì˜ì ì´ê³  ê°œë°©ì ì¸ ì„±ê²©)
    target_user = {
        "EXT": 4.2,  # ë†’ì€ ì™¸í–¥ì„±
        "EST": 2.5,  # ë‚®ì€ ì‹ ê²½ì¦
        "AGR": 4.5,  # ë†’ì€ ì¹œí™”ì„±
        "CSN": 3.8,  # ì¤‘ê°„ ì„±ì‹¤ì„±
        "OPN": 4.7,  # ë†’ì€ ê°œë°©ì„±
    }

    print(f"ğŸ¯ íƒ€ê²Ÿ ì‚¬ìš©ì: {target_user}")

    # ì¢…í•© ë¶„ì„ ì‹¤í–‰
    result = integrated_system.run_comprehensive_analysis(target_user, data_limit=500)

    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 80)
    print("ğŸ‰ ë©€í‹°ëª¨ë‹¬ í†µí•© ë¶„ì„ ê²°ê³¼")
    print("=" * 80)

    print(f"\nğŸ“Š ë°ì´í„° ìƒíƒœ:")
    for modality, status in result["data_status"].items():
        if status["status"] == "loaded":
            print(f"   âœ… {modality.upper()}: {status['shape'][0]}ê±´ ë¡œë“œ")
        else:
            print(f"   âŒ {modality.upper()}: ë¡œë“œ ì‹¤íŒ¨")

    print(f"\nğŸ‘¥ Vector Search ê²°ê³¼:")
    for i, user in enumerate(result["vector_search_results"], 1):
        print(f"   {i}. ìœ ì‚¬ë„ {user['similarity_score']:.3f} - {user['country']}")

    print(f"\nğŸ­ í†µí•© ì‚¬ìš©ì í”„ë¡œí•„:")
    profile = result["unified_profile"]
    print(f"   ì„±ê²© ìœ í˜•: {profile['personality']['personality_type']}")
    print(f"   Big5 ì ìˆ˜: {profile['personality']['big5_scores']}")

    print(f"\nğŸ’¡ í†µí•© ì¸ì‚¬ì´íŠ¸:")
    for insight in profile["integrated_insights"]:
        print(f"   â€¢ {insight}")

    print(f"\nğŸ¯ í†µí•© ì¶”ì²œ:")
    for rec in profile["recommendations"]:
        print(
            f"   [{rec['category']}] {rec['recommendation']} (ìš°ì„ ìˆœìœ„: {rec['priority']})"
        )

    print(f"\nğŸ“ˆ ë©€í‹°ëª¨ë‹¬ í†µí•© ìƒíƒœ:")
    insights = result["multimodal_insights"]
    print(f"   ì´ ëª¨ë‹¬ë¦¬í‹°: {insights['total_modalities']}ê°œ")
    print(f"   ì„±ê³µì  ë¶„ì„: {insights['successful_analyses']}ê°œ")
    print(f"   í†µí•© ìƒíƒœ: {insights['integration_status']}")

    print(f"\nâ° ë¶„ì„ ì™„ë£Œ ì‹œê°„: {result['system_info']['analysis_timestamp']}")
    print("\nğŸ‰ ë©€í‹°ëª¨ë‹¬ í†µí•© ì‹œìŠ¤í…œ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
