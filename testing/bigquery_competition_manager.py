#!/usr/bin/env python3
"""
BigQuery ëŒ€íšŒ í•µì‹¬ íŒŒì¼ í†µí•© ê´€ë¦¬ ì‹œìŠ¤í…œ
- ëª¨ë“  í•µì‹¬ ì‹œìŠ¤í…œì„ í•œ ê³³ì—ì„œ ê´€ë¦¬
- í†µí•© ì‹¤í–‰ ë° ëª¨ë‹ˆí„°ë§
- ê²°ê³¼ í†µí•© ë° ë³´ê³ ì„œ ìƒì„±
"""

import os
import sys
import json
import time
from datetime import datetime
from typing import Dict, List, Optional
import warnings

warnings.filterwarnings("ignore", category=UserWarning)


class BigQueryCompetitionManager:
    def __init__(self, project_id: str = "persona-diary-service"):
        self.project_id = project_id
        self.results_dir = "bigquery_competition_results"
        self.core_systems = {}
        self.results = {}
        
        # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.results_dir, exist_ok=True)
        
        # í•µì‹¬ ì‹œìŠ¤í…œ íŒŒì¼ë“¤ ì •ì˜
        self.core_files = {
            "vector_search": "vector_search_system.py",
            "ai_generate": "ai_generate_system.py", 
            "multimodal": "multimodal_integrated_system.py",
            "data_quality": "data_quality_improvement.py",
            "shap_analysis": "enhanced_shap_analysis.py",
            "clustering": "advanced_big5_clustering.py",
            "correlation": "advanced_correlation_analysis.py",
            "visualization": "advanced_big5_visualization.py",
            "bigquery_opt": "bigquery_optimization_strategy.py",
            "integration_test": "integration_test.py"
        }
        
        print("ğŸš€ BigQuery ëŒ€íšŒ í†µí•© ê´€ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        print("=" * 60)

    def check_core_files(self):
        """í•µì‹¬ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        print("ğŸ“ í•µì‹¬ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ì¤‘...")
        
        missing_files = []
        existing_files = []
        
        for system_name, filename in self.core_files.items():
            if os.path.exists(filename):
                existing_files.append(filename)
                print(f"  âœ… {filename}")
            else:
                missing_files.append(filename)
                print(f"  âŒ {filename} - ëˆ„ë½")
        
        print(f"\nğŸ“Š íŒŒì¼ ìƒíƒœ: {len(existing_files)}ê°œ ì¡´ì¬, {len(missing_files)}ê°œ ëˆ„ë½")
        
        if missing_files:
            print("\nâš ï¸ ëˆ„ë½ëœ íŒŒì¼ë“¤:")
            for file in missing_files:
                print(f"  - {file}")
        
        return existing_files, missing_files

    def run_vector_search_system(self):
        """Vector Search ì‹œìŠ¤í…œ ì‹¤í–‰"""
        print("\nğŸ” Vector Search ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘...")
        try:
            from vector_search_system import Big5VectorSearch
            
            vs = Big5VectorSearch(project_id=self.project_id)
            data = vs.load_data(limit=1000)
            
            # ìƒ˜í”Œ íƒ€ê²Ÿ ì‚¬ìš©ì
            target_user = {
                "EXT": 4.5, "EST": 2.0, "AGR": 4.0, 
                "CSN": 3.5, "OPN": 4.8
            }
            
            # ìœ ì‚¬ ì‚¬ìš©ì ê²€ìƒ‰
            similar_users = vs.search_similar_users(target_user, data, top_k=10)
            
            self.results["vector_search"] = {
                "status": "success",
                "data_size": len(data),
                "similar_users_count": len(similar_users),
                "top_similarity": similar_users[0]["similarity_score"] if similar_users else 0
            }
            
            print(f"  âœ… Vector Search ì™„ë£Œ: {len(similar_users)}ëª… ìœ ì‚¬ ì‚¬ìš©ì ë°œê²¬")
            
        except Exception as e:
            self.results["vector_search"] = {"status": "error", "error": str(e)}
            print(f"  âŒ Vector Search ì‹¤íŒ¨: {e}")

    def run_ai_generate_system(self):
        """AI Generate ì‹œìŠ¤í…œ ì‹¤í–‰"""
        print("\nğŸ¤– AI Generate ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘...")
        try:
            from ai_generate_system import AIGenerateSystem
            
            ai = AIGenerateSystem(project_id=self.project_id)
            
            # ìƒ˜í”Œ íƒ€ê²Ÿ ì‚¬ìš©ì
            target_user = {
                "EXT": 4.5, "EST": 2.0, "AGR": 4.0, 
                "CSN": 3.5, "OPN": 4.8
            }
            
            # ì¢…í•© ë³´ê³ ì„œ ìƒì„±
            report = ai.generate_comprehensive_report(target_user)
            
            self.results["ai_generate"] = {
                "status": "success",
                "report_sections": len(report),
                "recommendations_count": len(report.get("personalized_recommendations", [])),
                "shap_insights_count": len(report.get("shap_insights", []))
            }
            
            print(f"  âœ… AI Generate ì™„ë£Œ: {len(report)}ê°œ ì„¹ì…˜ ìƒì„±")
            
        except Exception as e:
            self.results["ai_generate"] = {"status": "error", "error": str(e)}
            print(f"  âŒ AI Generate ì‹¤íŒ¨: {e}")

    def run_clustering_analysis(self):
        """ê³ ê¸‰ í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ ì‹¤í–‰"""
        print("\nğŸ­ ê³ ê¸‰ í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ ì‹¤í–‰ ì¤‘...")
        try:
            from advanced_big5_clustering import AdvancedBig5Clustering
            
            clustering = AdvancedBig5Clustering(project_id=self.project_id)
            results = clustering.run_advanced_clustering_analysis(limit=2000)
            
            if results:
                self.results["clustering"] = {
                    "status": "success",
                    "best_algorithm": results["best_algorithm"],
                    "clusters_count": len(results["cluster_characteristics"]),
                    "data_size": len(results["big5_df"])
                }
                print(f"  âœ… í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ: {results['best_algorithm']} ì•Œê³ ë¦¬ì¦˜")
            else:
                self.results["clustering"] = {"status": "error", "error": "í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨"}
                print("  âŒ í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨")
                
        except Exception as e:
            self.results["clustering"] = {"status": "error", "error": str(e)}
            print(f"  âŒ í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨: {e}")

    def run_correlation_analysis(self):
        """ê³ ê¸‰ ìƒê´€ê´€ê³„ ë¶„ì„ ì‹¤í–‰"""
        print("\nğŸ“Š ê³ ê¸‰ ìƒê´€ê´€ê³„ ë¶„ì„ ì‹¤í–‰ ì¤‘...")
        try:
            from advanced_correlation_analysis import AdvancedCorrelationAnalysis
            
            correlation = AdvancedCorrelationAnalysis(project_id=self.project_id)
            results = correlation.run_advanced_correlation_analysis(limit=2000)
            
            if results:
                self.results["correlation"] = {
                    "status": "success",
                    "pearson_correlations": len(results["pearson_correlations"]),
                    "nonlinear_relationships": len(results["nonlinear_relationships"]),
                    "high_mi_relationships": len(results["high_mi_relationships"]),
                    "countries_analyzed": len(results["country_analysis"])
                }
                print(f"  âœ… ìƒê´€ê´€ê³„ ë¶„ì„ ì™„ë£Œ: {len(results['pearson_correlations'])}ê°œ ìƒê´€ê´€ê³„")
            else:
                self.results["correlation"] = {"status": "error", "error": "ìƒê´€ê´€ê³„ ë¶„ì„ ì‹¤íŒ¨"}
                print("  âŒ ìƒê´€ê´€ê³„ ë¶„ì„ ì‹¤íŒ¨")
                
        except Exception as e:
            self.results["correlation"] = {"status": "error", "error": str(e)}
            print(f"  âŒ ìƒê´€ê´€ê³„ ë¶„ì„ ì‹¤íŒ¨: {e}")

    def run_visualization_system(self):
        """ê³ ê¸‰ ì‹œê°í™” ì‹œìŠ¤í…œ ì‹¤í–‰"""
        print("\nğŸ“ˆ ê³ ê¸‰ ì‹œê°í™” ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘...")
        try:
            from advanced_big5_visualization import AdvancedBig5Visualization
            
            visualizer = AdvancedBig5Visualization(project_id=self.project_id)
            results = visualizer.create_comprehensive_visualization(limit=2000)
            
            if results:
                self.results["visualization"] = {
                    "status": "success",
                    "cluster_means_count": len(results["cluster_means"]),
                    "country_means_count": len(results["country_means"]),
                    "feature_importance_count": len(results["feature_importance"])
                }
                print(f"  âœ… ì‹œê°í™” ì™„ë£Œ: {len(results['cluster_means'])}ê°œ í´ëŸ¬ìŠ¤í„° ì‹œê°í™”")
            else:
                self.results["visualization"] = {"status": "error", "error": "ì‹œê°í™” ì‹¤íŒ¨"}
                print("  âŒ ì‹œê°í™” ì‹¤íŒ¨")
                
        except Exception as e:
            self.results["visualization"] = {"status": "error", "error": str(e)}
            print(f"  âŒ ì‹œê°í™” ì‹¤íŒ¨: {e}")

    def run_bigquery_optimization(self):
        """BigQuery ìµœì í™” ë¶„ì„ ì‹¤í–‰"""
        print("\nâš¡ BigQuery ìµœì í™” ë¶„ì„ ì‹¤í–‰ ì¤‘...")
        try:
            from bigquery_optimization_strategy import BigQueryOptimizationStrategy
            
            optimizer = BigQueryOptimizationStrategy(project_id=self.project_id)
            results = optimizer.run_optimization_analysis()
            
            if results:
                self.results["bigquery_opt"] = {
                    "status": "success",
                    "queries_tested": len(results["current_performance"]),
                    "optimizations_successful": len(results["recommendations"]),
                    "materialized_views": len(results["materialized_views"])
                }
                print(f"  âœ… BigQuery ìµœì í™” ì™„ë£Œ: {len(results['recommendations'])}ê°œ ìµœì í™”")
            else:
                self.results["bigquery_opt"] = {"status": "error", "error": "BigQuery ìµœì í™” ì‹¤íŒ¨"}
                print("  âŒ BigQuery ìµœì í™” ì‹¤íŒ¨")
                
        except Exception as e:
            self.results["bigquery_opt"] = {"status": "error", "error": str(e)}
            print(f"  âŒ BigQuery ìµœì í™” ì‹¤íŒ¨: {e}")

    def run_integration_test(self):
        """í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("\nğŸ”— í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
        try:
            from integration_test import test_integration
            
            # í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
            test_integration()
            
            self.results["integration_test"] = {
                "status": "success",
                "message": "í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ"
            }
            print("  âœ… í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
            
        except Exception as e:
            self.results["integration_test"] = {"status": "error", "error": str(e)}
            print(f"  âŒ í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

    def run_all_systems(self):
        """ëª¨ë“  í•µì‹¬ ì‹œìŠ¤í…œ ì‹¤í–‰"""
        print("ğŸš€ ëª¨ë“  í•µì‹¬ ì‹œìŠ¤í…œ ì‹¤í–‰ ì‹œì‘")
        print("=" * 60)
        
        start_time = time.time()
        
        # 1. íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        existing_files, missing_files = self.check_core_files()
        
        # 2. í•µì‹¬ ì‹œìŠ¤í…œë“¤ ìˆœì°¨ ì‹¤í–‰
        self.run_vector_search_system()
        self.run_ai_generate_system()
        self.run_clustering_analysis()
        self.run_correlation_analysis()
        self.run_visualization_system()
        self.run_bigquery_optimization()
        self.run_integration_test()
        
        execution_time = time.time() - start_time
        
        # 3. ê²°ê³¼ ìš”ì•½
        self.create_summary_report(execution_time, existing_files, missing_files)
        
        print(f"\nğŸ‰ ëª¨ë“  ì‹œìŠ¤í…œ ì‹¤í–‰ ì™„ë£Œ! (ì´ {execution_time:.2f}ì´ˆ)")
        print(f"   ê²°ê³¼ ì €ì¥: {self.results_dir}/")

    def create_summary_report(self, execution_time: float, existing_files: List[str], missing_files: List[str]):
        """ì¢…í•© ë³´ê³ ì„œ ìƒì„±"""
        print("\nğŸ“‹ ì¢…í•© ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        
        # ì„±ê³µ/ì‹¤íŒ¨ í†µê³„
        successful_systems = [name for name, result in self.results.items() if result["status"] == "success"]
        failed_systems = [name for name, result in self.results.items() if result["status"] == "error"]
        
        summary_report = {
            "timestamp": datetime.now().isoformat(),
            "project_id": self.project_id,
            "execution_time": execution_time,
            "file_status": {
                "existing_files": existing_files,
                "missing_files": missing_files,
                "total_files": len(self.core_files)
            },
            "system_results": self.results,
            "summary": {
                "total_systems": len(self.results),
                "successful_systems": len(successful_systems),
                "failed_systems": len(failed_systems),
                "success_rate": len(successful_systems) / len(self.results) * 100 if self.results else 0
            }
        }
        
        # JSON ë³´ê³ ì„œ ì €ì¥
        with open(f"{self.results_dir}/competition_summary.json", "w", encoding="utf-8") as f:
            json.dump(summary_report, f, indent=2, ensure_ascii=False)
        
        # í…ìŠ¤íŠ¸ ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
        with open(f"{self.results_dir}/competition_summary.txt", "w", encoding="utf-8") as f:
            f.write("BigQuery ëŒ€íšŒ í•µì‹¬ ì‹œìŠ¤í…œ ì¢…í•© ë³´ê³ ì„œ\n")
            f.write("=" * 60 + "\n\n")
            f.write(f"ì‹¤í–‰ ì‹œê°„: {summary_report['timestamp']}\n")
            f.write(f"í”„ë¡œì íŠ¸ ID: {summary_report['project_id']}\n")
            f.write(f"ì´ ì‹¤í–‰ ì‹œê°„: {execution_time:.2f}ì´ˆ\n\n")
            
            f.write("íŒŒì¼ ìƒíƒœ:\n")
            f.write(f"- ì¡´ì¬í•˜ëŠ” íŒŒì¼: {len(existing_files)}ê°œ\n")
            f.write(f"- ëˆ„ë½ëœ íŒŒì¼: {len(missing_files)}ê°œ\n\n")
            
            f.write("ì‹œìŠ¤í…œ ì‹¤í–‰ ê²°ê³¼:\n")
            f.write(f"- ì´ ì‹œìŠ¤í…œ: {summary_report['summary']['total_systems']}ê°œ\n")
            f.write(f"- ì„±ê³µ: {summary_report['summary']['successful_systems']}ê°œ\n")
            f.write(f"- ì‹¤íŒ¨: {summary_report['summary']['failed_systems']}ê°œ\n")
            f.write(f"- ì„±ê³µë¥ : {summary_report['summary']['success_rate']:.1f}%\n\n")
            
            f.write("ì‹œìŠ¤í…œë³„ ìƒì„¸ ê²°ê³¼:\n")
            for system_name, result in self.results.items():
                status = "âœ… ì„±ê³µ" if result["status"] == "success" else "âŒ ì‹¤íŒ¨"
                f.write(f"- {system_name}: {status}\n")
                if result["status"] == "error":
                    f.write(f"  ì˜¤ë¥˜: {result['error']}\n")
        
        print(f"âœ… ì¢…í•© ë³´ê³ ì„œ ì €ì¥: {self.results_dir}/competition_summary.json")
        print(f"âœ… ìš”ì•½ ë³´ê³ ì„œ ì €ì¥: {self.results_dir}/competition_summary.txt")

    def show_system_status(self):
        """ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ"""
        print("\nğŸ“Š í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœ")
        print("=" * 40)
        
        for system_name, result in self.results.items():
            status = "âœ… ì„±ê³µ" if result["status"] == "success" else "âŒ ì‹¤íŒ¨"
            print(f"{system_name:20} : {status}")
            
            if result["status"] == "error":
                print(f"{'':20}   ì˜¤ë¥˜: {result['error']}")

    def run_quick_test(self):
        """ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (í•µì‹¬ ì‹œìŠ¤í…œë§Œ)"""
        print("âš¡ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (í•µì‹¬ ì‹œìŠ¤í…œë§Œ)")
        print("=" * 50)
        
        self.run_vector_search_system()
        self.run_ai_generate_system()
        self.run_integration_test()
        
        print("\nğŸ‰ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

    def create_file_structure(self):
        """íŒŒì¼ êµ¬ì¡° ìƒì„±"""
        print("\nğŸ“ BigQuery ëŒ€íšŒ íŒŒì¼ êµ¬ì¡° ìƒì„± ì¤‘...")
        
        structure = {
            "bigquery_competition/": {
                "core_systems/": {
                    "vector_search_system.py": "ë²¡í„° ê²€ìƒ‰ ì‹œìŠ¤í…œ",
                    "ai_generate_system.py": "AI ìƒì„± ì‹œìŠ¤í…œ", 
                    "multimodal_integrated_system.py": "ë©€í‹°ëª¨ë‹¬ í†µí•© ì‹œìŠ¤í…œ",
                    "enhanced_shap_analysis.py": "SHAP ë¶„ì„ ì‹œìŠ¤í…œ"
                },
                "analysis/": {
                    "advanced_big5_clustering.py": "ê³ ê¸‰ í´ëŸ¬ìŠ¤í„°ë§",
                    "advanced_correlation_analysis.py": "ìƒê´€ê´€ê³„ ë¶„ì„",
                    "advanced_big5_visualization.py": "ì‹œê°í™” ì‹œìŠ¤í…œ"
                },
                "optimization/": {
                    "bigquery_optimization_strategy.py": "BigQuery ìµœì í™”",
                    "data_quality_improvement.py": "ë°ì´í„° í’ˆì§ˆ ê°œì„ "
                },
                "testing/": {
                    "integration_test.py": "í†µí•© í…ŒìŠ¤íŠ¸",
                    "bigquery_competition_manager.py": "í†µí•© ê´€ë¦¬ì"
                },
                "results/": {
                    "advanced_clustering_results/": "í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼",
                    "correlation_analysis_results/": "ìƒê´€ê´€ê³„ ë¶„ì„ ê²°ê³¼",
                    "advanced_visualization_results/": "ì‹œê°í™” ê²°ê³¼",
                    "bigquery_optimization_results/": "BigQuery ìµœì í™” ê²°ê³¼",
                    "bigquery_competition_results/": "í†µí•© ê²°ê³¼"
                }
            }
        }
        
        # êµ¬ì¡°ë¥¼ JSONìœ¼ë¡œ ì €ì¥
        with open(f"{self.results_dir}/file_structure.json", "w", encoding="utf-8") as f:
            json.dump(structure, f, indent=2, ensure_ascii=False)
        
        print("âœ… íŒŒì¼ êµ¬ì¡° ìƒì„± ì™„ë£Œ")
        return structure


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ§  BigQuery ëŒ€íšŒ í†µí•© ê´€ë¦¬ ì‹œìŠ¤í…œ")
    print("=" * 50)
    
    manager = BigQueryCompetitionManager()
    
    while True:
        print("\nğŸ“‹ ë©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
        print("1. ëª¨ë“  ì‹œìŠ¤í…œ ì‹¤í–‰")
        print("2. ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (í•µì‹¬ ì‹œìŠ¤í…œë§Œ)")
        print("3. ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸")
        print("4. íŒŒì¼ êµ¬ì¡° ìƒì„±")
        print("5. ì¢…ë£Œ")
        
        choice = input("\nì„ íƒ (1-5): ").strip()
        
        if choice == "1":
            manager.run_all_systems()
        elif choice == "2":
            manager.run_quick_test()
        elif choice == "3":
            manager.show_system_status()
        elif choice == "4":
            manager.create_file_structure()
        elif choice == "5":
            print("ğŸ‘‹ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        else:
            print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. 1-5 ì¤‘ì—ì„œ ì„ íƒí•˜ì„¸ìš”.")


if __name__ == "__main__":
    main()
