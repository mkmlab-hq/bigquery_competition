{
  "training_results": {
    "advanced_training": {
      "status": "failed",
      "error": "\nEpoch 1/100:   0%|          | 0/110 [00:00<?, ?it/s]\nEpoch 1/100:   0%|          | 0/110 [00:01<?, ?it/s]\nTraceback (most recent call last):\n  File \"f:\\workspace\\bigquery_competition\\optimization\\advanced_multimodal_training.py\", line 832, in <module>\n    main()\n  File \"f:\\workspace\\bigquery_competition\\optimization\\advanced_multimodal_training.py\", line 822, in main\n    results = trainer.run_comprehensive_training(n_samples=10000, epochs=100)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"f:\\workspace\\bigquery_competition\\optimization\\advanced_multimodal_training.py\", line 770, in run_comprehensive_training\n    training_results = self.train_model(train_loader, val_loader, epochs)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"f:\\workspace\\bigquery_competition\\optimization\\advanced_multimodal_training.py\", line 479, in train_model\n    outputs, attention_info, dynamic_weights = self.model(\n                                               ^^^^^^^^^^^\n  File \"F:\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"F:\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"f:\\workspace\\bigquery_competition\\optimization\\advanced_multimodal_training.py\", line 198, in forward\n    attended_features, cross_attention_weights = self.cross_attention(\n                                                 ^^^^^^^^^^^^^^^^^^^^^\n  File \"F:\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"F:\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"F:\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\activation.py\", line 1380, in forward\n    attn_output, attn_output_weights = F.multi_head_attention_forward(\n                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"F:\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py\", line 6304, in multi_head_attention_forward\n    q, k, v = _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"F:\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py\", line 5713, in _in_projection_packed\n    kv_proj = linear(k, w_kv, b_kv)\n              ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (192x128 and 64x128)\n"
    },
    "realtime_learning": {
      "status": "success",
      "output": "\ufffd\u01fd\u00f0\ufffd \ufffd\ufffd\u01bc\ufffd\ufffd\ufffd \ufffd\u043d\ufffd \ufffd\u00fd\ufffd\ufffd\ufffd\n============================================================\n\ufffd\u01fd\u00f0\ufffd \ufffd\u043d\ufffd \ufffd\u00f9\u0137\ufffd\ufffd\u033c\ufffd \ufffd\ufffd\ufffd\ufffd\n============================================================\nReal-Time Multimodal Learning System\n============================================================\n   \ufffd\ufffd\ufffd\ufffd\u033d\ufffd: cpu\n   \ufffd\ufffd\ufffd\ufffd \u0169\ufffd\ufffd: 1000\n   \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u01ae \ufffd\u05b1\ufffd: 10\n\ufffd\u01fd\u00f0\ufffd \ufffd\ufffd\u01bc\ufffd\ufffd\ufffd \ufffd\u00fd\ufffd\ufffd\ufffd \ufffd\u02b1\ufffd\u022d\n\ufffd\u01fd\u00f0\ufffd \ufffd\u043d\ufffd \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\n1000\ufffd\ufffd \ufffd\ufffd\ufffd\u00f7\ufffd \ufffd\u00f9\u0137\ufffd\ufffd\u033c\ufffd \ufffd\ufffd\ufffd\ufffd...\n\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\u0232 (100/1000):\n   \u0165 \u0169\ufffd\ufffd: 90\n   \ufffd\ufffd\ufffd\ufffd \u0169\ufffd\ufffd: 10\n   \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u01ae \u023d\ufffd\ufffd: 0\n\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\u0232 (200/1000):\n   \u0165 \u0169\ufffd\ufffd: 190\n   \ufffd\ufffd\ufffd\ufffd \u0169\ufffd\ufffd: 10\n   \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u01ae \u023d\ufffd\ufffd: 0\n\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\u0232 (300/1000):\n   \u0165 \u0169\ufffd\ufffd: 290\n   \ufffd\ufffd\ufffd\ufffd \u0169\ufffd\ufffd: 10\n   \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u01ae \u023d\ufffd\ufffd: 0\n\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\u0232 (400/1000):\n   \u0165 \u0169\ufffd\ufffd: 390\n   \ufffd\ufffd\ufffd\ufffd \u0169\ufffd\ufffd: 10\n   \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u01ae \u023d\ufffd\ufffd: 0\n\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\u0232 (500/1000):\n   \u0165 \u0169\ufffd\ufffd: 490\n   \ufffd\ufffd\ufffd\ufffd \u0169\ufffd\ufffd: 10\n   \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u01ae \u023d\ufffd\ufffd: 0\n\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\u0232 (600/1000):\n   \u0165 \u0169\ufffd\ufffd: 590\n   \ufffd\ufffd\ufffd\ufffd \u0169\ufffd\ufffd: 10\n   \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u01ae \u023d\ufffd\ufffd: 0\n\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\u0232 (700/1000):\n   \u0165 \u0169\ufffd\ufffd: 690\n   \ufffd\ufffd\ufffd\ufffd \u0169\ufffd\ufffd: 10\n   \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u01ae \u023d\ufffd\ufffd: 0\n\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\u0232 (800/1000):\n   \u0165 \u0169\ufffd\ufffd: 790\n   \ufffd\ufffd\ufffd\ufffd \u0169\ufffd\ufffd: 10\n   \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u01ae \u023d\ufffd\ufffd: 0\n\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\u0232 (900/1000):\n   \u0165 \u0169\ufffd\ufffd: 890\n   \ufffd\ufffd\ufffd\ufffd \u0169\ufffd\ufffd: 10\n   \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u01ae \u023d\ufffd\ufffd: 0\n\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\u0232 (1000/1000):\n   \u0165 \u0169\ufffd\ufffd: 990\n   \ufffd\ufffd\ufffd\ufffd \u0169\ufffd\ufffd: 10\n   \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u01ae \u023d\ufffd\ufffd: 0\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\u0370\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\u03f4\ufffd.\n\ufffd\u01fd\u00f0\ufffd \ufffd\u043d\ufffd \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\n\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd \ufffd\u05fd\ufffd\u01ae:\n   \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd: 3.4611\n   \ufffd\ufffd\u07b8\ufffd\u01bc \ufffd\ufffd\ufffd\ufffd\u0121: [0.25 0.25 0.25 0.25]\n\n\ufffd\u01fd\u00f0\ufffd \ufffd\u043d\ufffd \ufffd\u00f9\u0137\ufffd\ufffd\u033c\ufffd \ufffd\u03f7\ufffd!\n"
    },
    "performance_optimization": {
      "status": "success",
      "torchscript_throughput": 111710.59836744957,
      "speedup": 0.9400860167857379,
      "optimal_batch_size": 512,
      "memory_usage_mb": 464.12109375
    }
  },
  "dependencies": {
    "torch": true,
    "sklearn": true,
    "pandas": true,
    "numpy": true,
    "matplotlib": true,
    "seaborn": true,
    "tqdm": true
  },
  "total_time_minutes": 2.423902753988902,
  "successful_trainings": 2,
  "total_trainings": 3
}